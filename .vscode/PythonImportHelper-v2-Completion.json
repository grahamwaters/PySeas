[
    {
        "label": "urldefrag",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urllib.request",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request",
        "description": "urllib.request",
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "dif",
        "importPath": "difPy",
        "description": "difPy",
        "isExtraImport": true,
        "detail": "difPy",
        "documentation": {}
    },
    {
        "label": "dif",
        "importPath": "difPy",
        "description": "difPy",
        "isExtraImport": true,
        "detail": "difPy",
        "documentation": {}
    },
    {
        "label": "dif",
        "importPath": "difPy",
        "description": "difPy",
        "isExtraImport": true,
        "detail": "difPy",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "imutils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imutils",
        "description": "imutils",
        "detail": "imutils",
        "documentation": {}
    },
    {
        "label": "paths",
        "importPath": "imutils",
        "description": "imutils",
        "isExtraImport": true,
        "detail": "imutils",
        "documentation": {}
    },
    {
        "label": "PIL",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL",
        "description": "PIL",
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "cam_finder_raw",
        "description": "cam_finder_raw",
        "isExtraImport": true,
        "detail": "cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "ratelimit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ratelimit",
        "description": "ratelimit",
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "limits",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "sleep_and_retry",
        "importPath": "ratelimit",
        "description": "ratelimit",
        "isExtraImport": true,
        "detail": "ratelimit",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "keras",
        "importPath": "tensorflow",
        "description": "tensorflow",
        "isExtraImport": true,
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "layers",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "backend",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "optimizers",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "regularizers",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "initializers",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "constraints",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "activations",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "metrics",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "losses",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "utils",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Conv2D",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "MaxPooling2D",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "ImageDataGenerator",
        "importPath": "keras.preprocessing.image",
        "description": "keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "keras.preprocessing",
        "description": "keras.preprocessing",
        "isExtraImport": true,
        "detail": "keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "isExtraImport": true,
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "tensorflow_hub",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow_hub",
        "description": "tensorflow_hub",
        "detail": "tensorflow_hub",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "Self",
        "importPath": "typing_extensions",
        "description": "typing_extensions",
        "isExtraImport": true,
        "detail": "typing_extensions",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "download_image",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "resize_image_to_standard_height",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "split_image_into_panels",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "detect_horizon_line",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "align_horizon_line",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "mse",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "check_unusual_panels",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "stitch_aligned_images",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "load_skipped_buoys",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "download_image",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "resize_image_to_standard_height",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "split_image_into_panels",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "detect_horizon_line",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "align_horizon_line",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "mse",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "check_unusual_panels",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "stitch_aligned_images",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "load_skipped_buoys",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "download_image",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "resize_image_to_standard_height",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "split_image_into_panels",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "detect_horizon_line",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "align_horizon_line",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "mse",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "check_unusual_panels",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "stitch_aligned_images",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "load_skipped_buoys",
        "importPath": "phase_one",
        "description": "phase_one",
        "isExtraImport": true,
        "detail": "phase_one",
        "documentation": {}
    },
    {
        "label": "ImageClassifier",
        "importPath": "image_classifier",
        "description": "image_classifier",
        "isExtraImport": true,
        "detail": "image_classifier",
        "documentation": {}
    },
    {
        "label": "ImageClassifier",
        "importPath": "image_classifier",
        "description": "image_classifier",
        "isExtraImport": true,
        "detail": "image_classifier",
        "documentation": {}
    },
    {
        "label": "matplotlib.image",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.image",
        "description": "matplotlib.image",
        "detail": "matplotlib.image",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Back",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Back",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "textwrap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "textwrap",
        "description": "textwrap",
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "ids",
        "kind": 5,
        "importPath": "data.buoy_list_2023",
        "description": "data.buoy_list_2023",
        "peekOfCode": "ids = [\"21414\",\"21415\",\"21416\",\"21417\",\"21418\",\"21419\",\"32301\",\"32302\",\"32411\",\"32412\",\"32413\",\"41001\",\"41002\",\"41003\",\"41004\",\"41007\",\"41008\",\"41009\",\"41010\",\"41011\",\"41012\",\"41016\",\"41017\",\"41018\",\"41021\",\"41022\",\"41023\",\"41036\",\"41040\",\"41041\",\"41043\",\"41044\",\"41046\",\"41049\",\"41420\",\"41421\",\"41424\",\"41425\",\"42001\",\"42002\",\"42003\",\"42004\",\"42007\",\"42008\",\"42009\",\"42010\",\"42011\",\"42012\",\"42017\",\"42018\",\"42019\",\"42020\",\"42025\",\"42035\",\"42038\",\"42039\",\"42040\",\"42041\",\"42042\",\"42053\",\"42056\",\"42057\",\"42058\",\"42059\",\"42060\",\"42065\",\"42408\",\"42409\",\"42429\",\"42501\",\"42503\",\"42534\",\"44001\",\"44003\",\"44004\",\"44005\",\"44006\",\"44007\",\"44010\",\"44011\",\"44012\",\"44013\",\"44014\",\"44015\",\"44019\",\"44020\",\"44023\",\"44025\",\"44026\",\"44027\",\"44066\",\"44070\",\"44071\",\"44401\",\"44402\",\"44403\",\"45002\",\"45003\",\"45004\",\"45005\",\"45006\",\"45007\",\"45010\",\"45011\",\"45012\",\"46001\",\"46002\",\"46003\",\"46007\",\"46008\",\"46009\",\"46010\",\"46011\",\"46012\",\"46015\",\"46016\",\"46017\",\"46018\",\"46019\",\"46020\",\"46023\",\"46024\",\"46025\",\"46026\",\"46027\",\"46028\",\"46031\",\"46032\",\"46033\",\"46034\",\"46035\",\"46037\",\"46040\",\"46041\",\"46042\",\"46043\",\"46045\",\"46047\",\"46051\",\"46053\",\"46054\",\"46059\",\"46060\",\"46061\",\"46066\",\"46069\",\"46070\",\"46071\",\"46072\",\"46073\",\"46077\",\"46078\",\"46079\",\"46080\",\"46081\",\"46082\",\"46085\",\"46086\",\"46087\",\"46088\",\"46089\",\"46090\",\"46107\",\"46115\",\"46270\",\"46290\",\"46401\",\"46402\",\"46405\",\"46406\",\"46407\",\"46408\",\"46409\",\"46410\",\"46413\",\"46414\",\"46415\",\"46416\",\"46419\",\"46490\",\"46779\",\"46780\",\"46781\",\"46782\",\"46785\",\"51000\",\"51001\",\"51002\",\"51003\",\"51004\",\"51005\",\"51028\",\"51100\",\"51101\",\"51406\",\"51407\",\"51425\",\"52009\",\"52401\",\"52402\",\"52403\",\"52404\",\"52405\",\"91204\",\"91222\",\"91251\",\"91328\",\"91338\",\"91343\",\"91356\",\"91365\",\"91374\",\"91377\",\"91411\",\"91442\",\"46265\",\"41670\",\"41852\",\"41904\",\"41933\",\"48916\",\"48917\",\"52838\",\"52839\",\"52840\",\"52841\",\"52842\",\"52843\",\"52862\",\"55012\",\"55013\",\"55015\",\"55016\",\"55023\",\"55042\",\"58952\",\"31052\",\"31053\",\"41052\",\"41053\",\"41056\",\"41058\",\"41115\",\"41121\",\"41030\",\"44042\",\"44043\",\"44057\",\"44058\",\"44059\",\"44061\",\"44064\",\"44068\",\"45016\",\"45017\",\"45018\",\"45019\",\"45177\",\"45202\",\"45203\",\"45204\",\"45205\",\"45206\",\"45207\",\"46116\",\"46117\",\"46127\",\"42014\",\"42021\",\"42022\",\"42023\",\"42024\",\"42026\",\"32404\",\"41029\",\"41033\",\"41037\",\"41038\",\"41064\",\"41065\",\"41110\",\"41119\",\"41159\",\"32488\",\"41193\",\"44138\",\"44139\",\"44140\",\"44141\",\"44142\",\"44150\",\"44176\",\"44235\",\"44251\",\"44255\",\"44258\",\"44488\",\"45132\",\"45135\",\"45136\",\"45137\",\"45138\",\"45139\",\"45142\",\"45143\",\"45144\",\"45145\",\"45147\",\"45148\",\"45151\",\"45152\",\"45154\",\"45155\",\"45158\",\"45159\",\"46036\",\"46131\",\"46132\",\"46084\",\"46134\",\"46138\",\"46139\",\"46147\",\"46181\",\"46183\",\"46184\",\"46185\",\"46204\",\"46207\",\"46208\",\"46303\",\"46304\",\"48021\",\"45162\",\"45163\",\"45195\",\"23219\",\"23227\",\"32067\",\"32068\",\"42087\",\"42088\",\"42089\",\"42090\",\"46109\",\"46110\",\"46111\",\"46112\",\"21346\",\"21347\",\"21348\",\"21595\",\"21597\",\"21598\",\"21637\",\"21640\",\"22102\",\"22103\",\"22104\",\"22105\",\"22106\",\"22107\",\"45029\",\"45164\",\"45165\",\"45168\",\"45169\",\"45176\",\"46091\",\"46092\",\"62091\",\"62092\",\"62093\",\"62094\",\"41097\",\"41098\",\"41100\",\"41101\",\"41300\",\"61001\",\"45025\",\"45175\",\"44039\",\"44040\",\"44060\",\"23220\",\"23223\",\"23225\",\"46261\",\"46263\",\"48901\",\"48908\",\"48909\",\"48912\",\"44024\",\"44029\",\"44030\",\"44031\",\"44032\",\"44033\",\"44036\",\"44037\",\"45172\",\"45173\",\"46118\",\"46119\",\"46531\",\"46534\",\"46538\",\"46565\",\"44075\",\"44076\",\"44077\",\"44078\",\"46097\",\"46098\",\"51046\",\"51201\",\"51202\",\"51203\",\"51204\",\"51205\",\"51208\",\"51209\",\"51210\",\"51211\",\"51212\",\"51213\",\"52202\",\"52211\",\"13002\",\"13008\",\"13009\",\"13010\",\"15001\",\"15002\",\"31001\",\"31002\",\"31003\",\"31004\",\"31005\",\"31006\",\"62121\",\"62124\",\"62125\",\"62126\",\"62127\",\"62130\",\"62144\",\"62145\",\"62146\",\"62147\",\"62148\",\"62149\",\"62165\",\"62166\",\"63105\",\"63110\",\"63112\",\"63113\",\"14041\",\"14043\",\"14047\",\"23001\",\"23003\",\"23004\",\"23008\",\"23009\",\"23010\",\"23011\",\"23012\",\"23013\",\"23016\",\"23017\",\"53005\",\"53006\",\"53009\",\"53040\",\"56053\",\"01506\",\"01507\",\"01518\",\"01537\",\"48904\",\"48907\",\"01521\",\"01522\",\"01523\",\"01524\",\"01526\",\"01531\",\"01535\",\"01536\",\"01538\",\"01909\",\"01910\",\"31201\",\"41112\",\"41113\",\"41114\",\"41116\",\"41118\",\"41120\",\"42084\",\"42091\",\"42094\",\"42099\",\"44088\",\"44094\",\"44099\",\"44100\",\"44172\",\"46114\",\"46211\",\"46212\",\"46215\",\"46216\",\"46217\",\"46218\",\"46219\",\"46220\",\"46223\",\"46224\",\"46225\",\"46226\",\"46227\",\"46228\",\"46231\",\"46232\",\"46234\",\"46235\",\"46236\",\"46237\",\"46240\",\"46241\",\"46242\",\"46243\",\"46244\",\"46245\",\"46249\",\"46250\",\"46251\",\"46253\",\"46254\",\"46256\",\"46262\",\"46267\",\"46268\",\"46269\",\"46273\",\"46274\",\"51200\",\"48212\",\"48213\",\"48214\",\"48677\",\"48678\",\"48679\",\"48680\",\"48911\",\"42044\",\"42045\",\"42046\",\"42047\",\"42048\",\"42049\",\"42078\",\"42079\",\"42093\",\"42095\",\"42097\",\"44056\",\"45180\",\"46259\",\"46266\",\"62028\",\"62029\",\"62030\",\"62050\",\"62081\",\"62103\",\"62108\",\"62163\",\"62170\",\"62298\",\"62301\",\"62303\",\"62442\",\"64045\",\"44098\",\"46121\",\"46122\",\"46123\",\"46124\",\"28902\",\"28903\",\"28904\",\"28906\",\"28907\",\"28908\",\"58900\",\"58902\",\"58903\",\"58904\",\"58905\",\"58906\",\"58909\",\"68900\",\"78900\",\"45014\",\"45184\",\"44053\",\"01517\",\"32012\",\"41060\",\"41061\",\"21D20\",\"32D12\",\"32D13\",\"41A46\",\"41S43\",\"41S46\",\"46B35\",\"ALSN6\",\"AMAA2\",\"AUGA2\",\"BLIA2\",\"BURL1\",\"BUSL1\",\"CDRF1\",\"CHLV2\",\"CLKN7\",\"CSBF1\",\"DBLN6\",\"DESW1\",\"DRFA2\",\"DRYF1\",\"DSLN7\",\"DUCN7\",\"EB01\",\"EB10\",\"EB33\",\"EB35\",\"EB36\",\"EB43\",\"EB52\",\"EB53\",\"EB70\",\"EB90\",\"EB91\",\"EB92\",\"FARP2\",\"FBIS1\",\"FPSN7\",\"FWYF1\",\"GBCL1\",\"GDIL1\",\"GLLN6\",\"IOSN3\",\"LONF1\",\"LPOI1\",\"MDRM1\",\"MISM1\",\"MLRF1\",\"MPCL1\",\"PILA2\",\"PILM4\",\"PLSF1\",\"POTA2\",\"PTAC1\",\"PTAT2\",\"SANF1\",\"SAUF1\",\"SBIO1\",\"SGNW3\",\"SGOF1\",\"SISW1\",\"SPGF1\",\"SRST2\",\"STDM4\",\"SUPN6\",\"SVLS1\",\"THIN6\",\"VENF1\",\"HBXC1\",\"MYXC1\",\"TDPC1\",\"FSTI2\",\"DMNO3\",\"GPTW1\",\"HMNO3\",\"PRTO3\",\"SEFO3\",\"SETO3\",\"SRAW1\",\"SRFW1\",\"TANO3\",\"ANMF1\",\"ARPF1\",\"BGCF1\",\"CAMF1\",\"CLBF1\",\"EGKF1\",\"NFBF1\",\"PTRF1\",\"SHPF1\",\"MBIN7\",\"MBNN7\",\"OCPN7\",\"BSCA1\",\"CRTA1\",\"DPHA1\",\"KATA1\",\"MBLA1\",\"MHPA1\",\"SACV4\",\"BBSF1\",\"BDVF1\",\"BKYF1\",\"BNKF1\",\"BOBF1\",\"BSKF1\",\"CNBF1\",\"CWAF1\",\"DKKF1\",\"GBIF1\",\"GBTF1\",\"GKYF1\",\"JBYF1\",\"JKYF1\",\"LBRF1\",\"LBSF1\",\"LMDF1\",\"LMRF1\",\"LSNF1\",\"MDKF1\",\"MNBF1\",\"MUKF1\",\"NRRF1\",\"PKYF1\",\"TCVF1\",\"THRF1\",\"TPEF1\",\"TRRF1\",\"WIWF1\",\"WPLF1\",\"APNM4\",\"CHII2\",\"MCYI3\",\"SRLM4\",\"SVNM4\",\"TBIM4\",\"THLO1\",\"LCIY2\",\"LLBP7\",\"FWIC3\",\"MISC3\",\"MISN6\",\"NCSC3\",\"NOSC3\",\"OFPN6\",\"ILDL1\",\"MRSL1\",\"SIPM6\",\"SLPL1\",\"LUML1\",\"TAML1\",\"AKXA2\",\"APMA2\",\"BEXA2\",\"CDXA2\",\"CPXA2\",\"DHXA2\",\"DPXA2\",\"ERXA2\",\"GBXA2\",\"GEXA2\",\"GIXA2\",\"GPXA2\",\"HMSA2\",\"ICYA2\",\"JLXA2\",\"JMLA2\",\"JNGA2\",\"KEXA2\",\"KNXA2\",\"KOZA2\",\"LIXA2\",\"MIXA2\",\"MRNA2\",\"MRYA2\",\"NKLA2\",\"NKXA2\",\"NLXA2\",\"NMXA2\",\"NSXA2\",\"PAUA2\",\"PEXA2\",\"PGXA2\",\"PPXA2\",\"PTLA2\",\"RIXA2\",\"SCXA2\",\"SIXA2\",\"SKXA2\",\"SLXA2\",\"SPXA2\",\"SRXA2\",\"STXA2\",\"SXXA2\",\"TKEA2\",\"TPXA2\",\"UQXA2\",\"VDXA2\",\"WCXA2\",\"MSG10\",\"MSG12\",\"ACQS1\",\"ACXS1\",\"ANMN6\",\"ANRN6\",\"APQF1\",\"APXA2\",\"BILW3\",\"BRIM2\",\"BSLM2\",\"BVQW1\",\"CHNO3\",\"CHQO3\",\"CWQT2\",\"DBQS1\",\"DEQD1\",\"DRSD1\",\"EAZC1\",\"EHSC1\",\"EVMC1\",\"FFFC1\",\"GBHM6\",\"GBQN3\",\"GBRM6\",\"GDQM6\",\"GGGC1\",\"GTQF1\",\"GTXF1\",\"HBMN6\",\"HMRA2\",\"HUQN6\",\"JCTN4\",\"JOBP4\",\"JOQP4\",\"JOXP4\",\"KCHA2\",\"LTQM2\",\"MIST2\",\"MQMT2\",\"MWQT2\",\"NAQR1\",\"NAXR1\",\"NIQS1\",\"NOXN7\",\"NPQN6\",\"NPXN6\",\"OWDO1\",\"OWQO1\",\"OWSO1\",\"PBLW1\",\"PKBW3\",\"RKQF1\",\"RKXF1\",\"RYEC1\",\"SAQG1\",\"SCQC1\",\"SCQN6\",\"SEQA2\",\"SFXC1\",\"SKQN6\",\"SLOO3\",\"TCSV2\",\"TIQC1\",\"TIXC1\",\"TKPN6\",\"WAQM3\",\"WAXM3\",\"WELM1\",\"WEQM1\",\"WEXM1\",\"WKQA1\",\"WKXA1\",\"WYBS1\",\"NLMA3\",\"SBBN2\",\"SLMN2\",\"BAXC1\",\"BDRN4\",\"BDSP1\",\"BGNN6\",\"BKBF1\",\"BLIF1\",\"BRND1\",\"CHCM2\",\"CHYV2\",\"COVM2\",\"CPMW1\",\"CPNW1\",\"CRYV2\",\"DELD1\",\"DMSF1\",\"DOMV2\",\"DPXC1\",\"EBEF1\",\"FMOA1\",\"FRVM3\",\"FRXM3\",\"FSKM2\",\"FSNM2\",\"GCTF1\",\"LNDC1\",\"LQAT2\",\"LTJF1\",\"MBPA1\",\"MCGA1\",\"MHBT2\",\"MRCP1\",\"MTBF1\",\"MZXC1\",\"NBLP1\",\"NFDF1\",\"NWHC3\",\"OMHC1\",\"OPTF1\",\"PDVR1\",\"PEGF1\",\"PFDC1\",\"PFXC1\",\"PPTM2\",\"PPXC1\",\"PRJC1\",\"PRUR1\",\"PSBC1\",\"PSXC1\",\"PTOA1\",\"PVDR1\",\"PXAC1\",\"PXOC1\",\"PXSC1\",\"QPTR1\",\"RPLV2\",\"RTYC1\",\"SEIM1\",\"SJSN4\",\"SKCF1\",\"SWPM4\",\"TCNW1\",\"TLVT2\",\"TPAF1\",\"TSHF1\",\"TXVT2\",\"UPBC1\",\"WDSV2\",\"ACYN4\",\"ADKA2\",\"AGCM4\",\"ALIA2\",\"ALXN6\",\"AMRL1\",\"APAM2\",\"APCF1\",\"APRP7\",\"ASTO3\",\"ATGM1\",\"ATKA2\",\"BEPB6\",\"BFTN7\",\"BHBM3\",\"BISM2\",\"BKTL1\",\"BLTM2\",\"BYGL1\",\"BZBM3\",\"CAMM2\",\"CAPL1\",\"CARL1\",\"CASM1\",\"CECC1\",\"CFWM1\",\"CHAO3\",\"CHAV3\",\"CHBV2\",\"CHSV3\",\"CHYW1\",\"CLBP4\",\"CMAN4\",\"CMTI2\",\"CNDO1\",\"CRVA2\",\"DILA1\",\"DKCM6\",\"DTLM4\",\"DUKN7\",\"DULM5\",\"EBSW1\",\"ERTF1\",\"ESPP4\",\"FAIO1\",\"FCGT2\",\"FMRF1\",\"FOXR1\",\"FPTT2\",\"FRCB6\",\"FRDF1\",\"FRDW1\",\"FREL1\",\"FRPS1\",\"FTPC1\",\"GBWW3\",\"GCVF1\",\"GDMM5\",\"GISL1\",\"GNJT2\",\"GTOT2\",\"GWPM6\",\"HBYC1\",\"HCGN7\",\"HLNM4\",\"HMDO3\",\"ICAC1\",\"IIWC1\",\"ILOH1\",\"ITKA2\",\"JMPN7\",\"JNEA2\",\"KECA2\",\"KGCA2\",\"KLIH1\",\"KPTN6\",\"KPTV2\",\"KWHH1\",\"KYWF1\",\"LABL1\",\"LAMV3\",\"LAPW1\",\"LCLL1\",\"LDTM4\",\"LOPW1\",\"LPNM4\",\"LTBV3\",\"LTRM4\",\"LWSD1\",\"LWTV2\",\"MBRM4\",\"MCGM4\",\"MCYF1\",\"MEYC1\",\"MGIP4\",\"MGZP4\",\"MOKH1\",\"MQTT2\",\"MRHO1\",\"MROS1\",\"MTKN6\",\"MTYC1\",\"NEAW1\",\"NIAN6\",\"NJLC1\",\"NKTA2\",\"NLNC3\",\"NMTA2\",\"NTBC1\",\"NTKM3\",\"NUET2\",\"NWCL1\",\"NWPR1\",\"NWWH1\",\"OCIM2\",\"OHBC1\",\"OLSA2\",\"OOUH1\",\"ORIN7\",\"OSGN6\",\"PCBF1\",\"PCLF1\",\"PCOC1\",\"PGBP7\",\"PHBP1\",\"PLXA2\",\"PNLM6\",\"PORO3\",\"PRDA2\",\"PRYC1\",\"PSBM1\",\"PSLC1\",\"PTAW1\",\"PTIM4\",\"PTIT2\",\"PTWW1\",\"RARM6\",\"RCKM4\",\"RCYF1\",\"RDDA2\",\"RDYD1\",\"SAPF1\",\"SBEO3\",\"SBLF1\",\"SDBC1\",\"SDHN4\",\"SHBL1\",\"SJNP4\",\"SKTA2\",\"SLIM2\",\"SNDP5\",\"SWLA2\",\"SWPV2\",\"TESL1\",\"THRO1\",\"TLBO3\",\"TRDF1\",\"TXPT2\",\"ULAM6\",\"ULRA2\",\"UNLA2\",\"VAKF1\",\"VDZA2\",\"WAHV2\",\"WAKP8\",\"WASD2\",\"WAVM6\",\"WLON7\",\"WPTW1\",\"WYCM6\",\"YATA2\",\"BLTA2\",\"CDEA2\",\"EROA2\",\"LCNA2\",\"PBPA2\",\"PRTA2\",\"SDIA2\",\"AGMW3\",\"BHRI3\",\"BIGM4\",\"BSBM4\",\"CBRW3\",\"CLSM4\",\"FPTM4\",\"GBLW3\",\"GRMM4\",\"GSLM4\",\"GTLM4\",\"GTRM4\",\"KP53\",\"KP58\",\"KP59\",\"LSCM4\",\"MEEM4\",\"NABM4\",\"PCLM4\",\"PNGW3\",\"PRIM4\",\"PSCM4\",\"PWAW3\",\"SBLM4\",\"SPTM4\",\"SXHW3\",\"SYWW3\",\"TAWM4\",\"WFPM4\",\"BARN6\",\"CBLO1\",\"CHDS1\",\"CMPO1\",\"GELO1\",\"HHLO1\",\"LORO1\",\"NREP1\",\"OLCN6\",\"RPRN6\",\"WATS1\",\"AUDP4\",\"FRDP4\",\"PLSP4\",\"VQSP4\",\"CGCL1\",\"SKMG1\",\"SPAG1\",\"AVAN4\",\"BRBN4\",\"OCGN4\",\"AWRT2\",\"BABT2\",\"BZST2\",\"CLLT2\",\"CPNT2\",\"EMAT2\",\"GRRT2\",\"HIST2\",\"IRDT2\",\"LUIT2\",\"LYBT2\",\"MGPT2\",\"NWST2\",\"PACT2\",\"PCGT2\",\"PCNT2\",\"PMNT2\",\"PORT2\",\"RSJT2\",\"RTAT2\",\"RTOT2\",\"SDRT2\",\"SGNT2\",\"TAQT2\",\"BTHD1\",\"FRFN7\",\"JPRN7\",\"18CI3\",\"20CM4\",\"GDIV2\",\"32ST0\",\"41NT0\"]",
        "detail": "data.buoy_list_2023",
        "documentation": {}
    },
    {
        "label": "Buoy",
        "kind": 6,
        "importPath": "old_files.PyBuoy",
        "description": "old_files.PyBuoy",
        "peekOfCode": "class Buoy(): # this is the super parent class\n    def __init__(self,buoy_id=\"none\",temperature=\"none\"):\n        self.buoy_id = buoy_id\n        self.temperature = temperature\n    def check_buoy(self,buoy_id):\n        self.check_data = 'defaults' # put defaults into the code here\nclass Chosen_Buoy(Buoy):\n    def __init__(self,buoy_type=\"none\"):\n        super().__init__(\"Chosen_Buoy\")\n        self.buoy_lat = 10.0",
        "detail": "old_files.PyBuoy",
        "documentation": {}
    },
    {
        "label": "Chosen_Buoy",
        "kind": 6,
        "importPath": "old_files.PyBuoy",
        "description": "old_files.PyBuoy",
        "peekOfCode": "class Chosen_Buoy(Buoy):\n    def __init__(self,buoy_type=\"none\"):\n        super().__init__(\"Chosen_Buoy\")\n        self.buoy_lat = 10.0\n        self.buoy_lng = 10.0\n        self.buoy_depth = 10.0\n        self.buoy_temp = 10.0\n        self.buoy_atmpressure = 10.0\n    def report_out(self,chosen_metric):\n        super().report_out(chosen_metric)",
        "detail": "old_files.PyBuoy",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "old_files.PyBuoy",
        "description": "old_files.PyBuoy",
        "peekOfCode": "def main():\n    # create a matrix 36 x 36 containing buoy ids\n    # https://www.ndbc.noaa.gov/buoycam.php?station=xxxxx\n    # this gets most recent photo from the buoy with the code xxxxx\n    # https://tidesandcurrents.noaa.gov/api-helper/url-generator.html\n    #https://www.ndbc.noaa.gov/rss/ndbc_obs_search.php?lat=40N&lon=73W&radius=100\n    #https://www.ndbc.noaa.gov/data/realtime2/ (station id) .swdir\n    #https://api.tidesandcurrents.noaa.gov/api/prod/datagetter?begin_date=20130808 15:00&end_date=20130808 15:06&station=8454000&product=water_temperature&units=english&time_zone=gmt&application=ports_screen&format=json\n    #The result \"V\" should be the desired variable\n    product = 'air_temperature'",
        "detail": "old_files.PyBuoy",
        "documentation": {}
    },
    {
        "label": "Artist",
        "kind": 6,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "class Artist:\n    def __init__(self):\n        self.folder = 'images'\n        self.batches = []\n    def make_panorama(self, images):\n        \"\"\"\n        make_panorama takes a list of images and makes a panorama out of them\n        :param images: _description_\n        :type images: _type_\n        :return: _description_",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "panel_sorter",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def panel_sorter():\n    # Go into each panel directory and sort the images into folders by the date in their filename (if they haven't already been sorted)\n    # example unsorted directory: 'images/panels/46078/2022_11_5_15_44_panel_1.png'\n    # example sorted directory: images/panels/51000/2022_11_5_15_44/panel_1.png\n    for buoy_id in os.listdir('images/panels'):\n        if buoy_id != '.DS_Store' and '.' not in buoy_id:\n            for image in os.listdir('images/panels/{}'.format(buoy_id)):\n                if image != '.DS_Store' and '.' not in image:\n                    try:\n                        # find the 2022_11_5_15_44 (#_#_#_#_#) part of the filename and make a new folder with that name.",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "divide_into_panels",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def divide_into_panels(buoy_id, image_file):\n    # divide the image into six panels, as dictated in the image processing pipeline for NOAA Buoy Cameras Comments above.\n    # read the image\n    img = cv2.imread(image_file)\n    # get the name of the image file\n    image_name = image_file.split('/')[-1]\n    # get the dimensions of the image\n    height, width, channels = img.shape\n    # Before dividing into panels, crop the image to remove 30 pixels from the bottom of the image.\n    # This is to remove the \"Buoy Camera\" text from the image.",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "is_it_daytime",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def is_it_daytime(image_path):\n    # This function will take an image path and return True if it is daytime and False if it is nighttime.\n    # The image path should be a string.\n    # The image path should be the path to the image that was used to create the panels.\n    # The image path should be in the format 'images/buoys/46025/2019_12_12_12_12.jpg'\n    # get the image\n    try:\n        img = Image.open(image_path)\n        # get the image size\n        width, height = img.size",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "image_has_changed",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def image_has_changed(image_one,image_two):\n    # looks for changes between two images and returns True if there are changes and False if there are not.\n    # this function is used to determine what rate the images are being updated for each buoy.\n    # if the images are not changing, then the buoy is not updating the images.\n    # if the images are changing, then the buoy is updating the images.\n    try:\n        image_one = cv2.imread(image_one)\n        image_two = cv2.imread(image_two)\n        difference = cv2.subtract(image_one, image_two)\n        result = not np.any(difference)",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "artist_eval",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def artist_eval(image_path):\n    # get the image\n    img = Image.open(image_path)\n    # get the image size\n    width, height = img.size\n    # get the pixel values for the center of the image\n    pixel_values = img.getpixel((int(width/2), int(height/2)))\n    # get the pixel values for the top left corner of the image\n    upper_left = img.getpixel((0, 0))\n    # get the pixel values for the top right corner of the image",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "check_for_updates",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def check_for_updates(buoy_update_rates_dict):\n    # Check the buoy_update_rates_dict to see if any of the buoys satistfy the update rate requirements:\n    # Requirements: the current time minus the last time we downloaded an image for this buoy must be greater than the update rate for this buoy. If it is, then we will add the buoy id to the list of buoys that need to be updated and return it to the main function.\n    # If the buoy_update_rates_dict is empty, then we will return an empty list.\n    # If the buoy_update_rates_dict is not empty, then we will check the update rates for each buoy and return a list of the buoy ids that need to be updated.\n    if len(buoy_update_rates_dict) == 0:\n        return []\n    else:\n        buoys_to_update = []\n        for buoy_id in buoy_update_rates_dict:",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "get_latest_data",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def get_latest_data():\n    url = \"https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt\"\n    s=requests.get(url).content\n    # the table contains two rows that have header data. combine them into one row.\n    df = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\\s+')\n    df.columns = df.columns.str.strip()\n    # df = df.dropna(axis=1, how='all')\n    # df = df.dropna(axis=0, how='all')\n    # df = df.dropna(axis=0, how='any')\n    # df = df.reset_index(drop=True)",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "display_last_image",
        "kind": 2,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "def display_last_image(buoys_to_update):\n    # get the last buoy in the list of buoys that need to be updated\n    buoy_id = buoys_to_update[-1]\n    # get the list of images in the folder\n    # sort the images by date\n    # make folder_path variable from relative path\n    # choose the last buoy in the list of buoy folders\n    last_buoy=buoys_to_update[-1]\n    folder_path = 'images/buoys/{}'.format(last_buoy)\n    images = os.listdir(folder_path)",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "cam_buoys",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "cam_buoys = []\n# %%\n# Set up #logging file\n#logging.basicConfig(filename='cam_finder.log', level=#logging.INFO)\n# %% [markdown]\n# Stage One\n# %%\nids = [\"21414\",\"21415\",\"21416\",\"21417\",\"21418\",\"21419\",\"32301\",\"32302\",\"32411\",\"32412\",\"32413\",\"41001\",\"41002\",\"41003\",\"41004\",\"41007\",\"41008\",\"41009\",\"41010\",\"41011\",\"41012\",\"41016\",\"41017\",\"41018\",\"41021\",\"41022\",\"41023\",\"41036\",\"41040\",\"41041\",\"41043\",\"41044\",\"41046\",\"41049\",\"41420\",\"41421\",\"41424\",\"41425\",\"42001\",\"42002\",\"42003\",\"42004\",\"42007\",\"42008\",\"42009\",\"42010\",\"42011\",\"42012\",\"42017\",\"42018\",\"42019\",\"42020\",\"42025\",\"42035\",\"42038\",\"42039\",\"42040\",\"42041\",\"42042\",\"42053\",\"42056\",\"42057\",\"42058\",\"42059\",\"42060\",\"42065\",\"42408\",\"42409\",\"42429\",\"42501\",\"42503\",\"42534\",\"44001\",\"44003\",\"44004\",\"44005\",\"44006\",\"44007\",\"44010\",\"44011\",\"44012\",\"44013\",\"44014\",\"44015\",\"44019\",\"44020\",\"44023\",\"44025\",\"44026\",\"44027\",\"44066\",\"44070\",\"44071\",\"44401\",\"44402\",\"44403\",\"45002\",\"45003\",\"45004\",\"45005\",\"45006\",\"45007\",\"45010\",\"45011\",\"45012\",\"46001\",\"46002\",\"46003\",\"46007\",\"46008\",\"46009\",\"46010\",\"46011\",\"46012\",\"46015\",\"46016\",\"46017\",\"46018\",\"46019\",\"46020\",\"46023\",\"46024\",\"46025\",\"46026\",\"46027\",\"46028\",\"46031\",\"46032\",\"46033\",\"46034\",\"46035\",\"46037\",\"46040\",\"46041\",\"46042\",\"46043\",\"46045\",\"46047\",\"46051\",\"46053\",\"46054\",\"46059\",\"46060\",\"46061\",\"46066\",\"46069\",\"46070\",\"46071\",\"46072\",\"46073\",\"46077\",\"46078\",\"46079\",\"46080\",\"46081\",\"46082\",\"46085\",\"46086\",\"46087\",\"46088\",\"46089\",\"46090\",\"46107\",\"46115\",\"46270\",\"46290\",\"46401\",\"46402\",\"46405\",\"46406\",\"46407\",\"46408\",\"46409\",\"46410\",\"46413\",\"46414\",\"46415\",\"46416\",\"46419\",\"46490\",\"46779\",\"46780\",\"46781\",\"46782\",\"46785\",\"51000\",\"51001\",\"51002\",\"51003\",\"51004\",\"51005\",\"51028\",\"51100\",\"51101\",\"51406\",\"51407\",\"51425\",\"52009\",\"52401\",\"52402\",\"52403\",\"52404\",\"52405\",\"91204\",\"91222\",\"91251\",\"91328\",\"91338\",\"91343\",\"91356\",\"91365\",\"91374\",\"91377\",\"91411\",\"91442\",\"46265\",\"41670\",\"41852\",\"41904\",\"41933\",\"48916\",\"48917\",\"52838\",\"52839\",\"52840\",\"52841\",\"52842\",\"52843\",\"52862\",\"55012\",\"55013\",\"55015\",\"55016\",\"55023\",\"55042\",\"58952\",\"31052\",\"31053\",\"41052\",\"41053\",\"41056\",\"41058\",\"41115\",\"41121\",\"41030\",\"44042\",\"44043\",\"44057\",\"44058\",\"44059\",\"44061\",\"44064\",\"44068\",\"45016\",\"45017\",\"45018\",\"45019\",\"45177\",\"45202\",\"45203\",\"45204\",\"45205\",\"45206\",\"45207\",\"46116\",\"46117\",\"46127\",\"42014\",\"42021\",\"42022\",\"42023\",\"42024\",\"42026\",\"32404\",\"41029\",\"41033\",\"41037\",\"41038\",\"41064\",\"41065\",\"41110\",\"41119\",\"41159\",\"32488\",\"41193\",\"44138\",\"44139\",\"44140\",\"44141\",\"44142\",\"44150\",\"44176\",\"44235\",\"44251\",\"44255\",\"44258\",\"44488\",\"45132\",\"45135\",\"45136\",\"45137\",\"45138\",\"45139\",\"45142\",\"45143\",\"45144\",\"45145\",\"45147\",\"45148\",\"45151\",\"45152\",\"45154\",\"45155\",\"45158\",\"45159\",\"46036\",\"46131\",\"46132\",\"46084\",\"46134\",\"46138\",\"46139\",\"46147\",\"46181\",\"46183\",\"46184\",\"46185\",\"46204\",\"46207\",\"46208\",\"46303\",\"46304\",\"48021\",\"45162\",\"45163\",\"45195\",\"23219\",\"23227\",\"32067\",\"32068\",\"42087\",\"42088\",\"42089\",\"42090\",\"46109\",\"46110\",\"46111\",\"46112\",\"21346\",\"21347\",\"21348\",\"21595\",\"21597\",\"21598\",\"21637\",\"21640\",\"22102\",\"22103\",\"22104\",\"22105\",\"22106\",\"22107\",\"45029\",\"45164\",\"45165\",\"45168\",\"45169\",\"45176\",\"46091\",\"46092\",\"62091\",\"62092\",\"62093\",\"62094\",\"41097\",\"41098\",\"41100\",\"41101\",\"41300\",\"61001\",\"45025\",\"45175\",\"44039\",\"44040\",\"44060\",\"23220\",\"23223\",\"23225\",\"46261\",\"46263\",\"48901\",\"48908\",\"48909\",\"48912\",\"44024\",\"44029\",\"44030\",\"44031\",\"44032\",\"44033\",\"44036\",\"44037\",\"45172\",\"45173\",\"46118\",\"46119\",\"46531\",\"46534\",\"46538\",\"46565\",\"44075\",\"44076\",\"44077\",\"44078\",\"46097\",\"46098\",\"51046\",\"51201\",\"51202\",\"51203\",\"51204\",\"51205\",\"51208\",\"51209\",\"51210\",\"51211\",\"51212\",\"51213\",\"52202\",\"52211\",\"13002\",\"13008\",\"13009\",\"13010\",\"15001\",\"15002\",\"31001\",\"31002\",\"31003\",\"31004\",\"31005\",\"31006\",\"62121\",\"62124\",\"62125\",\"62126\",\"62127\",\"62130\",\"62144\",\"62145\",\"62146\",\"62147\",\"62148\",\"62149\",\"62165\",\"62166\",\"63105\",\"63110\",\"63112\",\"63113\",\"14041\",\"14043\",\"14047\",\"23001\",\"23003\",\"23004\",\"23008\",\"23009\",\"23010\",\"23011\",\"23012\",\"23013\",\"23016\",\"23017\",\"53005\",\"53006\",\"53009\",\"53040\",\"56053\",\"01506\",\"01507\",\"01518\",\"01537\",\"48904\",\"48907\",\"01521\",\"01522\",\"01523\",\"01524\",\"01526\",\"01531\",\"01535\",\"01536\",\"01538\",\"01909\",\"01910\",\"31201\",\"41112\",\"41113\",\"41114\",\"41116\",\"41118\",\"41120\",\"42084\",\"42091\",\"42094\",\"42099\",\"44088\",\"44094\",\"44099\",\"44100\",\"44172\",\"46114\",\"46211\",\"46212\",\"46215\",\"46216\",\"46217\",\"46218\",\"46219\",\"46220\",\"46223\",\"46224\",\"46225\",\"46226\",\"46227\",\"46228\",\"46231\",\"46232\",\"46234\",\"46235\",\"46236\",\"46237\",\"46240\",\"46241\",\"46242\",\"46243\",\"46244\",\"46245\",\"46249\",\"46250\",\"46251\",\"46253\",\"46254\",\"46256\",\"46262\",\"46267\",\"46268\",\"46269\",\"46273\",\"46274\",\"51200\",\"48212\",\"48213\",\"48214\",\"48677\",\"48678\",\"48679\",\"48680\",\"48911\",\"42044\",\"42045\",\"42046\",\"42047\",\"42048\",\"42049\",\"42078\",\"42079\",\"42093\",\"42095\",\"42097\",\"44056\",\"45180\",\"46259\",\"46266\",\"62028\",\"62029\",\"62030\",\"62050\",\"62081\",\"62103\",\"62108\",\"62163\",\"62170\",\"62298\",\"62301\",\"62303\",\"62442\",\"64045\",\"44098\",\"46121\",\"46122\",\"46123\",\"46124\",\"28902\",\"28903\",\"28904\",\"28906\",\"28907\",\"28908\",\"58900\",\"58902\",\"58903\",\"58904\",\"58905\",\"58906\",\"58909\",\"68900\",\"78900\",\"45014\",\"45184\",\"44053\",\"01517\",\"32012\",\"41060\",\"41061\",\"21D20\",\"32D12\",\"32D13\",\"41A46\",\"41S43\",\"41S46\",\"46B35\",\"ALSN6\",\"AMAA2\",\"AUGA2\",\"BLIA2\",\"BURL1\",\"BUSL1\",\"CDRF1\",\"CHLV2\",\"CLKN7\",\"CSBF1\",\"DBLN6\",\"DESW1\",\"DRFA2\",\"DRYF1\",\"DSLN7\",\"DUCN7\",\"EB01\",\"EB10\",\"EB33\",\"EB35\",\"EB36\",\"EB43\",\"EB52\",\"EB53\",\"EB70\",\"EB90\",\"EB91\",\"EB92\",\"FARP2\",\"FBIS1\",\"FPSN7\",\"FWYF1\",\"GBCL1\",\"GDIL1\",\"GLLN6\",\"IOSN3\",\"LONF1\",\"LPOI1\",\"MDRM1\",\"MISM1\",\"MLRF1\",\"MPCL1\",\"PILA2\",\"PILM4\",\"PLSF1\",\"POTA2\",\"PTAC1\",\"PTAT2\",\"SANF1\",\"SAUF1\",\"SBIO1\",\"SGNW3\",\"SGOF1\",\"SISW1\",\"SPGF1\",\"SRST2\",\"STDM4\",\"SUPN6\",\"SVLS1\",\"THIN6\",\"VENF1\",\"HBXC1\",\"MYXC1\",\"TDPC1\",\"FSTI2\",\"DMNO3\",\"GPTW1\",\"HMNO3\",\"PRTO3\",\"SEFO3\",\"SETO3\",\"SRAW1\",\"SRFW1\",\"TANO3\",\"ANMF1\",\"ARPF1\",\"BGCF1\",\"CAMF1\",\"CLBF1\",\"EGKF1\",\"NFBF1\",\"PTRF1\",\"SHPF1\",\"MBIN7\",\"MBNN7\",\"OCPN7\",\"BSCA1\",\"CRTA1\",\"DPHA1\",\"KATA1\",\"MBLA1\",\"MHPA1\",\"SACV4\",\"BBSF1\",\"BDVF1\",\"BKYF1\",\"BNKF1\",\"BOBF1\",\"BSKF1\",\"CNBF1\",\"CWAF1\",\"DKKF1\",\"GBIF1\",\"GBTF1\",\"GKYF1\",\"JBYF1\",\"JKYF1\",\"LBRF1\",\"LBSF1\",\"LMDF1\",\"LMRF1\",\"LSNF1\",\"MDKF1\",\"MNBF1\",\"MUKF1\",\"NRRF1\",\"PKYF1\",\"TCVF1\",\"THRF1\",\"TPEF1\",\"TRRF1\",\"WIWF1\",\"WPLF1\",\"APNM4\",\"CHII2\",\"MCYI3\",\"SRLM4\",\"SVNM4\",\"TBIM4\",\"THLO1\",\"LCIY2\",\"LLBP7\",\"FWIC3\",\"MISC3\",\"MISN6\",\"NCSC3\",\"NOSC3\",\"OFPN6\",\"ILDL1\",\"MRSL1\",\"SIPM6\",\"SLPL1\",\"LUML1\",\"TAML1\",\"AKXA2\",\"APMA2\",\"BEXA2\",\"CDXA2\",\"CPXA2\",\"DHXA2\",\"DPXA2\",\"ERXA2\",\"GBXA2\",\"GEXA2\",\"GIXA2\",\"GPXA2\",\"HMSA2\",\"ICYA2\",\"JLXA2\",\"JMLA2\",\"JNGA2\",\"KEXA2\",\"KNXA2\",\"KOZA2\",\"LIXA2\",\"MIXA2\",\"MRNA2\",\"MRYA2\",\"NKLA2\",\"NKXA2\",\"NLXA2\",\"NMXA2\",\"NSXA2\",\"PAUA2\",\"PEXA2\",\"PGXA2\",\"PPXA2\",\"PTLA2\",\"RIXA2\",\"SCXA2\",\"SIXA2\",\"SKXA2\",\"SLXA2\",\"SPXA2\",\"SRXA2\",\"STXA2\",\"SXXA2\",\"TKEA2\",\"TPXA2\",\"UQXA2\",\"VDXA2\",\"WCXA2\",\"MSG10\",\"MSG12\",\"ACQS1\",\"ACXS1\",\"ANMN6\",\"ANRN6\",\"APQF1\",\"APXA2\",\"BILW3\",\"BRIM2\",\"BSLM2\",\"BVQW1\",\"CHNO3\",\"CHQO3\",\"CWQT2\",\"DBQS1\",\"DEQD1\",\"DRSD1\",\"EAZC1\",\"EHSC1\",\"EVMC1\",\"FFFC1\",\"GBHM6\",\"GBQN3\",\"GBRM6\",\"GDQM6\",\"GGGC1\",\"GTQF1\",\"GTXF1\",\"HBMN6\",\"HMRA2\",\"HUQN6\",\"JCTN4\",\"JOBP4\",\"JOQP4\",\"JOXP4\",\"KCHA2\",\"LTQM2\",\"MIST2\",\"MQMT2\",\"MWQT2\",\"NAQR1\",\"NAXR1\",\"NIQS1\",\"NOXN7\",\"NPQN6\",\"NPXN6\",\"OWDO1\",\"OWQO1\",\"OWSO1\",\"PBLW1\",\"PKBW3\",\"RKQF1\",\"RKXF1\",\"RYEC1\",\"SAQG1\",\"SCQC1\",\"SCQN6\",\"SEQA2\",\"SFXC1\",\"SKQN6\",\"SLOO3\",\"TCSV2\",\"TIQC1\",\"TIXC1\",\"TKPN6\",\"WAQM3\",\"WAXM3\",\"WELM1\",\"WEQM1\",\"WEXM1\",\"WKQA1\",\"WKXA1\",\"WYBS1\",\"NLMA3\",\"SBBN2\",\"SLMN2\",\"BAXC1\",\"BDRN4\",\"BDSP1\",\"BGNN6\",\"BKBF1\",\"BLIF1\",\"BRND1\",\"CHCM2\",\"CHYV2\",\"COVM2\",\"CPMW1\",\"CPNW1\",\"CRYV2\",\"DELD1\",\"DMSF1\",\"DOMV2\",\"DPXC1\",\"EBEF1\",\"FMOA1\",\"FRVM3\",\"FRXM3\",\"FSKM2\",\"FSNM2\",\"GCTF1\",\"LNDC1\",\"LQAT2\",\"LTJF1\",\"MBPA1\",\"MCGA1\",\"MHBT2\",\"MRCP1\",\"MTBF1\",\"MZXC1\",\"NBLP1\",\"NFDF1\",\"NWHC3\",\"OMHC1\",\"OPTF1\",\"PDVR1\",\"PEGF1\",\"PFDC1\",\"PFXC1\",\"PPTM2\",\"PPXC1\",\"PRJC1\",\"PRUR1\",\"PSBC1\",\"PSXC1\",\"PTOA1\",\"PVDR1\",\"PXAC1\",\"PXOC1\",\"PXSC1\",\"QPTR1\",\"RPLV2\",\"RTYC1\",\"SEIM1\",\"SJSN4\",\"SKCF1\",\"SWPM4\",\"TCNW1\",\"TLVT2\",\"TPAF1\",\"TSHF1\",\"TXVT2\",\"UPBC1\",\"WDSV2\",\"ACYN4\",\"ADKA2\",\"AGCM4\",\"ALIA2\",\"ALXN6\",\"AMRL1\",\"APAM2\",\"APCF1\",\"APRP7\",\"ASTO3\",\"ATGM1\",\"ATKA2\",\"BEPB6\",\"BFTN7\",\"BHBM3\",\"BISM2\",\"BKTL1\",\"BLTM2\",\"BYGL1\",\"BZBM3\",\"CAMM2\",\"CAPL1\",\"CARL1\",\"CASM1\",\"CECC1\",\"CFWM1\",\"CHAO3\",\"CHAV3\",\"CHBV2\",\"CHSV3\",\"CHYW1\",\"CLBP4\",\"CMAN4\",\"CMTI2\",\"CNDO1\",\"CRVA2\",\"DILA1\",\"DKCM6\",\"DTLM4\",\"DUKN7\",\"DULM5\",\"EBSW1\",\"ERTF1\",\"ESPP4\",\"FAIO1\",\"FCGT2\",\"FMRF1\",\"FOXR1\",\"FPTT2\",\"FRCB6\",\"FRDF1\",\"FRDW1\",\"FREL1\",\"FRPS1\",\"FTPC1\",\"GBWW3\",\"GCVF1\",\"GDMM5\",\"GISL1\",\"GNJT2\",\"GTOT2\",\"GWPM6\",\"HBYC1\",\"HCGN7\",\"HLNM4\",\"HMDO3\",\"ICAC1\",\"IIWC1\",\"ILOH1\",\"ITKA2\",\"JMPN7\",\"JNEA2\",\"KECA2\",\"KGCA2\",\"KLIH1\",\"KPTN6\",\"KPTV2\",\"KWHH1\",\"KYWF1\",\"LABL1\",\"LAMV3\",\"LAPW1\",\"LCLL1\",\"LDTM4\",\"LOPW1\",\"LPNM4\",\"LTBV3\",\"LTRM4\",\"LWSD1\",\"LWTV2\",\"MBRM4\",\"MCGM4\",\"MCYF1\",\"MEYC1\",\"MGIP4\",\"MGZP4\",\"MOKH1\",\"MQTT2\",\"MRHO1\",\"MROS1\",\"MTKN6\",\"MTYC1\",\"NEAW1\",\"NIAN6\",\"NJLC1\",\"NKTA2\",\"NLNC3\",\"NMTA2\",\"NTBC1\",\"NTKM3\",\"NUET2\",\"NWCL1\",\"NWPR1\",\"NWWH1\",\"OCIM2\",\"OHBC1\",\"OLSA2\",\"OOUH1\",\"ORIN7\",\"OSGN6\",\"PCBF1\",\"PCLF1\",\"PCOC1\",\"PGBP7\",\"PHBP1\",\"PLXA2\",\"PNLM6\",\"PORO3\",\"PRDA2\",\"PRYC1\",\"PSBM1\",\"PSLC1\",\"PTAW1\",\"PTIM4\",\"PTIT2\",\"PTWW1\",\"RARM6\",\"RCKM4\",\"RCYF1\",\"RDDA2\",\"RDYD1\",\"SAPF1\",\"SBEO3\",\"SBLF1\",\"SDBC1\",\"SDHN4\",\"SHBL1\",\"SJNP4\",\"SKTA2\",\"SLIM2\",\"SNDP5\",\"SWLA2\",\"SWPV2\",\"TESL1\",\"THRO1\",\"TLBO3\",\"TRDF1\",\"TXPT2\",\"ULAM6\",\"ULRA2\",\"UNLA2\",\"VAKF1\",\"VDZA2\",\"WAHV2\",\"WAKP8\",\"WASD2\",\"WAVM6\",\"WLON7\",\"WPTW1\",\"WYCM6\",\"YATA2\",\"BLTA2\",\"CDEA2\",\"EROA2\",\"LCNA2\",\"PBPA2\",\"PRTA2\",\"SDIA2\",\"AGMW3\",\"BHRI3\",\"BIGM4\",\"BSBM4\",\"CBRW3\",\"CLSM4\",\"FPTM4\",\"GBLW3\",\"GRMM4\",\"GSLM4\",\"GTLM4\",\"GTRM4\",\"KP53\",\"KP58\",\"KP59\",\"LSCM4\",\"MEEM4\",\"NABM4\",\"PCLM4\",\"PNGW3\",\"PRIM4\",\"PSCM4\",\"PWAW3\",\"SBLM4\",\"SPTM4\",\"SXHW3\",\"SYWW3\",\"TAWM4\",\"WFPM4\",\"BARN6\",\"CBLO1\",\"CHDS1\",\"CMPO1\",\"GELO1\",\"HHLO1\",\"LORO1\",\"NREP1\",\"OLCN6\",\"RPRN6\",\"WATS1\",\"AUDP4\",\"FRDP4\",\"PLSP4\",\"VQSP4\",\"CGCL1\",\"SKMG1\",\"SPAG1\",\"AVAN4\",\"BRBN4\",\"OCGN4\",\"AWRT2\",\"BABT2\",\"BZST2\",\"CLLT2\",\"CPNT2\",\"EMAT2\",\"GRRT2\",\"HIST2\",\"IRDT2\",\"LUIT2\",\"LYBT2\",\"MGPT2\",\"NWST2\",\"PACT2\",\"PCGT2\",\"PCNT2\",\"PMNT2\",\"PORT2\",\"RSJT2\",\"RTAT2\",\"RTOT2\",\"SDRT2\",\"SGNT2\",\"TAQT2\",\"BTHD1\",\"FRFN7\",\"JPRN7\",\"18CI3\",\"20CM4\",\"GDIV2\",\"32ST0\",\"41NT0\"]\nbuoy_ids = ids\nbuoy_ids_with_cameras = [] # blank list to store buoy ids with cameras",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "ids",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "ids = [\"21414\",\"21415\",\"21416\",\"21417\",\"21418\",\"21419\",\"32301\",\"32302\",\"32411\",\"32412\",\"32413\",\"41001\",\"41002\",\"41003\",\"41004\",\"41007\",\"41008\",\"41009\",\"41010\",\"41011\",\"41012\",\"41016\",\"41017\",\"41018\",\"41021\",\"41022\",\"41023\",\"41036\",\"41040\",\"41041\",\"41043\",\"41044\",\"41046\",\"41049\",\"41420\",\"41421\",\"41424\",\"41425\",\"42001\",\"42002\",\"42003\",\"42004\",\"42007\",\"42008\",\"42009\",\"42010\",\"42011\",\"42012\",\"42017\",\"42018\",\"42019\",\"42020\",\"42025\",\"42035\",\"42038\",\"42039\",\"42040\",\"42041\",\"42042\",\"42053\",\"42056\",\"42057\",\"42058\",\"42059\",\"42060\",\"42065\",\"42408\",\"42409\",\"42429\",\"42501\",\"42503\",\"42534\",\"44001\",\"44003\",\"44004\",\"44005\",\"44006\",\"44007\",\"44010\",\"44011\",\"44012\",\"44013\",\"44014\",\"44015\",\"44019\",\"44020\",\"44023\",\"44025\",\"44026\",\"44027\",\"44066\",\"44070\",\"44071\",\"44401\",\"44402\",\"44403\",\"45002\",\"45003\",\"45004\",\"45005\",\"45006\",\"45007\",\"45010\",\"45011\",\"45012\",\"46001\",\"46002\",\"46003\",\"46007\",\"46008\",\"46009\",\"46010\",\"46011\",\"46012\",\"46015\",\"46016\",\"46017\",\"46018\",\"46019\",\"46020\",\"46023\",\"46024\",\"46025\",\"46026\",\"46027\",\"46028\",\"46031\",\"46032\",\"46033\",\"46034\",\"46035\",\"46037\",\"46040\",\"46041\",\"46042\",\"46043\",\"46045\",\"46047\",\"46051\",\"46053\",\"46054\",\"46059\",\"46060\",\"46061\",\"46066\",\"46069\",\"46070\",\"46071\",\"46072\",\"46073\",\"46077\",\"46078\",\"46079\",\"46080\",\"46081\",\"46082\",\"46085\",\"46086\",\"46087\",\"46088\",\"46089\",\"46090\",\"46107\",\"46115\",\"46270\",\"46290\",\"46401\",\"46402\",\"46405\",\"46406\",\"46407\",\"46408\",\"46409\",\"46410\",\"46413\",\"46414\",\"46415\",\"46416\",\"46419\",\"46490\",\"46779\",\"46780\",\"46781\",\"46782\",\"46785\",\"51000\",\"51001\",\"51002\",\"51003\",\"51004\",\"51005\",\"51028\",\"51100\",\"51101\",\"51406\",\"51407\",\"51425\",\"52009\",\"52401\",\"52402\",\"52403\",\"52404\",\"52405\",\"91204\",\"91222\",\"91251\",\"91328\",\"91338\",\"91343\",\"91356\",\"91365\",\"91374\",\"91377\",\"91411\",\"91442\",\"46265\",\"41670\",\"41852\",\"41904\",\"41933\",\"48916\",\"48917\",\"52838\",\"52839\",\"52840\",\"52841\",\"52842\",\"52843\",\"52862\",\"55012\",\"55013\",\"55015\",\"55016\",\"55023\",\"55042\",\"58952\",\"31052\",\"31053\",\"41052\",\"41053\",\"41056\",\"41058\",\"41115\",\"41121\",\"41030\",\"44042\",\"44043\",\"44057\",\"44058\",\"44059\",\"44061\",\"44064\",\"44068\",\"45016\",\"45017\",\"45018\",\"45019\",\"45177\",\"45202\",\"45203\",\"45204\",\"45205\",\"45206\",\"45207\",\"46116\",\"46117\",\"46127\",\"42014\",\"42021\",\"42022\",\"42023\",\"42024\",\"42026\",\"32404\",\"41029\",\"41033\",\"41037\",\"41038\",\"41064\",\"41065\",\"41110\",\"41119\",\"41159\",\"32488\",\"41193\",\"44138\",\"44139\",\"44140\",\"44141\",\"44142\",\"44150\",\"44176\",\"44235\",\"44251\",\"44255\",\"44258\",\"44488\",\"45132\",\"45135\",\"45136\",\"45137\",\"45138\",\"45139\",\"45142\",\"45143\",\"45144\",\"45145\",\"45147\",\"45148\",\"45151\",\"45152\",\"45154\",\"45155\",\"45158\",\"45159\",\"46036\",\"46131\",\"46132\",\"46084\",\"46134\",\"46138\",\"46139\",\"46147\",\"46181\",\"46183\",\"46184\",\"46185\",\"46204\",\"46207\",\"46208\",\"46303\",\"46304\",\"48021\",\"45162\",\"45163\",\"45195\",\"23219\",\"23227\",\"32067\",\"32068\",\"42087\",\"42088\",\"42089\",\"42090\",\"46109\",\"46110\",\"46111\",\"46112\",\"21346\",\"21347\",\"21348\",\"21595\",\"21597\",\"21598\",\"21637\",\"21640\",\"22102\",\"22103\",\"22104\",\"22105\",\"22106\",\"22107\",\"45029\",\"45164\",\"45165\",\"45168\",\"45169\",\"45176\",\"46091\",\"46092\",\"62091\",\"62092\",\"62093\",\"62094\",\"41097\",\"41098\",\"41100\",\"41101\",\"41300\",\"61001\",\"45025\",\"45175\",\"44039\",\"44040\",\"44060\",\"23220\",\"23223\",\"23225\",\"46261\",\"46263\",\"48901\",\"48908\",\"48909\",\"48912\",\"44024\",\"44029\",\"44030\",\"44031\",\"44032\",\"44033\",\"44036\",\"44037\",\"45172\",\"45173\",\"46118\",\"46119\",\"46531\",\"46534\",\"46538\",\"46565\",\"44075\",\"44076\",\"44077\",\"44078\",\"46097\",\"46098\",\"51046\",\"51201\",\"51202\",\"51203\",\"51204\",\"51205\",\"51208\",\"51209\",\"51210\",\"51211\",\"51212\",\"51213\",\"52202\",\"52211\",\"13002\",\"13008\",\"13009\",\"13010\",\"15001\",\"15002\",\"31001\",\"31002\",\"31003\",\"31004\",\"31005\",\"31006\",\"62121\",\"62124\",\"62125\",\"62126\",\"62127\",\"62130\",\"62144\",\"62145\",\"62146\",\"62147\",\"62148\",\"62149\",\"62165\",\"62166\",\"63105\",\"63110\",\"63112\",\"63113\",\"14041\",\"14043\",\"14047\",\"23001\",\"23003\",\"23004\",\"23008\",\"23009\",\"23010\",\"23011\",\"23012\",\"23013\",\"23016\",\"23017\",\"53005\",\"53006\",\"53009\",\"53040\",\"56053\",\"01506\",\"01507\",\"01518\",\"01537\",\"48904\",\"48907\",\"01521\",\"01522\",\"01523\",\"01524\",\"01526\",\"01531\",\"01535\",\"01536\",\"01538\",\"01909\",\"01910\",\"31201\",\"41112\",\"41113\",\"41114\",\"41116\",\"41118\",\"41120\",\"42084\",\"42091\",\"42094\",\"42099\",\"44088\",\"44094\",\"44099\",\"44100\",\"44172\",\"46114\",\"46211\",\"46212\",\"46215\",\"46216\",\"46217\",\"46218\",\"46219\",\"46220\",\"46223\",\"46224\",\"46225\",\"46226\",\"46227\",\"46228\",\"46231\",\"46232\",\"46234\",\"46235\",\"46236\",\"46237\",\"46240\",\"46241\",\"46242\",\"46243\",\"46244\",\"46245\",\"46249\",\"46250\",\"46251\",\"46253\",\"46254\",\"46256\",\"46262\",\"46267\",\"46268\",\"46269\",\"46273\",\"46274\",\"51200\",\"48212\",\"48213\",\"48214\",\"48677\",\"48678\",\"48679\",\"48680\",\"48911\",\"42044\",\"42045\",\"42046\",\"42047\",\"42048\",\"42049\",\"42078\",\"42079\",\"42093\",\"42095\",\"42097\",\"44056\",\"45180\",\"46259\",\"46266\",\"62028\",\"62029\",\"62030\",\"62050\",\"62081\",\"62103\",\"62108\",\"62163\",\"62170\",\"62298\",\"62301\",\"62303\",\"62442\",\"64045\",\"44098\",\"46121\",\"46122\",\"46123\",\"46124\",\"28902\",\"28903\",\"28904\",\"28906\",\"28907\",\"28908\",\"58900\",\"58902\",\"58903\",\"58904\",\"58905\",\"58906\",\"58909\",\"68900\",\"78900\",\"45014\",\"45184\",\"44053\",\"01517\",\"32012\",\"41060\",\"41061\",\"21D20\",\"32D12\",\"32D13\",\"41A46\",\"41S43\",\"41S46\",\"46B35\",\"ALSN6\",\"AMAA2\",\"AUGA2\",\"BLIA2\",\"BURL1\",\"BUSL1\",\"CDRF1\",\"CHLV2\",\"CLKN7\",\"CSBF1\",\"DBLN6\",\"DESW1\",\"DRFA2\",\"DRYF1\",\"DSLN7\",\"DUCN7\",\"EB01\",\"EB10\",\"EB33\",\"EB35\",\"EB36\",\"EB43\",\"EB52\",\"EB53\",\"EB70\",\"EB90\",\"EB91\",\"EB92\",\"FARP2\",\"FBIS1\",\"FPSN7\",\"FWYF1\",\"GBCL1\",\"GDIL1\",\"GLLN6\",\"IOSN3\",\"LONF1\",\"LPOI1\",\"MDRM1\",\"MISM1\",\"MLRF1\",\"MPCL1\",\"PILA2\",\"PILM4\",\"PLSF1\",\"POTA2\",\"PTAC1\",\"PTAT2\",\"SANF1\",\"SAUF1\",\"SBIO1\",\"SGNW3\",\"SGOF1\",\"SISW1\",\"SPGF1\",\"SRST2\",\"STDM4\",\"SUPN6\",\"SVLS1\",\"THIN6\",\"VENF1\",\"HBXC1\",\"MYXC1\",\"TDPC1\",\"FSTI2\",\"DMNO3\",\"GPTW1\",\"HMNO3\",\"PRTO3\",\"SEFO3\",\"SETO3\",\"SRAW1\",\"SRFW1\",\"TANO3\",\"ANMF1\",\"ARPF1\",\"BGCF1\",\"CAMF1\",\"CLBF1\",\"EGKF1\",\"NFBF1\",\"PTRF1\",\"SHPF1\",\"MBIN7\",\"MBNN7\",\"OCPN7\",\"BSCA1\",\"CRTA1\",\"DPHA1\",\"KATA1\",\"MBLA1\",\"MHPA1\",\"SACV4\",\"BBSF1\",\"BDVF1\",\"BKYF1\",\"BNKF1\",\"BOBF1\",\"BSKF1\",\"CNBF1\",\"CWAF1\",\"DKKF1\",\"GBIF1\",\"GBTF1\",\"GKYF1\",\"JBYF1\",\"JKYF1\",\"LBRF1\",\"LBSF1\",\"LMDF1\",\"LMRF1\",\"LSNF1\",\"MDKF1\",\"MNBF1\",\"MUKF1\",\"NRRF1\",\"PKYF1\",\"TCVF1\",\"THRF1\",\"TPEF1\",\"TRRF1\",\"WIWF1\",\"WPLF1\",\"APNM4\",\"CHII2\",\"MCYI3\",\"SRLM4\",\"SVNM4\",\"TBIM4\",\"THLO1\",\"LCIY2\",\"LLBP7\",\"FWIC3\",\"MISC3\",\"MISN6\",\"NCSC3\",\"NOSC3\",\"OFPN6\",\"ILDL1\",\"MRSL1\",\"SIPM6\",\"SLPL1\",\"LUML1\",\"TAML1\",\"AKXA2\",\"APMA2\",\"BEXA2\",\"CDXA2\",\"CPXA2\",\"DHXA2\",\"DPXA2\",\"ERXA2\",\"GBXA2\",\"GEXA2\",\"GIXA2\",\"GPXA2\",\"HMSA2\",\"ICYA2\",\"JLXA2\",\"JMLA2\",\"JNGA2\",\"KEXA2\",\"KNXA2\",\"KOZA2\",\"LIXA2\",\"MIXA2\",\"MRNA2\",\"MRYA2\",\"NKLA2\",\"NKXA2\",\"NLXA2\",\"NMXA2\",\"NSXA2\",\"PAUA2\",\"PEXA2\",\"PGXA2\",\"PPXA2\",\"PTLA2\",\"RIXA2\",\"SCXA2\",\"SIXA2\",\"SKXA2\",\"SLXA2\",\"SPXA2\",\"SRXA2\",\"STXA2\",\"SXXA2\",\"TKEA2\",\"TPXA2\",\"UQXA2\",\"VDXA2\",\"WCXA2\",\"MSG10\",\"MSG12\",\"ACQS1\",\"ACXS1\",\"ANMN6\",\"ANRN6\",\"APQF1\",\"APXA2\",\"BILW3\",\"BRIM2\",\"BSLM2\",\"BVQW1\",\"CHNO3\",\"CHQO3\",\"CWQT2\",\"DBQS1\",\"DEQD1\",\"DRSD1\",\"EAZC1\",\"EHSC1\",\"EVMC1\",\"FFFC1\",\"GBHM6\",\"GBQN3\",\"GBRM6\",\"GDQM6\",\"GGGC1\",\"GTQF1\",\"GTXF1\",\"HBMN6\",\"HMRA2\",\"HUQN6\",\"JCTN4\",\"JOBP4\",\"JOQP4\",\"JOXP4\",\"KCHA2\",\"LTQM2\",\"MIST2\",\"MQMT2\",\"MWQT2\",\"NAQR1\",\"NAXR1\",\"NIQS1\",\"NOXN7\",\"NPQN6\",\"NPXN6\",\"OWDO1\",\"OWQO1\",\"OWSO1\",\"PBLW1\",\"PKBW3\",\"RKQF1\",\"RKXF1\",\"RYEC1\",\"SAQG1\",\"SCQC1\",\"SCQN6\",\"SEQA2\",\"SFXC1\",\"SKQN6\",\"SLOO3\",\"TCSV2\",\"TIQC1\",\"TIXC1\",\"TKPN6\",\"WAQM3\",\"WAXM3\",\"WELM1\",\"WEQM1\",\"WEXM1\",\"WKQA1\",\"WKXA1\",\"WYBS1\",\"NLMA3\",\"SBBN2\",\"SLMN2\",\"BAXC1\",\"BDRN4\",\"BDSP1\",\"BGNN6\",\"BKBF1\",\"BLIF1\",\"BRND1\",\"CHCM2\",\"CHYV2\",\"COVM2\",\"CPMW1\",\"CPNW1\",\"CRYV2\",\"DELD1\",\"DMSF1\",\"DOMV2\",\"DPXC1\",\"EBEF1\",\"FMOA1\",\"FRVM3\",\"FRXM3\",\"FSKM2\",\"FSNM2\",\"GCTF1\",\"LNDC1\",\"LQAT2\",\"LTJF1\",\"MBPA1\",\"MCGA1\",\"MHBT2\",\"MRCP1\",\"MTBF1\",\"MZXC1\",\"NBLP1\",\"NFDF1\",\"NWHC3\",\"OMHC1\",\"OPTF1\",\"PDVR1\",\"PEGF1\",\"PFDC1\",\"PFXC1\",\"PPTM2\",\"PPXC1\",\"PRJC1\",\"PRUR1\",\"PSBC1\",\"PSXC1\",\"PTOA1\",\"PVDR1\",\"PXAC1\",\"PXOC1\",\"PXSC1\",\"QPTR1\",\"RPLV2\",\"RTYC1\",\"SEIM1\",\"SJSN4\",\"SKCF1\",\"SWPM4\",\"TCNW1\",\"TLVT2\",\"TPAF1\",\"TSHF1\",\"TXVT2\",\"UPBC1\",\"WDSV2\",\"ACYN4\",\"ADKA2\",\"AGCM4\",\"ALIA2\",\"ALXN6\",\"AMRL1\",\"APAM2\",\"APCF1\",\"APRP7\",\"ASTO3\",\"ATGM1\",\"ATKA2\",\"BEPB6\",\"BFTN7\",\"BHBM3\",\"BISM2\",\"BKTL1\",\"BLTM2\",\"BYGL1\",\"BZBM3\",\"CAMM2\",\"CAPL1\",\"CARL1\",\"CASM1\",\"CECC1\",\"CFWM1\",\"CHAO3\",\"CHAV3\",\"CHBV2\",\"CHSV3\",\"CHYW1\",\"CLBP4\",\"CMAN4\",\"CMTI2\",\"CNDO1\",\"CRVA2\",\"DILA1\",\"DKCM6\",\"DTLM4\",\"DUKN7\",\"DULM5\",\"EBSW1\",\"ERTF1\",\"ESPP4\",\"FAIO1\",\"FCGT2\",\"FMRF1\",\"FOXR1\",\"FPTT2\",\"FRCB6\",\"FRDF1\",\"FRDW1\",\"FREL1\",\"FRPS1\",\"FTPC1\",\"GBWW3\",\"GCVF1\",\"GDMM5\",\"GISL1\",\"GNJT2\",\"GTOT2\",\"GWPM6\",\"HBYC1\",\"HCGN7\",\"HLNM4\",\"HMDO3\",\"ICAC1\",\"IIWC1\",\"ILOH1\",\"ITKA2\",\"JMPN7\",\"JNEA2\",\"KECA2\",\"KGCA2\",\"KLIH1\",\"KPTN6\",\"KPTV2\",\"KWHH1\",\"KYWF1\",\"LABL1\",\"LAMV3\",\"LAPW1\",\"LCLL1\",\"LDTM4\",\"LOPW1\",\"LPNM4\",\"LTBV3\",\"LTRM4\",\"LWSD1\",\"LWTV2\",\"MBRM4\",\"MCGM4\",\"MCYF1\",\"MEYC1\",\"MGIP4\",\"MGZP4\",\"MOKH1\",\"MQTT2\",\"MRHO1\",\"MROS1\",\"MTKN6\",\"MTYC1\",\"NEAW1\",\"NIAN6\",\"NJLC1\",\"NKTA2\",\"NLNC3\",\"NMTA2\",\"NTBC1\",\"NTKM3\",\"NUET2\",\"NWCL1\",\"NWPR1\",\"NWWH1\",\"OCIM2\",\"OHBC1\",\"OLSA2\",\"OOUH1\",\"ORIN7\",\"OSGN6\",\"PCBF1\",\"PCLF1\",\"PCOC1\",\"PGBP7\",\"PHBP1\",\"PLXA2\",\"PNLM6\",\"PORO3\",\"PRDA2\",\"PRYC1\",\"PSBM1\",\"PSLC1\",\"PTAW1\",\"PTIM4\",\"PTIT2\",\"PTWW1\",\"RARM6\",\"RCKM4\",\"RCYF1\",\"RDDA2\",\"RDYD1\",\"SAPF1\",\"SBEO3\",\"SBLF1\",\"SDBC1\",\"SDHN4\",\"SHBL1\",\"SJNP4\",\"SKTA2\",\"SLIM2\",\"SNDP5\",\"SWLA2\",\"SWPV2\",\"TESL1\",\"THRO1\",\"TLBO3\",\"TRDF1\",\"TXPT2\",\"ULAM6\",\"ULRA2\",\"UNLA2\",\"VAKF1\",\"VDZA2\",\"WAHV2\",\"WAKP8\",\"WASD2\",\"WAVM6\",\"WLON7\",\"WPTW1\",\"WYCM6\",\"YATA2\",\"BLTA2\",\"CDEA2\",\"EROA2\",\"LCNA2\",\"PBPA2\",\"PRTA2\",\"SDIA2\",\"AGMW3\",\"BHRI3\",\"BIGM4\",\"BSBM4\",\"CBRW3\",\"CLSM4\",\"FPTM4\",\"GBLW3\",\"GRMM4\",\"GSLM4\",\"GTLM4\",\"GTRM4\",\"KP53\",\"KP58\",\"KP59\",\"LSCM4\",\"MEEM4\",\"NABM4\",\"PCLM4\",\"PNGW3\",\"PRIM4\",\"PSCM4\",\"PWAW3\",\"SBLM4\",\"SPTM4\",\"SXHW3\",\"SYWW3\",\"TAWM4\",\"WFPM4\",\"BARN6\",\"CBLO1\",\"CHDS1\",\"CMPO1\",\"GELO1\",\"HHLO1\",\"LORO1\",\"NREP1\",\"OLCN6\",\"RPRN6\",\"WATS1\",\"AUDP4\",\"FRDP4\",\"PLSP4\",\"VQSP4\",\"CGCL1\",\"SKMG1\",\"SPAG1\",\"AVAN4\",\"BRBN4\",\"OCGN4\",\"AWRT2\",\"BABT2\",\"BZST2\",\"CLLT2\",\"CPNT2\",\"EMAT2\",\"GRRT2\",\"HIST2\",\"IRDT2\",\"LUIT2\",\"LYBT2\",\"MGPT2\",\"NWST2\",\"PACT2\",\"PCGT2\",\"PCNT2\",\"PMNT2\",\"PORT2\",\"RSJT2\",\"RTAT2\",\"RTOT2\",\"SDRT2\",\"SGNT2\",\"TAQT2\",\"BTHD1\",\"FRFN7\",\"JPRN7\",\"18CI3\",\"20CM4\",\"GDIV2\",\"32ST0\",\"41NT0\"]\nbuoy_ids = ids\nbuoy_ids_with_cameras = [] # blank list to store buoy ids with cameras\n# %%\n# Loop through the buoy ids\nfor buoy_id in tqdm(buoy_ids):\n    # if the page text needs to be retrieved then do so, else pull from the text files\n    if not os.path.exists('data/buoy_pages/{}.txt'.format(buoy_id)):\n        # get the page text\n        time.sleep(1)",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "buoy_ids",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "buoy_ids = ids\nbuoy_ids_with_cameras = [] # blank list to store buoy ids with cameras\n# %%\n# Loop through the buoy ids\nfor buoy_id in tqdm(buoy_ids):\n    # if the page text needs to be retrieved then do so, else pull from the text files\n    if not os.path.exists('data/buoy_pages/{}.txt'.format(buoy_id)):\n        # get the page text\n        time.sleep(1)\n        page = requests.get('https://www.ndbc.noaa.gov/station_page.php?station={}'.format(buoy_id))",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "buoy_ids_with_cameras",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "buoy_ids_with_cameras = [] # blank list to store buoy ids with cameras\n# %%\n# Loop through the buoy ids\nfor buoy_id in tqdm(buoy_ids):\n    # if the page text needs to be retrieved then do so, else pull from the text files\n    if not os.path.exists('data/buoy_pages/{}.txt'.format(buoy_id)):\n        # get the page text\n        time.sleep(1)\n        page = requests.get('https://www.ndbc.noaa.gov/station_page.php?station={}'.format(buoy_id))\n        # write the page text to a file",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "cam_buoys",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "cam_buoys = [] # blank list to store buoy ids with cameras\n# %%\n# Purpose: parse the page text to get the camera urls and save them to a file. The page is parsed using BeautifulSoup and the camera urls are extracted using regular expressions.\n# only do this once to get the camera urls and save them to a file for later use\n# if the file does not exist then do so, else pull from the file\n#note: uncomment below if error but it takes forever.\n# if not os.path.exists('data/cam_buoys.txt'):\n#     # open each buoy page text file in data/buoy_pages and parse the page text\n#     for buoy_page in tqdm(os.listdir('data/buoy_pages')):\n#         with open('data/buoy_pages/{}'.format(buoy_page), 'r') as f:",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "#cam_buoys",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "#cam_buoys = pd.read_csv('data/buoys.csv') # read the cam_buoys from data/buoys.csv\n# %%\n# Purpose: get the camera urls from the buoy pages and save them to a file\n# open each buoy page text file in data/buoy_pages and parse the page text to get the camera urls\n# print(f'Found {len(cam_buoys)} buoys with functional cameras.')\n# # save them to the file data/buoys.csv\n# with open('data/buoys.csv', 'w+') as f:\n#     f.write(\"'buoy_id',\\n\") # could add lat and lng later\n#     for buoy_id in cam_buoys: # loop through the buoy ids with cameras\n#         f.write('{},\\n'.format(buoy_id)) # write the buoy id to the file",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "cam_urls",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "cam_urls = pd.read_csv('data/camera_urls.csv') # read the cam_buoys from data/buoys.csv\ncam_buoys = pd.read_csv('data/buoy_ids_with_cameras.txt') # read the cam_buoys from data/buoys.csv\n# %%\ndef panel_sorter():\n    # Go into each panel directory and sort the images into folders by the date in their filename (if they haven't already been sorted)\n    # example unsorted directory: 'images/panels/46078/2022_11_5_15_44_panel_1.png'\n    # example sorted directory: images/panels/51000/2022_11_5_15_44/panel_1.png\n    for buoy_id in os.listdir('images/panels'):\n        if buoy_id != '.DS_Store' and '.' not in buoy_id:\n            for image in os.listdir('images/panels/{}'.format(buoy_id)):",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "cam_buoys",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "cam_buoys = pd.read_csv('data/buoy_ids_with_cameras.txt') # read the cam_buoys from data/buoys.csv\n# %%\ndef panel_sorter():\n    # Go into each panel directory and sort the images into folders by the date in their filename (if they haven't already been sorted)\n    # example unsorted directory: 'images/panels/46078/2022_11_5_15_44_panel_1.png'\n    # example sorted directory: images/panels/51000/2022_11_5_15_44/panel_1.png\n    for buoy_id in os.listdir('images/panels'):\n        if buoy_id != '.DS_Store' and '.' not in buoy_id:\n            for image in os.listdir('images/panels/{}'.format(buoy_id)):\n                if image != '.DS_Store' and '.' not in image:",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "buoy_update_rates_dict",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "buoy_update_rates_dict = {} # blank dictionary to store the update rates for each buoy (i.e. how often the buoy takes a picture (measured in seconds))\n# fill the dictionary with blank update rate arrays for each buoy.\n# these arrays will be averaged to get the average update rate for each buoy in real time.\nfor buoy_id in cam_buoys:\n    buoy_update_rates_dict[buoy_id] = 1 # set the initial update rate to 600 seconds (10 minutes)\n# %%\ndef image_has_changed(image_one,image_two):\n    # looks for changes between two images and returns True if there are changes and False if there are not.\n    # this function is used to determine what rate the images are being updated for each buoy.\n    # if the images are not changing, then the buoy is not updating the images.",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "buoy_update_rates_dict",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "buoy_update_rates_dict = {'46025': [600, datetime.datetime.now()]}\nprint(check_for_updates(buoy_update_rates_dict)) # should return an empty list\n# wait 10 seconds\ntime.sleep(10)\nprint(check_for_updates(buoy_update_rates_dict)) # should return ['46025']\n# %%\n# import shutil\n# from difPy import dif\n# # go through each buoy and check if there are duplicated images in the images/buoys folder\n# for folder in os.listdir('images/buoys'):",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "iteration_counter",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "iteration_counter = 0\nvincent = Artist() # create an instance of the Artist class\n# %%\n# print('Starting the download loop')\n# last_time_fetched = time.time() # get the current time\n# first_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\n# while True:\n#     try:\n#         # turn on at 4 am CST and turn off at 11 pm CST\n#         if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "vincent",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "vincent = Artist() # create an instance of the Artist class\n# %%\n# print('Starting the download loop')\n# last_time_fetched = time.time() # get the current time\n# first_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\n# while True:\n#     try:\n#         # turn on at 4 am CST and turn off at 11 pm CST\n#         if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm\n#             # wait to turn on until 4 am CST",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "#path",
        "kind": 5,
        "importPath": "old_files.cam_backend",
        "description": "old_files.cam_backend",
        "peekOfCode": "#path = 'images/panels/46066/2022_11_5_15_45/2022_11_5_15_45_panel_1.png'\n#print(is_it_daytime(path))",
        "detail": "old_files.cam_backend",
        "documentation": {}
    },
    {
        "label": "Artist",
        "kind": 6,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "class Artist:\n    def __init__(self):\n        self.folder = 'images'\n    def make_panorama(self, images):\n        # this function will take a list of images and make a panorama out of them\n        # resize image\n        scale_percent = 70 # percent of original size\n        images = [cv2.resize(images[i], (int(images[i].shape[1]*scale_percent/100), int(images[i].shape[0]*scale_percent/100)), interpolation= cv2.INTER_AREA) for i in range(len(images))]\n        # create a list of the images\n        # print('Making a panorama...')",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "panel_sorter",
        "kind": 2,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "def panel_sorter():\n    # Go into each panel directory and sort the images into folders by the date in their filename (if they haven't already been sorted)\n    # example unsorted directory: 'images/panels/46078/2022_11_5_15_44_panel_1.png'\n    # example sorted directory: images/panels/51000/2022_11_5_15_44/panel_1.png\n    for buoy_id in os.listdir('images/panels'):\n        if buoy_id != '.DS_Store' and '.' not in buoy_id:\n            for image in os.listdir('images/panels/{}'.format(buoy_id)):\n                if image != '.DS_Store' and '.' not in image:\n                    try:\n                        # find the 2022_11_5_15_44 (#_#_#_#_#) part of the filename and make a new folder with that name.",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "divide_into_panels",
        "kind": 2,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "def divide_into_panels(buoy_id, image_file):\n    # divide the image into six panels, as dictated in the image processing pipeline for NOAA Buoy Cameras Comments above.\n    # read the image\n    img = cv2.imread(image_file)\n    # get the name of the image file\n    image_name = image_file.split('/')[-1]\n    # get the dimensions of the image\n    height, width, channels = img.shape\n    # Before dividing into panels, crop the image to remove 30 pixels from the bottom of the image.\n    # This is to remove the \"Buoy Camera\" text from the image.",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "is_it_daytime",
        "kind": 2,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "def is_it_daytime(image_path):\n    # This function will take an image path and return True if it is daytime and False if it is nighttime.\n    # The image path should be a string.\n    # The image path should be the path to the image that was used to create the panels.\n    # The image path should be in the format 'images/buoys/46025/2019_12_12_12_12.jpg'\n    # get the image\n    img = Image.open(image_path)\n    # get the image size\n    width, height = img.size\n    # get the pixel values for the center of the image",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "image_has_changed",
        "kind": 2,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "def image_has_changed(image_one,image_two):\n    # looks for changes between two images and returns True if there are changes and False if there are not.\n    # this function is used to determine what rate the images are being updated for each buoy.\n    # if the images are not changing, then the buoy is not updating the images.\n    # if the images are changing, then the buoy is updating the images.\n    try:\n        image_one = cv2.imread(image_one)\n        image_two = cv2.imread(image_two)\n        difference = cv2.subtract(image_one, image_two)\n        result = not np.any(difference)",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "artist_eval",
        "kind": 2,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "def artist_eval(image_path):\n    # get the image\n    img = Image.open(image_path)\n    # get the image size\n    width, height = img.size\n    # get the pixel values for the center of the image\n    pixel_values = img.getpixel((int(width/2), int(height/2)))\n    # get the pixel values for the top left corner of the image\n    upper_left = img.getpixel((0, 0))\n    # get the pixel values for the top right corner of the image",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "check_for_updates",
        "kind": 2,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "def check_for_updates(buoy_update_rates_dict):\n    # Check the buoy_update_rates_dict to see if any of the buoys satistfy the update rate requirements:\n    # Requirements: the current time minus the last time we downloaded an image for this buoy must be greater than the update rate for this buoy. If it is, then we will add the buoy id to the list of buoys that need to be updated and return it to the main function.\n    # If the buoy_update_rates_dict is empty, then we will return an empty list.\n    # If the buoy_update_rates_dict is not empty, then we will check the update rates for each buoy and return a list of the buoy ids that need to be updated.\n    if len(buoy_update_rates_dict) == 0:\n        return []\n    else:\n        buoys_to_update = []\n        for buoy_id in buoy_update_rates_dict:",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "get_latest_data",
        "kind": 2,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "def get_latest_data():\n    url = \"https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt\"\n    s=requests.get(url).content\n    # the table contains two rows that have header data. combine them into one row.\n    df = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\\s+')\n    df.columns = df.columns.str.strip()\n    # df = df.dropna(axis=1, how='all')\n    # df = df.dropna(axis=0, how='all')\n    # df = df.dropna(axis=0, how='any')\n    # df = df.reset_index(drop=True)",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "cam_buoys",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "cam_buoys = []\n# %%\n# Set up #logging file\n#logging.basicConfig(filename='cam_finder.log', level=#logging.INFO)\n# %% [markdown]\n# Stage One\n# %%\nids = [\"21414\",\"21415\",\"21416\",\"21417\",\"21418\",\"21419\",\"32301\",\"32302\",\"32411\",\"32412\",\"32413\",\"41001\",\"41002\",\"41003\",\"41004\",\"41007\",\"41008\",\"41009\",\"41010\",\"41011\",\"41012\",\"41016\",\"41017\",\"41018\",\"41021\",\"41022\",\"41023\",\"41036\",\"41040\",\"41041\",\"41043\",\"41044\",\"41046\",\"41049\",\"41420\",\"41421\",\"41424\",\"41425\",\"42001\",\"42002\",\"42003\",\"42004\",\"42007\",\"42008\",\"42009\",\"42010\",\"42011\",\"42012\",\"42017\",\"42018\",\"42019\",\"42020\",\"42025\",\"42035\",\"42038\",\"42039\",\"42040\",\"42041\",\"42042\",\"42053\",\"42056\",\"42057\",\"42058\",\"42059\",\"42060\",\"42065\",\"42408\",\"42409\",\"42429\",\"42501\",\"42503\",\"42534\",\"44001\",\"44003\",\"44004\",\"44005\",\"44006\",\"44007\",\"44010\",\"44011\",\"44012\",\"44013\",\"44014\",\"44015\",\"44019\",\"44020\",\"44023\",\"44025\",\"44026\",\"44027\",\"44066\",\"44070\",\"44071\",\"44401\",\"44402\",\"44403\",\"45002\",\"45003\",\"45004\",\"45005\",\"45006\",\"45007\",\"45010\",\"45011\",\"45012\",\"46001\",\"46002\",\"46003\",\"46007\",\"46008\",\"46009\",\"46010\",\"46011\",\"46012\",\"46015\",\"46016\",\"46017\",\"46018\",\"46019\",\"46020\",\"46023\",\"46024\",\"46025\",\"46026\",\"46027\",\"46028\",\"46031\",\"46032\",\"46033\",\"46034\",\"46035\",\"46037\",\"46040\",\"46041\",\"46042\",\"46043\",\"46045\",\"46047\",\"46051\",\"46053\",\"46054\",\"46059\",\"46060\",\"46061\",\"46066\",\"46069\",\"46070\",\"46071\",\"46072\",\"46073\",\"46077\",\"46078\",\"46079\",\"46080\",\"46081\",\"46082\",\"46085\",\"46086\",\"46087\",\"46088\",\"46089\",\"46090\",\"46107\",\"46115\",\"46270\",\"46290\",\"46401\",\"46402\",\"46405\",\"46406\",\"46407\",\"46408\",\"46409\",\"46410\",\"46413\",\"46414\",\"46415\",\"46416\",\"46419\",\"46490\",\"46779\",\"46780\",\"46781\",\"46782\",\"46785\",\"51000\",\"51001\",\"51002\",\"51003\",\"51004\",\"51005\",\"51028\",\"51100\",\"51101\",\"51406\",\"51407\",\"51425\",\"52009\",\"52401\",\"52402\",\"52403\",\"52404\",\"52405\",\"91204\",\"91222\",\"91251\",\"91328\",\"91338\",\"91343\",\"91356\",\"91365\",\"91374\",\"91377\",\"91411\",\"91442\",\"46265\",\"41670\",\"41852\",\"41904\",\"41933\",\"48916\",\"48917\",\"52838\",\"52839\",\"52840\",\"52841\",\"52842\",\"52843\",\"52862\",\"55012\",\"55013\",\"55015\",\"55016\",\"55023\",\"55042\",\"58952\",\"31052\",\"31053\",\"41052\",\"41053\",\"41056\",\"41058\",\"41115\",\"41121\",\"41030\",\"44042\",\"44043\",\"44057\",\"44058\",\"44059\",\"44061\",\"44064\",\"44068\",\"45016\",\"45017\",\"45018\",\"45019\",\"45177\",\"45202\",\"45203\",\"45204\",\"45205\",\"45206\",\"45207\",\"46116\",\"46117\",\"46127\",\"42014\",\"42021\",\"42022\",\"42023\",\"42024\",\"42026\",\"32404\",\"41029\",\"41033\",\"41037\",\"41038\",\"41064\",\"41065\",\"41110\",\"41119\",\"41159\",\"32488\",\"41193\",\"44138\",\"44139\",\"44140\",\"44141\",\"44142\",\"44150\",\"44176\",\"44235\",\"44251\",\"44255\",\"44258\",\"44488\",\"45132\",\"45135\",\"45136\",\"45137\",\"45138\",\"45139\",\"45142\",\"45143\",\"45144\",\"45145\",\"45147\",\"45148\",\"45151\",\"45152\",\"45154\",\"45155\",\"45158\",\"45159\",\"46036\",\"46131\",\"46132\",\"46084\",\"46134\",\"46138\",\"46139\",\"46147\",\"46181\",\"46183\",\"46184\",\"46185\",\"46204\",\"46207\",\"46208\",\"46303\",\"46304\",\"48021\",\"45162\",\"45163\",\"45195\",\"23219\",\"23227\",\"32067\",\"32068\",\"42087\",\"42088\",\"42089\",\"42090\",\"46109\",\"46110\",\"46111\",\"46112\",\"21346\",\"21347\",\"21348\",\"21595\",\"21597\",\"21598\",\"21637\",\"21640\",\"22102\",\"22103\",\"22104\",\"22105\",\"22106\",\"22107\",\"45029\",\"45164\",\"45165\",\"45168\",\"45169\",\"45176\",\"46091\",\"46092\",\"62091\",\"62092\",\"62093\",\"62094\",\"41097\",\"41098\",\"41100\",\"41101\",\"41300\",\"61001\",\"45025\",\"45175\",\"44039\",\"44040\",\"44060\",\"23220\",\"23223\",\"23225\",\"46261\",\"46263\",\"48901\",\"48908\",\"48909\",\"48912\",\"44024\",\"44029\",\"44030\",\"44031\",\"44032\",\"44033\",\"44036\",\"44037\",\"45172\",\"45173\",\"46118\",\"46119\",\"46531\",\"46534\",\"46538\",\"46565\",\"44075\",\"44076\",\"44077\",\"44078\",\"46097\",\"46098\",\"51046\",\"51201\",\"51202\",\"51203\",\"51204\",\"51205\",\"51208\",\"51209\",\"51210\",\"51211\",\"51212\",\"51213\",\"52202\",\"52211\",\"13002\",\"13008\",\"13009\",\"13010\",\"15001\",\"15002\",\"31001\",\"31002\",\"31003\",\"31004\",\"31005\",\"31006\",\"62121\",\"62124\",\"62125\",\"62126\",\"62127\",\"62130\",\"62144\",\"62145\",\"62146\",\"62147\",\"62148\",\"62149\",\"62165\",\"62166\",\"63105\",\"63110\",\"63112\",\"63113\",\"14041\",\"14043\",\"14047\",\"23001\",\"23003\",\"23004\",\"23008\",\"23009\",\"23010\",\"23011\",\"23012\",\"23013\",\"23016\",\"23017\",\"53005\",\"53006\",\"53009\",\"53040\",\"56053\",\"01506\",\"01507\",\"01518\",\"01537\",\"48904\",\"48907\",\"01521\",\"01522\",\"01523\",\"01524\",\"01526\",\"01531\",\"01535\",\"01536\",\"01538\",\"01909\",\"01910\",\"31201\",\"41112\",\"41113\",\"41114\",\"41116\",\"41118\",\"41120\",\"42084\",\"42091\",\"42094\",\"42099\",\"44088\",\"44094\",\"44099\",\"44100\",\"44172\",\"46114\",\"46211\",\"46212\",\"46215\",\"46216\",\"46217\",\"46218\",\"46219\",\"46220\",\"46223\",\"46224\",\"46225\",\"46226\",\"46227\",\"46228\",\"46231\",\"46232\",\"46234\",\"46235\",\"46236\",\"46237\",\"46240\",\"46241\",\"46242\",\"46243\",\"46244\",\"46245\",\"46249\",\"46250\",\"46251\",\"46253\",\"46254\",\"46256\",\"46262\",\"46267\",\"46268\",\"46269\",\"46273\",\"46274\",\"51200\",\"48212\",\"48213\",\"48214\",\"48677\",\"48678\",\"48679\",\"48680\",\"48911\",\"42044\",\"42045\",\"42046\",\"42047\",\"42048\",\"42049\",\"42078\",\"42079\",\"42093\",\"42095\",\"42097\",\"44056\",\"45180\",\"46259\",\"46266\",\"62028\",\"62029\",\"62030\",\"62050\",\"62081\",\"62103\",\"62108\",\"62163\",\"62170\",\"62298\",\"62301\",\"62303\",\"62442\",\"64045\",\"44098\",\"46121\",\"46122\",\"46123\",\"46124\",\"28902\",\"28903\",\"28904\",\"28906\",\"28907\",\"28908\",\"58900\",\"58902\",\"58903\",\"58904\",\"58905\",\"58906\",\"58909\",\"68900\",\"78900\",\"45014\",\"45184\",\"44053\",\"01517\",\"32012\",\"41060\",\"41061\",\"21D20\",\"32D12\",\"32D13\",\"41A46\",\"41S43\",\"41S46\",\"46B35\",\"ALSN6\",\"AMAA2\",\"AUGA2\",\"BLIA2\",\"BURL1\",\"BUSL1\",\"CDRF1\",\"CHLV2\",\"CLKN7\",\"CSBF1\",\"DBLN6\",\"DESW1\",\"DRFA2\",\"DRYF1\",\"DSLN7\",\"DUCN7\",\"EB01\",\"EB10\",\"EB33\",\"EB35\",\"EB36\",\"EB43\",\"EB52\",\"EB53\",\"EB70\",\"EB90\",\"EB91\",\"EB92\",\"FARP2\",\"FBIS1\",\"FPSN7\",\"FWYF1\",\"GBCL1\",\"GDIL1\",\"GLLN6\",\"IOSN3\",\"LONF1\",\"LPOI1\",\"MDRM1\",\"MISM1\",\"MLRF1\",\"MPCL1\",\"PILA2\",\"PILM4\",\"PLSF1\",\"POTA2\",\"PTAC1\",\"PTAT2\",\"SANF1\",\"SAUF1\",\"SBIO1\",\"SGNW3\",\"SGOF1\",\"SISW1\",\"SPGF1\",\"SRST2\",\"STDM4\",\"SUPN6\",\"SVLS1\",\"THIN6\",\"VENF1\",\"HBXC1\",\"MYXC1\",\"TDPC1\",\"FSTI2\",\"DMNO3\",\"GPTW1\",\"HMNO3\",\"PRTO3\",\"SEFO3\",\"SETO3\",\"SRAW1\",\"SRFW1\",\"TANO3\",\"ANMF1\",\"ARPF1\",\"BGCF1\",\"CAMF1\",\"CLBF1\",\"EGKF1\",\"NFBF1\",\"PTRF1\",\"SHPF1\",\"MBIN7\",\"MBNN7\",\"OCPN7\",\"BSCA1\",\"CRTA1\",\"DPHA1\",\"KATA1\",\"MBLA1\",\"MHPA1\",\"SACV4\",\"BBSF1\",\"BDVF1\",\"BKYF1\",\"BNKF1\",\"BOBF1\",\"BSKF1\",\"CNBF1\",\"CWAF1\",\"DKKF1\",\"GBIF1\",\"GBTF1\",\"GKYF1\",\"JBYF1\",\"JKYF1\",\"LBRF1\",\"LBSF1\",\"LMDF1\",\"LMRF1\",\"LSNF1\",\"MDKF1\",\"MNBF1\",\"MUKF1\",\"NRRF1\",\"PKYF1\",\"TCVF1\",\"THRF1\",\"TPEF1\",\"TRRF1\",\"WIWF1\",\"WPLF1\",\"APNM4\",\"CHII2\",\"MCYI3\",\"SRLM4\",\"SVNM4\",\"TBIM4\",\"THLO1\",\"LCIY2\",\"LLBP7\",\"FWIC3\",\"MISC3\",\"MISN6\",\"NCSC3\",\"NOSC3\",\"OFPN6\",\"ILDL1\",\"MRSL1\",\"SIPM6\",\"SLPL1\",\"LUML1\",\"TAML1\",\"AKXA2\",\"APMA2\",\"BEXA2\",\"CDXA2\",\"CPXA2\",\"DHXA2\",\"DPXA2\",\"ERXA2\",\"GBXA2\",\"GEXA2\",\"GIXA2\",\"GPXA2\",\"HMSA2\",\"ICYA2\",\"JLXA2\",\"JMLA2\",\"JNGA2\",\"KEXA2\",\"KNXA2\",\"KOZA2\",\"LIXA2\",\"MIXA2\",\"MRNA2\",\"MRYA2\",\"NKLA2\",\"NKXA2\",\"NLXA2\",\"NMXA2\",\"NSXA2\",\"PAUA2\",\"PEXA2\",\"PGXA2\",\"PPXA2\",\"PTLA2\",\"RIXA2\",\"SCXA2\",\"SIXA2\",\"SKXA2\",\"SLXA2\",\"SPXA2\",\"SRXA2\",\"STXA2\",\"SXXA2\",\"TKEA2\",\"TPXA2\",\"UQXA2\",\"VDXA2\",\"WCXA2\",\"MSG10\",\"MSG12\",\"ACQS1\",\"ACXS1\",\"ANMN6\",\"ANRN6\",\"APQF1\",\"APXA2\",\"BILW3\",\"BRIM2\",\"BSLM2\",\"BVQW1\",\"CHNO3\",\"CHQO3\",\"CWQT2\",\"DBQS1\",\"DEQD1\",\"DRSD1\",\"EAZC1\",\"EHSC1\",\"EVMC1\",\"FFFC1\",\"GBHM6\",\"GBQN3\",\"GBRM6\",\"GDQM6\",\"GGGC1\",\"GTQF1\",\"GTXF1\",\"HBMN6\",\"HMRA2\",\"HUQN6\",\"JCTN4\",\"JOBP4\",\"JOQP4\",\"JOXP4\",\"KCHA2\",\"LTQM2\",\"MIST2\",\"MQMT2\",\"MWQT2\",\"NAQR1\",\"NAXR1\",\"NIQS1\",\"NOXN7\",\"NPQN6\",\"NPXN6\",\"OWDO1\",\"OWQO1\",\"OWSO1\",\"PBLW1\",\"PKBW3\",\"RKQF1\",\"RKXF1\",\"RYEC1\",\"SAQG1\",\"SCQC1\",\"SCQN6\",\"SEQA2\",\"SFXC1\",\"SKQN6\",\"SLOO3\",\"TCSV2\",\"TIQC1\",\"TIXC1\",\"TKPN6\",\"WAQM3\",\"WAXM3\",\"WELM1\",\"WEQM1\",\"WEXM1\",\"WKQA1\",\"WKXA1\",\"WYBS1\",\"NLMA3\",\"SBBN2\",\"SLMN2\",\"BAXC1\",\"BDRN4\",\"BDSP1\",\"BGNN6\",\"BKBF1\",\"BLIF1\",\"BRND1\",\"CHCM2\",\"CHYV2\",\"COVM2\",\"CPMW1\",\"CPNW1\",\"CRYV2\",\"DELD1\",\"DMSF1\",\"DOMV2\",\"DPXC1\",\"EBEF1\",\"FMOA1\",\"FRVM3\",\"FRXM3\",\"FSKM2\",\"FSNM2\",\"GCTF1\",\"LNDC1\",\"LQAT2\",\"LTJF1\",\"MBPA1\",\"MCGA1\",\"MHBT2\",\"MRCP1\",\"MTBF1\",\"MZXC1\",\"NBLP1\",\"NFDF1\",\"NWHC3\",\"OMHC1\",\"OPTF1\",\"PDVR1\",\"PEGF1\",\"PFDC1\",\"PFXC1\",\"PPTM2\",\"PPXC1\",\"PRJC1\",\"PRUR1\",\"PSBC1\",\"PSXC1\",\"PTOA1\",\"PVDR1\",\"PXAC1\",\"PXOC1\",\"PXSC1\",\"QPTR1\",\"RPLV2\",\"RTYC1\",\"SEIM1\",\"SJSN4\",\"SKCF1\",\"SWPM4\",\"TCNW1\",\"TLVT2\",\"TPAF1\",\"TSHF1\",\"TXVT2\",\"UPBC1\",\"WDSV2\",\"ACYN4\",\"ADKA2\",\"AGCM4\",\"ALIA2\",\"ALXN6\",\"AMRL1\",\"APAM2\",\"APCF1\",\"APRP7\",\"ASTO3\",\"ATGM1\",\"ATKA2\",\"BEPB6\",\"BFTN7\",\"BHBM3\",\"BISM2\",\"BKTL1\",\"BLTM2\",\"BYGL1\",\"BZBM3\",\"CAMM2\",\"CAPL1\",\"CARL1\",\"CASM1\",\"CECC1\",\"CFWM1\",\"CHAO3\",\"CHAV3\",\"CHBV2\",\"CHSV3\",\"CHYW1\",\"CLBP4\",\"CMAN4\",\"CMTI2\",\"CNDO1\",\"CRVA2\",\"DILA1\",\"DKCM6\",\"DTLM4\",\"DUKN7\",\"DULM5\",\"EBSW1\",\"ERTF1\",\"ESPP4\",\"FAIO1\",\"FCGT2\",\"FMRF1\",\"FOXR1\",\"FPTT2\",\"FRCB6\",\"FRDF1\",\"FRDW1\",\"FREL1\",\"FRPS1\",\"FTPC1\",\"GBWW3\",\"GCVF1\",\"GDMM5\",\"GISL1\",\"GNJT2\",\"GTOT2\",\"GWPM6\",\"HBYC1\",\"HCGN7\",\"HLNM4\",\"HMDO3\",\"ICAC1\",\"IIWC1\",\"ILOH1\",\"ITKA2\",\"JMPN7\",\"JNEA2\",\"KECA2\",\"KGCA2\",\"KLIH1\",\"KPTN6\",\"KPTV2\",\"KWHH1\",\"KYWF1\",\"LABL1\",\"LAMV3\",\"LAPW1\",\"LCLL1\",\"LDTM4\",\"LOPW1\",\"LPNM4\",\"LTBV3\",\"LTRM4\",\"LWSD1\",\"LWTV2\",\"MBRM4\",\"MCGM4\",\"MCYF1\",\"MEYC1\",\"MGIP4\",\"MGZP4\",\"MOKH1\",\"MQTT2\",\"MRHO1\",\"MROS1\",\"MTKN6\",\"MTYC1\",\"NEAW1\",\"NIAN6\",\"NJLC1\",\"NKTA2\",\"NLNC3\",\"NMTA2\",\"NTBC1\",\"NTKM3\",\"NUET2\",\"NWCL1\",\"NWPR1\",\"NWWH1\",\"OCIM2\",\"OHBC1\",\"OLSA2\",\"OOUH1\",\"ORIN7\",\"OSGN6\",\"PCBF1\",\"PCLF1\",\"PCOC1\",\"PGBP7\",\"PHBP1\",\"PLXA2\",\"PNLM6\",\"PORO3\",\"PRDA2\",\"PRYC1\",\"PSBM1\",\"PSLC1\",\"PTAW1\",\"PTIM4\",\"PTIT2\",\"PTWW1\",\"RARM6\",\"RCKM4\",\"RCYF1\",\"RDDA2\",\"RDYD1\",\"SAPF1\",\"SBEO3\",\"SBLF1\",\"SDBC1\",\"SDHN4\",\"SHBL1\",\"SJNP4\",\"SKTA2\",\"SLIM2\",\"SNDP5\",\"SWLA2\",\"SWPV2\",\"TESL1\",\"THRO1\",\"TLBO3\",\"TRDF1\",\"TXPT2\",\"ULAM6\",\"ULRA2\",\"UNLA2\",\"VAKF1\",\"VDZA2\",\"WAHV2\",\"WAKP8\",\"WASD2\",\"WAVM6\",\"WLON7\",\"WPTW1\",\"WYCM6\",\"YATA2\",\"BLTA2\",\"CDEA2\",\"EROA2\",\"LCNA2\",\"PBPA2\",\"PRTA2\",\"SDIA2\",\"AGMW3\",\"BHRI3\",\"BIGM4\",\"BSBM4\",\"CBRW3\",\"CLSM4\",\"FPTM4\",\"GBLW3\",\"GRMM4\",\"GSLM4\",\"GTLM4\",\"GTRM4\",\"KP53\",\"KP58\",\"KP59\",\"LSCM4\",\"MEEM4\",\"NABM4\",\"PCLM4\",\"PNGW3\",\"PRIM4\",\"PSCM4\",\"PWAW3\",\"SBLM4\",\"SPTM4\",\"SXHW3\",\"SYWW3\",\"TAWM4\",\"WFPM4\",\"BARN6\",\"CBLO1\",\"CHDS1\",\"CMPO1\",\"GELO1\",\"HHLO1\",\"LORO1\",\"NREP1\",\"OLCN6\",\"RPRN6\",\"WATS1\",\"AUDP4\",\"FRDP4\",\"PLSP4\",\"VQSP4\",\"CGCL1\",\"SKMG1\",\"SPAG1\",\"AVAN4\",\"BRBN4\",\"OCGN4\",\"AWRT2\",\"BABT2\",\"BZST2\",\"CLLT2\",\"CPNT2\",\"EMAT2\",\"GRRT2\",\"HIST2\",\"IRDT2\",\"LUIT2\",\"LYBT2\",\"MGPT2\",\"NWST2\",\"PACT2\",\"PCGT2\",\"PCNT2\",\"PMNT2\",\"PORT2\",\"RSJT2\",\"RTAT2\",\"RTOT2\",\"SDRT2\",\"SGNT2\",\"TAQT2\",\"BTHD1\",\"FRFN7\",\"JPRN7\",\"18CI3\",\"20CM4\",\"GDIV2\",\"32ST0\",\"41NT0\"]\nbuoy_ids = ids\nbuoy_ids_with_cameras = [] # blank list to store buoy ids with cameras",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "ids",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "ids = [\"21414\",\"21415\",\"21416\",\"21417\",\"21418\",\"21419\",\"32301\",\"32302\",\"32411\",\"32412\",\"32413\",\"41001\",\"41002\",\"41003\",\"41004\",\"41007\",\"41008\",\"41009\",\"41010\",\"41011\",\"41012\",\"41016\",\"41017\",\"41018\",\"41021\",\"41022\",\"41023\",\"41036\",\"41040\",\"41041\",\"41043\",\"41044\",\"41046\",\"41049\",\"41420\",\"41421\",\"41424\",\"41425\",\"42001\",\"42002\",\"42003\",\"42004\",\"42007\",\"42008\",\"42009\",\"42010\",\"42011\",\"42012\",\"42017\",\"42018\",\"42019\",\"42020\",\"42025\",\"42035\",\"42038\",\"42039\",\"42040\",\"42041\",\"42042\",\"42053\",\"42056\",\"42057\",\"42058\",\"42059\",\"42060\",\"42065\",\"42408\",\"42409\",\"42429\",\"42501\",\"42503\",\"42534\",\"44001\",\"44003\",\"44004\",\"44005\",\"44006\",\"44007\",\"44010\",\"44011\",\"44012\",\"44013\",\"44014\",\"44015\",\"44019\",\"44020\",\"44023\",\"44025\",\"44026\",\"44027\",\"44066\",\"44070\",\"44071\",\"44401\",\"44402\",\"44403\",\"45002\",\"45003\",\"45004\",\"45005\",\"45006\",\"45007\",\"45010\",\"45011\",\"45012\",\"46001\",\"46002\",\"46003\",\"46007\",\"46008\",\"46009\",\"46010\",\"46011\",\"46012\",\"46015\",\"46016\",\"46017\",\"46018\",\"46019\",\"46020\",\"46023\",\"46024\",\"46025\",\"46026\",\"46027\",\"46028\",\"46031\",\"46032\",\"46033\",\"46034\",\"46035\",\"46037\",\"46040\",\"46041\",\"46042\",\"46043\",\"46045\",\"46047\",\"46051\",\"46053\",\"46054\",\"46059\",\"46060\",\"46061\",\"46066\",\"46069\",\"46070\",\"46071\",\"46072\",\"46073\",\"46077\",\"46078\",\"46079\",\"46080\",\"46081\",\"46082\",\"46085\",\"46086\",\"46087\",\"46088\",\"46089\",\"46090\",\"46107\",\"46115\",\"46270\",\"46290\",\"46401\",\"46402\",\"46405\",\"46406\",\"46407\",\"46408\",\"46409\",\"46410\",\"46413\",\"46414\",\"46415\",\"46416\",\"46419\",\"46490\",\"46779\",\"46780\",\"46781\",\"46782\",\"46785\",\"51000\",\"51001\",\"51002\",\"51003\",\"51004\",\"51005\",\"51028\",\"51100\",\"51101\",\"51406\",\"51407\",\"51425\",\"52009\",\"52401\",\"52402\",\"52403\",\"52404\",\"52405\",\"91204\",\"91222\",\"91251\",\"91328\",\"91338\",\"91343\",\"91356\",\"91365\",\"91374\",\"91377\",\"91411\",\"91442\",\"46265\",\"41670\",\"41852\",\"41904\",\"41933\",\"48916\",\"48917\",\"52838\",\"52839\",\"52840\",\"52841\",\"52842\",\"52843\",\"52862\",\"55012\",\"55013\",\"55015\",\"55016\",\"55023\",\"55042\",\"58952\",\"31052\",\"31053\",\"41052\",\"41053\",\"41056\",\"41058\",\"41115\",\"41121\",\"41030\",\"44042\",\"44043\",\"44057\",\"44058\",\"44059\",\"44061\",\"44064\",\"44068\",\"45016\",\"45017\",\"45018\",\"45019\",\"45177\",\"45202\",\"45203\",\"45204\",\"45205\",\"45206\",\"45207\",\"46116\",\"46117\",\"46127\",\"42014\",\"42021\",\"42022\",\"42023\",\"42024\",\"42026\",\"32404\",\"41029\",\"41033\",\"41037\",\"41038\",\"41064\",\"41065\",\"41110\",\"41119\",\"41159\",\"32488\",\"41193\",\"44138\",\"44139\",\"44140\",\"44141\",\"44142\",\"44150\",\"44176\",\"44235\",\"44251\",\"44255\",\"44258\",\"44488\",\"45132\",\"45135\",\"45136\",\"45137\",\"45138\",\"45139\",\"45142\",\"45143\",\"45144\",\"45145\",\"45147\",\"45148\",\"45151\",\"45152\",\"45154\",\"45155\",\"45158\",\"45159\",\"46036\",\"46131\",\"46132\",\"46084\",\"46134\",\"46138\",\"46139\",\"46147\",\"46181\",\"46183\",\"46184\",\"46185\",\"46204\",\"46207\",\"46208\",\"46303\",\"46304\",\"48021\",\"45162\",\"45163\",\"45195\",\"23219\",\"23227\",\"32067\",\"32068\",\"42087\",\"42088\",\"42089\",\"42090\",\"46109\",\"46110\",\"46111\",\"46112\",\"21346\",\"21347\",\"21348\",\"21595\",\"21597\",\"21598\",\"21637\",\"21640\",\"22102\",\"22103\",\"22104\",\"22105\",\"22106\",\"22107\",\"45029\",\"45164\",\"45165\",\"45168\",\"45169\",\"45176\",\"46091\",\"46092\",\"62091\",\"62092\",\"62093\",\"62094\",\"41097\",\"41098\",\"41100\",\"41101\",\"41300\",\"61001\",\"45025\",\"45175\",\"44039\",\"44040\",\"44060\",\"23220\",\"23223\",\"23225\",\"46261\",\"46263\",\"48901\",\"48908\",\"48909\",\"48912\",\"44024\",\"44029\",\"44030\",\"44031\",\"44032\",\"44033\",\"44036\",\"44037\",\"45172\",\"45173\",\"46118\",\"46119\",\"46531\",\"46534\",\"46538\",\"46565\",\"44075\",\"44076\",\"44077\",\"44078\",\"46097\",\"46098\",\"51046\",\"51201\",\"51202\",\"51203\",\"51204\",\"51205\",\"51208\",\"51209\",\"51210\",\"51211\",\"51212\",\"51213\",\"52202\",\"52211\",\"13002\",\"13008\",\"13009\",\"13010\",\"15001\",\"15002\",\"31001\",\"31002\",\"31003\",\"31004\",\"31005\",\"31006\",\"62121\",\"62124\",\"62125\",\"62126\",\"62127\",\"62130\",\"62144\",\"62145\",\"62146\",\"62147\",\"62148\",\"62149\",\"62165\",\"62166\",\"63105\",\"63110\",\"63112\",\"63113\",\"14041\",\"14043\",\"14047\",\"23001\",\"23003\",\"23004\",\"23008\",\"23009\",\"23010\",\"23011\",\"23012\",\"23013\",\"23016\",\"23017\",\"53005\",\"53006\",\"53009\",\"53040\",\"56053\",\"01506\",\"01507\",\"01518\",\"01537\",\"48904\",\"48907\",\"01521\",\"01522\",\"01523\",\"01524\",\"01526\",\"01531\",\"01535\",\"01536\",\"01538\",\"01909\",\"01910\",\"31201\",\"41112\",\"41113\",\"41114\",\"41116\",\"41118\",\"41120\",\"42084\",\"42091\",\"42094\",\"42099\",\"44088\",\"44094\",\"44099\",\"44100\",\"44172\",\"46114\",\"46211\",\"46212\",\"46215\",\"46216\",\"46217\",\"46218\",\"46219\",\"46220\",\"46223\",\"46224\",\"46225\",\"46226\",\"46227\",\"46228\",\"46231\",\"46232\",\"46234\",\"46235\",\"46236\",\"46237\",\"46240\",\"46241\",\"46242\",\"46243\",\"46244\",\"46245\",\"46249\",\"46250\",\"46251\",\"46253\",\"46254\",\"46256\",\"46262\",\"46267\",\"46268\",\"46269\",\"46273\",\"46274\",\"51200\",\"48212\",\"48213\",\"48214\",\"48677\",\"48678\",\"48679\",\"48680\",\"48911\",\"42044\",\"42045\",\"42046\",\"42047\",\"42048\",\"42049\",\"42078\",\"42079\",\"42093\",\"42095\",\"42097\",\"44056\",\"45180\",\"46259\",\"46266\",\"62028\",\"62029\",\"62030\",\"62050\",\"62081\",\"62103\",\"62108\",\"62163\",\"62170\",\"62298\",\"62301\",\"62303\",\"62442\",\"64045\",\"44098\",\"46121\",\"46122\",\"46123\",\"46124\",\"28902\",\"28903\",\"28904\",\"28906\",\"28907\",\"28908\",\"58900\",\"58902\",\"58903\",\"58904\",\"58905\",\"58906\",\"58909\",\"68900\",\"78900\",\"45014\",\"45184\",\"44053\",\"01517\",\"32012\",\"41060\",\"41061\",\"21D20\",\"32D12\",\"32D13\",\"41A46\",\"41S43\",\"41S46\",\"46B35\",\"ALSN6\",\"AMAA2\",\"AUGA2\",\"BLIA2\",\"BURL1\",\"BUSL1\",\"CDRF1\",\"CHLV2\",\"CLKN7\",\"CSBF1\",\"DBLN6\",\"DESW1\",\"DRFA2\",\"DRYF1\",\"DSLN7\",\"DUCN7\",\"EB01\",\"EB10\",\"EB33\",\"EB35\",\"EB36\",\"EB43\",\"EB52\",\"EB53\",\"EB70\",\"EB90\",\"EB91\",\"EB92\",\"FARP2\",\"FBIS1\",\"FPSN7\",\"FWYF1\",\"GBCL1\",\"GDIL1\",\"GLLN6\",\"IOSN3\",\"LONF1\",\"LPOI1\",\"MDRM1\",\"MISM1\",\"MLRF1\",\"MPCL1\",\"PILA2\",\"PILM4\",\"PLSF1\",\"POTA2\",\"PTAC1\",\"PTAT2\",\"SANF1\",\"SAUF1\",\"SBIO1\",\"SGNW3\",\"SGOF1\",\"SISW1\",\"SPGF1\",\"SRST2\",\"STDM4\",\"SUPN6\",\"SVLS1\",\"THIN6\",\"VENF1\",\"HBXC1\",\"MYXC1\",\"TDPC1\",\"FSTI2\",\"DMNO3\",\"GPTW1\",\"HMNO3\",\"PRTO3\",\"SEFO3\",\"SETO3\",\"SRAW1\",\"SRFW1\",\"TANO3\",\"ANMF1\",\"ARPF1\",\"BGCF1\",\"CAMF1\",\"CLBF1\",\"EGKF1\",\"NFBF1\",\"PTRF1\",\"SHPF1\",\"MBIN7\",\"MBNN7\",\"OCPN7\",\"BSCA1\",\"CRTA1\",\"DPHA1\",\"KATA1\",\"MBLA1\",\"MHPA1\",\"SACV4\",\"BBSF1\",\"BDVF1\",\"BKYF1\",\"BNKF1\",\"BOBF1\",\"BSKF1\",\"CNBF1\",\"CWAF1\",\"DKKF1\",\"GBIF1\",\"GBTF1\",\"GKYF1\",\"JBYF1\",\"JKYF1\",\"LBRF1\",\"LBSF1\",\"LMDF1\",\"LMRF1\",\"LSNF1\",\"MDKF1\",\"MNBF1\",\"MUKF1\",\"NRRF1\",\"PKYF1\",\"TCVF1\",\"THRF1\",\"TPEF1\",\"TRRF1\",\"WIWF1\",\"WPLF1\",\"APNM4\",\"CHII2\",\"MCYI3\",\"SRLM4\",\"SVNM4\",\"TBIM4\",\"THLO1\",\"LCIY2\",\"LLBP7\",\"FWIC3\",\"MISC3\",\"MISN6\",\"NCSC3\",\"NOSC3\",\"OFPN6\",\"ILDL1\",\"MRSL1\",\"SIPM6\",\"SLPL1\",\"LUML1\",\"TAML1\",\"AKXA2\",\"APMA2\",\"BEXA2\",\"CDXA2\",\"CPXA2\",\"DHXA2\",\"DPXA2\",\"ERXA2\",\"GBXA2\",\"GEXA2\",\"GIXA2\",\"GPXA2\",\"HMSA2\",\"ICYA2\",\"JLXA2\",\"JMLA2\",\"JNGA2\",\"KEXA2\",\"KNXA2\",\"KOZA2\",\"LIXA2\",\"MIXA2\",\"MRNA2\",\"MRYA2\",\"NKLA2\",\"NKXA2\",\"NLXA2\",\"NMXA2\",\"NSXA2\",\"PAUA2\",\"PEXA2\",\"PGXA2\",\"PPXA2\",\"PTLA2\",\"RIXA2\",\"SCXA2\",\"SIXA2\",\"SKXA2\",\"SLXA2\",\"SPXA2\",\"SRXA2\",\"STXA2\",\"SXXA2\",\"TKEA2\",\"TPXA2\",\"UQXA2\",\"VDXA2\",\"WCXA2\",\"MSG10\",\"MSG12\",\"ACQS1\",\"ACXS1\",\"ANMN6\",\"ANRN6\",\"APQF1\",\"APXA2\",\"BILW3\",\"BRIM2\",\"BSLM2\",\"BVQW1\",\"CHNO3\",\"CHQO3\",\"CWQT2\",\"DBQS1\",\"DEQD1\",\"DRSD1\",\"EAZC1\",\"EHSC1\",\"EVMC1\",\"FFFC1\",\"GBHM6\",\"GBQN3\",\"GBRM6\",\"GDQM6\",\"GGGC1\",\"GTQF1\",\"GTXF1\",\"HBMN6\",\"HMRA2\",\"HUQN6\",\"JCTN4\",\"JOBP4\",\"JOQP4\",\"JOXP4\",\"KCHA2\",\"LTQM2\",\"MIST2\",\"MQMT2\",\"MWQT2\",\"NAQR1\",\"NAXR1\",\"NIQS1\",\"NOXN7\",\"NPQN6\",\"NPXN6\",\"OWDO1\",\"OWQO1\",\"OWSO1\",\"PBLW1\",\"PKBW3\",\"RKQF1\",\"RKXF1\",\"RYEC1\",\"SAQG1\",\"SCQC1\",\"SCQN6\",\"SEQA2\",\"SFXC1\",\"SKQN6\",\"SLOO3\",\"TCSV2\",\"TIQC1\",\"TIXC1\",\"TKPN6\",\"WAQM3\",\"WAXM3\",\"WELM1\",\"WEQM1\",\"WEXM1\",\"WKQA1\",\"WKXA1\",\"WYBS1\",\"NLMA3\",\"SBBN2\",\"SLMN2\",\"BAXC1\",\"BDRN4\",\"BDSP1\",\"BGNN6\",\"BKBF1\",\"BLIF1\",\"BRND1\",\"CHCM2\",\"CHYV2\",\"COVM2\",\"CPMW1\",\"CPNW1\",\"CRYV2\",\"DELD1\",\"DMSF1\",\"DOMV2\",\"DPXC1\",\"EBEF1\",\"FMOA1\",\"FRVM3\",\"FRXM3\",\"FSKM2\",\"FSNM2\",\"GCTF1\",\"LNDC1\",\"LQAT2\",\"LTJF1\",\"MBPA1\",\"MCGA1\",\"MHBT2\",\"MRCP1\",\"MTBF1\",\"MZXC1\",\"NBLP1\",\"NFDF1\",\"NWHC3\",\"OMHC1\",\"OPTF1\",\"PDVR1\",\"PEGF1\",\"PFDC1\",\"PFXC1\",\"PPTM2\",\"PPXC1\",\"PRJC1\",\"PRUR1\",\"PSBC1\",\"PSXC1\",\"PTOA1\",\"PVDR1\",\"PXAC1\",\"PXOC1\",\"PXSC1\",\"QPTR1\",\"RPLV2\",\"RTYC1\",\"SEIM1\",\"SJSN4\",\"SKCF1\",\"SWPM4\",\"TCNW1\",\"TLVT2\",\"TPAF1\",\"TSHF1\",\"TXVT2\",\"UPBC1\",\"WDSV2\",\"ACYN4\",\"ADKA2\",\"AGCM4\",\"ALIA2\",\"ALXN6\",\"AMRL1\",\"APAM2\",\"APCF1\",\"APRP7\",\"ASTO3\",\"ATGM1\",\"ATKA2\",\"BEPB6\",\"BFTN7\",\"BHBM3\",\"BISM2\",\"BKTL1\",\"BLTM2\",\"BYGL1\",\"BZBM3\",\"CAMM2\",\"CAPL1\",\"CARL1\",\"CASM1\",\"CECC1\",\"CFWM1\",\"CHAO3\",\"CHAV3\",\"CHBV2\",\"CHSV3\",\"CHYW1\",\"CLBP4\",\"CMAN4\",\"CMTI2\",\"CNDO1\",\"CRVA2\",\"DILA1\",\"DKCM6\",\"DTLM4\",\"DUKN7\",\"DULM5\",\"EBSW1\",\"ERTF1\",\"ESPP4\",\"FAIO1\",\"FCGT2\",\"FMRF1\",\"FOXR1\",\"FPTT2\",\"FRCB6\",\"FRDF1\",\"FRDW1\",\"FREL1\",\"FRPS1\",\"FTPC1\",\"GBWW3\",\"GCVF1\",\"GDMM5\",\"GISL1\",\"GNJT2\",\"GTOT2\",\"GWPM6\",\"HBYC1\",\"HCGN7\",\"HLNM4\",\"HMDO3\",\"ICAC1\",\"IIWC1\",\"ILOH1\",\"ITKA2\",\"JMPN7\",\"JNEA2\",\"KECA2\",\"KGCA2\",\"KLIH1\",\"KPTN6\",\"KPTV2\",\"KWHH1\",\"KYWF1\",\"LABL1\",\"LAMV3\",\"LAPW1\",\"LCLL1\",\"LDTM4\",\"LOPW1\",\"LPNM4\",\"LTBV3\",\"LTRM4\",\"LWSD1\",\"LWTV2\",\"MBRM4\",\"MCGM4\",\"MCYF1\",\"MEYC1\",\"MGIP4\",\"MGZP4\",\"MOKH1\",\"MQTT2\",\"MRHO1\",\"MROS1\",\"MTKN6\",\"MTYC1\",\"NEAW1\",\"NIAN6\",\"NJLC1\",\"NKTA2\",\"NLNC3\",\"NMTA2\",\"NTBC1\",\"NTKM3\",\"NUET2\",\"NWCL1\",\"NWPR1\",\"NWWH1\",\"OCIM2\",\"OHBC1\",\"OLSA2\",\"OOUH1\",\"ORIN7\",\"OSGN6\",\"PCBF1\",\"PCLF1\",\"PCOC1\",\"PGBP7\",\"PHBP1\",\"PLXA2\",\"PNLM6\",\"PORO3\",\"PRDA2\",\"PRYC1\",\"PSBM1\",\"PSLC1\",\"PTAW1\",\"PTIM4\",\"PTIT2\",\"PTWW1\",\"RARM6\",\"RCKM4\",\"RCYF1\",\"RDDA2\",\"RDYD1\",\"SAPF1\",\"SBEO3\",\"SBLF1\",\"SDBC1\",\"SDHN4\",\"SHBL1\",\"SJNP4\",\"SKTA2\",\"SLIM2\",\"SNDP5\",\"SWLA2\",\"SWPV2\",\"TESL1\",\"THRO1\",\"TLBO3\",\"TRDF1\",\"TXPT2\",\"ULAM6\",\"ULRA2\",\"UNLA2\",\"VAKF1\",\"VDZA2\",\"WAHV2\",\"WAKP8\",\"WASD2\",\"WAVM6\",\"WLON7\",\"WPTW1\",\"WYCM6\",\"YATA2\",\"BLTA2\",\"CDEA2\",\"EROA2\",\"LCNA2\",\"PBPA2\",\"PRTA2\",\"SDIA2\",\"AGMW3\",\"BHRI3\",\"BIGM4\",\"BSBM4\",\"CBRW3\",\"CLSM4\",\"FPTM4\",\"GBLW3\",\"GRMM4\",\"GSLM4\",\"GTLM4\",\"GTRM4\",\"KP53\",\"KP58\",\"KP59\",\"LSCM4\",\"MEEM4\",\"NABM4\",\"PCLM4\",\"PNGW3\",\"PRIM4\",\"PSCM4\",\"PWAW3\",\"SBLM4\",\"SPTM4\",\"SXHW3\",\"SYWW3\",\"TAWM4\",\"WFPM4\",\"BARN6\",\"CBLO1\",\"CHDS1\",\"CMPO1\",\"GELO1\",\"HHLO1\",\"LORO1\",\"NREP1\",\"OLCN6\",\"RPRN6\",\"WATS1\",\"AUDP4\",\"FRDP4\",\"PLSP4\",\"VQSP4\",\"CGCL1\",\"SKMG1\",\"SPAG1\",\"AVAN4\",\"BRBN4\",\"OCGN4\",\"AWRT2\",\"BABT2\",\"BZST2\",\"CLLT2\",\"CPNT2\",\"EMAT2\",\"GRRT2\",\"HIST2\",\"IRDT2\",\"LUIT2\",\"LYBT2\",\"MGPT2\",\"NWST2\",\"PACT2\",\"PCGT2\",\"PCNT2\",\"PMNT2\",\"PORT2\",\"RSJT2\",\"RTAT2\",\"RTOT2\",\"SDRT2\",\"SGNT2\",\"TAQT2\",\"BTHD1\",\"FRFN7\",\"JPRN7\",\"18CI3\",\"20CM4\",\"GDIV2\",\"32ST0\",\"41NT0\"]\nbuoy_ids = ids\nbuoy_ids_with_cameras = [] # blank list to store buoy ids with cameras\n# %%\n# Loop through the buoy ids\nfor buoy_id in tqdm(buoy_ids):\n    # if the page text needs to be retrieved then do so, else pull from the text files\n    if not os.path.exists('data/buoy_pages/{}.txt'.format(buoy_id)):\n        # get the page text\n        time.sleep(1)",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "buoy_ids",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "buoy_ids = ids\nbuoy_ids_with_cameras = [] # blank list to store buoy ids with cameras\n# %%\n# Loop through the buoy ids\nfor buoy_id in tqdm(buoy_ids):\n    # if the page text needs to be retrieved then do so, else pull from the text files\n    if not os.path.exists('data/buoy_pages/{}.txt'.format(buoy_id)):\n        # get the page text\n        time.sleep(1)\n        page = requests.get('https://www.ndbc.noaa.gov/station_page.php?station={}'.format(buoy_id))",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "buoy_ids_with_cameras",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "buoy_ids_with_cameras = [] # blank list to store buoy ids with cameras\n# %%\n# Loop through the buoy ids\nfor buoy_id in tqdm(buoy_ids):\n    # if the page text needs to be retrieved then do so, else pull from the text files\n    if not os.path.exists('data/buoy_pages/{}.txt'.format(buoy_id)):\n        # get the page text\n        time.sleep(1)\n        page = requests.get('https://www.ndbc.noaa.gov/station_page.php?station={}'.format(buoy_id))\n        # write the page text to a file",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "cam_buoys",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "cam_buoys = [] # blank list to store buoy ids with cameras\n# %%\n# Purpose: parse the page text to get the camera urls and save them to a file. The page is parsed using BeautifulSoup and the camera urls are extracted using regular expressions.\n# only do this once to get the camera urls and save them to a file for later use\n# if the file does not exist then do so, else pull from the file\nif not os.path.exists('data/buoy_ids_with_cameras.txt'):\n    # open each buoy page text file in data/buoy_pages and parse the page text\n    for buoy_page in tqdm(os.listdir('data/buoy_pages')):\n        with open('data/buoy_pages/{}'.format(buoy_page), 'r') as f:\n            page = f.read() # read the page text",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "cam_urls",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "cam_urls = [] # blank list to store the camera urls\nfor buoy_id in tqdm(cam_buoys):\n    cam_url = 'https://www.ndbc.noaa.gov/buoycam.php?station={}'.format(buoy_id)\n    cam_urls.append(cam_url) # add the camera url to the list of camera urls\n# save the camera urls to the file data/camera_urls.csv\nwith open('data/camera_urls.csv', 'w+') as f:\n    f.write(\"'cam_url',\\n\")\n    for cam_url in cam_urls: # loop through the camera urls\n        f.write('{},\\n'.format(cam_url)) # write the camera url to the file\nprint('These have been saved in the cam_urls array.')",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "buoy_update_rates_dict",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "buoy_update_rates_dict = {} # blank dictionary to store the update rates for each buoy (i.e. how often the buoy takes a picture (measured in seconds))\n# fill the dictionary with blank update rate arrays for each buoy.\n# these arrays will be averaged to get the average update rate for each buoy in real time.\nfor buoy_id in cam_buoys:\n    buoy_update_rates_dict[buoy_id] = 1 # set the initial update rate to 600 seconds (10 minutes)\n# %%\ndef image_has_changed(image_one,image_two):\n    # looks for changes between two images and returns True if there are changes and False if there are not.\n    # this function is used to determine what rate the images are being updated for each buoy.\n    # if the images are not changing, then the buoy is not updating the images.",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "buoy_update_rates_dict",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "buoy_update_rates_dict = {'46025': [600, datetime.datetime.now()]}\nprint(check_for_updates(buoy_update_rates_dict)) # should return an empty list\n# wait 10 seconds\ntime.sleep(10)\nprint(check_for_updates(buoy_update_rates_dict)) # should return ['46025']\n# %%\n# import shutil\n# from difPy import dif\n# go through each buoy and check if there are duplicated images in the images/buoys folder\nfor folder in os.listdir('images/buoys'):",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "iteration_counter",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "iteration_counter = 0\nvincent = Artist() # create an instance of the Artist class\n# %%\nprint('Starting the download loop')\nlast_time_fetched = time.time() # get the current time\nfirst_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nwhile True:\n    try:\n        # turn on at 4 am CST and turn off at 11 pm CST\n        if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "vincent",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "vincent = Artist() # create an instance of the Artist class\n# %%\nprint('Starting the download loop')\nlast_time_fetched = time.time() # get the current time\nfirst_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nwhile True:\n    try:\n        # turn on at 4 am CST and turn off at 11 pm CST\n        if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm\n            # wait to turn on until 4 am CST",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "last_time_fetched",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "last_time_fetched = time.time() # get the current time\nfirst_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nwhile True:\n    try:\n        # turn on at 4 am CST and turn off at 11 pm CST\n        if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm\n            # wait to turn on until 4 am CST\n            # keep the computer awake\n            print('The computer is sleeping')\n            time.sleep(240) # sleep for 4 minutes",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "first_run",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "first_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nwhile True:\n    try:\n        # turn on at 4 am CST and turn off at 11 pm CST\n        if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm\n            # wait to turn on until 4 am CST\n            # keep the computer awake\n            print('The computer is sleeping')\n            time.sleep(240) # sleep for 4 minutes\n            continue",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "old_files.cam_finder_raw",
        "description": "old_files.cam_finder_raw",
        "peekOfCode": "path = 'images/panels/46066/2022_11_5_15_45/2022_11_5_15_45_panel_1.png'\nprint(is_it_daytime(path))",
        "detail": "old_files.cam_finder_raw",
        "documentation": {}
    },
    {
        "label": "last_time_fetched",
        "kind": 5,
        "importPath": "old_files.camfinder",
        "description": "old_files.camfinder",
        "peekOfCode": "last_time_fetched = time.time() # get the current time\nfirst_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nwhile True:\n    try:\n        # turn on at 4 am CST and turn off at 11 pm CST\n        if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm\n            # wait to turn on until 4 am CST\n            # keep the computer awake\n            print('The computer is sleeping')\n            time.sleep(240) # sleep for 4 minutes",
        "detail": "old_files.camfinder",
        "documentation": {}
    },
    {
        "label": "first_run",
        "kind": 5,
        "importPath": "old_files.camfinder",
        "description": "old_files.camfinder",
        "peekOfCode": "first_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nwhile True:\n    try:\n        # turn on at 4 am CST and turn off at 11 pm CST\n        if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm\n            # wait to turn on until 4 am CST\n            # keep the computer awake\n            print('The computer is sleeping')\n            time.sleep(240) # sleep for 4 minutes\n            continue",
        "detail": "old_files.camfinder",
        "documentation": {}
    },
    {
        "label": "scrape_links",
        "kind": 2,
        "importPath": "old_files.carmensandiego",
        "description": "old_files.carmensandiego",
        "peekOfCode": "def scrape_links(timezone, page):\n    # get the html of the page\n    url = f'http://www.insecam.org/en/bytimezone/{timezone}/?page={page}'\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    # find all the links with 'view' in them\n    links = soup.find_all('a', href=re.compile('view'))\n    # add the links to the dataframe\n    for link in links:\n        cameras_df.loc[len(cameras_df)] = [link['href'], timezone, link['title']]",
        "detail": "old_files.carmensandiego",
        "documentation": {}
    },
    {
        "label": "imageurls[0]",
        "kind": 5,
        "importPath": "old_files.carmensandiego",
        "description": "old_files.carmensandiego",
        "peekOfCode": "imageurls[0] = new String(\"http://80.56.142.202:83/mjpg/video.mjpg\");\n</script>\n<script async=\"\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\"></script>\n<ins class=\"adsbygoogle\" style=\"display:block; text-align:center;\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-9642036526375612\" data-ad-slot=\"8439664353\"></ins>\n<script>\n     (adsbygoogle = window.adsbygoogle || []).push({});\n</script>\n```\nSo, if you find the `nofollow` a rel and retrieve the href attribute, you will get the url for the stream.\nThe `title` attribute contains the location of the camera which is also useful to keep in the dataframe.",
        "detail": "old_files.carmensandiego",
        "documentation": {}
    },
    {
        "label": "cameras_df",
        "kind": 5,
        "importPath": "old_files.carmensandiego",
        "description": "old_files.carmensandiego",
        "peekOfCode": "cameras_df = pd.DataFrame(columns=['url', 'timezone', 'location'])\n# what else could I get from the page? location, time, etc. Within the html of the `view` page there is a table in a the div with class'camera-details' which contains the location, time, etc. I could scrape that and add it to the dataframe. This includes Country, Country Code, Region, City, Latitude, Longitude, Zip, and Timezone.\n# the css selector for this table is '.camera-details'\n# Step One A. Request the html of each timezone page and scrape the links from the html.\n# The timezones are: +01:00, +02:00, +03:00, +04:00, +05:00, +06:00, +07:00, +08:00, +09:00, +10:00, +11:00, +12:00, -01:00, -02:00, -03:00, -04:00, -05:00, -06:00, -07:00, -08:00, -09:00, -10:00, -11:00, -12:00, +13:00\ntimezones = ['+01:00', '+02:00', '+03:00', '+04:00', '+05:00', '+06:00', '+07:00', '+08:00', '+09:00', '+10:00', '+11:00', '+12:00', '-01:00', '-02:00', '-03:00', '-04:00', '-05:00', '-06:00', '-07:00', '-08:00', '-09:00', '-10:00', '-11:00', '-12:00', '+13:00']\n# make a function to perform the scraping so we can use it for each timezone and use ratelimit to limit the number of requests per second.\n@sleep_and_retry\n@limits(calls=20, period=600)\ndef scrape_links(timezone, page):",
        "detail": "old_files.carmensandiego",
        "documentation": {}
    },
    {
        "label": "timezones",
        "kind": 5,
        "importPath": "old_files.carmensandiego",
        "description": "old_files.carmensandiego",
        "peekOfCode": "timezones = ['+01:00', '+02:00', '+03:00', '+04:00', '+05:00', '+06:00', '+07:00', '+08:00', '+09:00', '+10:00', '+11:00', '+12:00', '-01:00', '-02:00', '-03:00', '-04:00', '-05:00', '-06:00', '-07:00', '-08:00', '-09:00', '-10:00', '-11:00', '-12:00', '+13:00']\n# make a function to perform the scraping so we can use it for each timezone and use ratelimit to limit the number of requests per second.\n@sleep_and_retry\n@limits(calls=20, period=600)\ndef scrape_links(timezone, page):\n    # get the html of the page\n    url = f'http://www.insecam.org/en/bytimezone/{timezone}/?page={page}'\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    # find all the links with 'view' in them",
        "detail": "old_files.carmensandiego",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "old_files.finding_sunrise",
        "description": "old_files.finding_sunrise",
        "peekOfCode": "model = load_model('models/buoy_model/keras_model.h5')\n# load the images\n# we will load the images from the webcam_captures folder\n# we will then run the model on each image and return a prediction for if the image contains a sunrise or not\n# we will then save the predictions to a csv file\n# get the list of locations\nlocations = os.listdir('images/webcam_captures')\n# create a dataframe to store the predictions\npredictions = pd.DataFrame(columns=['location', 'prediction'])\n# loop through the locations",
        "detail": "old_files.finding_sunrise",
        "documentation": {}
    },
    {
        "label": "locations",
        "kind": 5,
        "importPath": "old_files.finding_sunrise",
        "description": "old_files.finding_sunrise",
        "peekOfCode": "locations = os.listdir('images/webcam_captures')\n# create a dataframe to store the predictions\npredictions = pd.DataFrame(columns=['location', 'prediction'])\n# loop through the locations\nfor location in locations:\n    # get the list of images\n    images = os.listdir('images/webcam_captures/' + location)\n    # loop through the images\n    for image in images:\n        # load the image",
        "detail": "old_files.finding_sunrise",
        "documentation": {}
    },
    {
        "label": "predictions",
        "kind": 5,
        "importPath": "old_files.finding_sunrise",
        "description": "old_files.finding_sunrise",
        "peekOfCode": "predictions = pd.DataFrame(columns=['location', 'prediction'])\n# loop through the locations\nfor location in locations:\n    # get the list of images\n    images = os.listdir('images/webcam_captures/' + location)\n    # loop through the images\n    for image in images:\n        # load the image\n        img = image.load_img('images/webcam_captures/' + location + '/' + image, target_size=(256, 256))\n        # convert the image to an array",
        "detail": "old_files.finding_sunrise",
        "documentation": {}
    },
    {
        "label": "is_recent",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def is_recent(file, minutes):\n    # get the time the image was taken\n    image_time = os.path.getmtime(file)\n    # get the current time\n    current_time = time.time()\n    # get the difference between the two times\n    time_difference = current_time - image_time\n    # if the time difference is less than minutes, return true\n    if time_difference < minutes*60:\n        return True",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "crop_the_bottom_off",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def crop_the_bottom_off(images):\n    # for each of the images crop the bottom off (20 pixels)\n    for image in images:\n        try:\n            # get the image size\n            img_width, img_height = get_image_size(image)\n            # crop the bottom off\n            cropped_image = image.crop((0, 0, img_width, img_height-20))\n            # save the image\n            cropped_image.save(image)",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "check_colors_of_six_panels",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def check_colors_of_six_panels(image):\n    # there are six panels in the image (side by side) and we want to check the colors of each panel\n    # get the image size\n    # the input image should be an image object\n    img_width, img_height = get_image_size(image)\n    # get the width of each panel\n    panel_width = img_width/6\n    # get the height of each panel (remove botttom 20 pixels)\n    panel_height = img_height-20\n    # get the colors of each panel",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "get_panel_segments",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def get_panel_segments(image):\n    \"\"\"\n    get_panel_segments takes an image and returns the segments of the image that are the panels\n    :param image: the image to be segmented\n    :param image: the image to be segmented\n    :type image: image object (from PIL) or numpy array (from OpenCV)\n    :return: the segments of the image that are the panels\n    :rtype: list of image objects\n    \"\"\"\n    # get the image size",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "get_average_color",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def get_average_color(image):\n    \"\"\"\n    get_average_color takes an image and returns the average color of the image\n    :param image: the image to be segmented\n    :type image: image object (from PIL) or numpy array (from OpenCV)\n    :return: the average color of the image\n    :rtype: tuple of integers\n    \"\"\"\n    # get the image size\n    img_width, img_height = image.shape[0], image.shape[1]",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "generate_one_full_day",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def generate_one_full_day(buoy_id, day_number, month_number, year_number):\n    # concatenate one image for each hour of the day and save it as a new image called 'full_day.png'\n    # get the images from the buoy_id folder and sort them\n    images = os.listdir(buoy_id)\n    images.sort()\n    # the names of the images are in the format: '2019-01-01_00.png'\n    # images/buoys/41004/2022_11_5_15_44.jpg\n    # where the day is the 3rd element in the list\n    # and the hour is the 4th element in the list\n    # so we can use a list comprehension to get the images for each hour of the day if we sort the images first.",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "finding_red_version_two",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def finding_red_version_two(image):\n    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    image_height = image.shape[0]\n    image_width = image.shape[1]\n    # https://stackoverflow.com/questions/30331944/finding-red-color-in-image-using-python-opencv\n    image_result = np.zeros((image_height,image_width,3),np.uint8)\n    for i in range(image_height):  #those are set elsewhere\n        for j in range(image_width): #those are set elsewhere\n            if img_hsv[i][j][1]>=50 \\\n                and img_hsv[i][j][2]>=50 \\",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "finding_red_version_three",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def finding_red_version_three(image_path):\n    \"\"\"\n    finding_red_version_three takes an image and returns the red pixels in the image\n    :param image_path: the path to the image to be segmented\n    :param image_path: the path to the image to be segmented\n    :type image_path: string\n    :return: the red pixels in the image\n    :rtype: image object\n    \"\"\"\n    img=cv2.imread(image_path)",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "detect_red_v4",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def detect_red_v4(image):\n    # Red color\n    if type(image) == str:\n        image = cv2.imread(image) # read the image\n    low_red = np.array([161, 155, 84])\n    high_red = np.array([179, 255, 255])\n    red_mask = cv2.inRange(image, low_red, high_red)\n    percent_pixels_red = np.sum(red_mask) / (image.shape[0] * image.shape[1])\n    return percent_pixels_red\ndef detect_red(img):",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "detect_red",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def detect_red(img):\n    \"\"\"\n    detect_red _summary_\n    _extended_summary_\n    :param image: _description_\n    :type image:\n    :return: _description_\n    :rtype: _type_\n    \"\"\"\n    try:",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "deal_with_white_images_and_populate_tapestry",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def deal_with_white_images_and_populate_tapestry():\n    sunsets_found = 0 # keep track of how many sunsets we find\n    files =glob.glob('images/buoys/*/*')\n    # without glob\n    #files = []\n    #for file in os.listdir('images/buoys/'):\n    #   files.append('images/buoys/' + file)\n    #print(files)\n    height, width, channels = cv2.imread(files[0]).shape\n    # blank_image = np.zeros((height*10, width, channels), np.uint8)",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "stitched_panoramas",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def stitched_panoramas(panel1, panel2, panel3, panel4, panel5, panel6):\n    # get the image size\n    img_width, img_height = panel1.shape[1], panel1.shape[0]\n    # get the ratio of the width to height\n    r = float(img_width)/float(img_height)\n    # get the aspect ratio of the image\n    ar = round(r, 2)\n    # calculate the rotation angle\n    rot = math.degrees(math.atan2(-panel1.get_top(), -panel1.get_left()))\n    # get the rotation matrix for this angle",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "get_image_size",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def get_image_size(image):\n    \"\"\"\n    get_image_size returns the width and height of an image\n    _extended_summary_\n    :param image: the image to get the size of\n    :type image: cv2 image\n    :return: the width and height of the image\n    :rtype: tuple\n    \"\"\"\n    # get the image width and height",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "buoy_links",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def buoy_links():\n    global ids\n    links = [\"https://www.ndbc.noaa.gov/buoycam.php?station=42001\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46059\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41044\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46071\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46072\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46066\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41046\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46088\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44066\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46089\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41043\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42012\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42039\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46012\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46011\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42060\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41009\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46028\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44011\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41008\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46015\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42059\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44013\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44007\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51003\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46027\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46026\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51000\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42040\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44020\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46025\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41010\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41004\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51001\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44025\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41001\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51004\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44027\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42020\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46078\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46087\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51101\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46086\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46053\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46047\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46084\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46085\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45003\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45007\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46042\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45012\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42019\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46069\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46054\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41049\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45005\"]\n    #note: undo this to go with the established buoy list\n    # links_2 = create_buoy_links(ids)\n    # # append the links_2 to links if they are not already in links\n    # for link in links_2:\n    #     if link not in links:\n    #         links.append(link)\n    return links",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "create_buoy_links",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def create_buoy_links(ids):\n    # for each id in ids, create a link\n    links = []\n    for id in ids:\n        link = \"https://www.ndbc.noaa.gov/buoycam.php?station=\" + id\n        links.append(link)\n    return links\n# Notes:\n# Buoy 42002 Has good sunsets\ndef check_buoy_image_ifwhite(image):",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "check_buoy_image_ifwhite",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def check_buoy_image_ifwhite(image):\n    \"\"\"\n    check_buoy_image_ifwhite checks if the image is white\n    This function checks if the image is white. If the image is white, then the image is not valid and should be deleted.\n    :param image: the image to check\n    :type image: result of requests library get request for image url\n    :return: True if the image is white, False if the image is not white\n    :rtype: bool\n    \"\"\"\n    # some buoys do not have a camera or the camera is not working. In these cases the image is white with only the text \"No Image Available\"",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "ocean_stitching",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def ocean_stitching(imagePaths, pano_path):\n    images = []\n    # loop over the image paths, load each one, and add them to our\n    # images to stitch list\n    # open each image with cv2 and append to images list\n    for imagePath in imagePaths:\n        try:\n            # add the full path to the image\n            # '/Volumes/Backups of Grahams IMAC/PythonProjects/PySeas_Master_Folder/PySeas/images/panels/44020/2022_11_6_10_54/panel_1.jpg'\n            # read the image",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "refine_view",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def refine_view(stitched_image):\n    stitched = cv2.copyMakeBorder(stitched, 10, 10, 10, 10,\n\t\t\tcv2.BORDER_CONSTANT, (0, 0, 0))\n    # convert the stitched image to grayscale and threshold it\n    # such that all pixels greater than zero are set to 255\n    # (foreground) while all others remain 0 (background)\n    gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)\n    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n    # find all external contours in the threshold image then find\n    # the *largest* contour which will be the contour/outline of",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "create_pano_image",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def create_pano_image(image_list, pano_path):\n    # create a pano image from the images in image_list\n    # image_list is a list of image paths\n    # pano_path is the path to save the pano image\n    # create the pano image\n    ocean_stitching(image_list, pano_path)\n    # refine the pano image\n    #refine_view(pano_path)\ndef chunk_images(buoy_id,foldername):\n    \"\"\"",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "chunk_images",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def chunk_images(buoy_id,foldername):\n    \"\"\"\n    chunk_images takes a folder of images and splits them into sets of 6 images\n    _extended_summary_\n    :param buoy_id: The id of the buoy\n    :type buoy_id: int\n    :param foldername: The name of the folder containing the images\n    :type foldername: str\n    # \"\"\"\n    # #buoy_id = str(foldername)",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "pull_data",
        "kind": 2,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "def pull_data(cam_url, buoy_id, now):\n    img = requests.get(cam_url) # get the image\n    if img.status_code == 200:\n        return img\n    else:\n        print(\"status code\", img.status_code, \"for buoy\", buoy_id)\n    return img\n### Testing the code\n# detect red in an image\n# load the image",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "last_time_fetched",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "last_time_fetched = time.time() # get the current time\nfirst_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nduplicate_removal_flag = True # set this flag to true if we want to remove duplicated images with difPy\n#note: bugs are present in difPy, so this flag is set to false\nexper_1 = False # flag for dupe detect in panels\nverbose_wait = False # flag that makes waiting show a progress bar.\n# import the necessary packages\nfrom imutils import paths\nimport numpy as np\nimport argparse",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "first_run",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "first_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\nduplicate_removal_flag = True # set this flag to true if we want to remove duplicated images with difPy\n#note: bugs are present in difPy, so this flag is set to false\nexper_1 = False # flag for dupe detect in panels\nverbose_wait = False # flag that makes waiting show a progress bar.\n# import the necessary packages\nfrom imutils import paths\nimport numpy as np\nimport argparse\nimport imutils",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "duplicate_removal_flag",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "duplicate_removal_flag = True # set this flag to true if we want to remove duplicated images with difPy\n#note: bugs are present in difPy, so this flag is set to false\nexper_1 = False # flag for dupe detect in panels\nverbose_wait = False # flag that makes waiting show a progress bar.\n# import the necessary packages\nfrom imutils import paths\nimport numpy as np\nimport argparse\nimport imutils\nimport cv2",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "exper_1",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "exper_1 = False # flag for dupe detect in panels\nverbose_wait = False # flag that makes waiting show a progress bar.\n# import the necessary packages\nfrom imutils import paths\nimport numpy as np\nimport argparse\nimport imutils\nimport cv2\nimport glob\nrotating = True # flag to indicate if the tapestry is rotating",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "verbose_wait",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "verbose_wait = False # flag that makes waiting show a progress bar.\n# import the necessary packages\nfrom imutils import paths\nimport numpy as np\nimport argparse\nimport imutils\nimport cv2\nimport glob\nrotating = True # flag to indicate if the tapestry is rotating\npanel_mode = False # flag to indicate if we want to use panels for color detection",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "rotating",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "rotating = True # flag to indicate if the tapestry is rotating\npanel_mode = False # flag to indicate if we want to use panels for color detection\ndef is_recent(file, minutes):\n    # get the time the image was taken\n    image_time = os.path.getmtime(file)\n    # get the current time\n    current_time = time.time()\n    # get the difference between the two times\n    time_difference = current_time - image_time\n    # if the time difference is less than minutes, return true",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "panel_mode",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "panel_mode = False # flag to indicate if we want to use panels for color detection\ndef is_recent(file, minutes):\n    # get the time the image was taken\n    image_time = os.path.getmtime(file)\n    # get the current time\n    current_time = time.time()\n    # get the difference between the two times\n    time_difference = current_time - image_time\n    # if the time difference is less than minutes, return true\n    if time_difference < minutes*60:",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "cam_urls",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "cam_urls = buoy_links() # get the links to the cameras\nall_buoy_urls = create_buoy_links(ids)\nstitch_switch = False # make false if you don't want to stitch the images.\n# open the blacklist file\nfrom ratelimit import limits, sleep_and_retry\n# @limits(calls=1, period=4) # limit the number of calls to the function to 1 every 4 seconds.\n@sleep_and_retry\ndef pull_data(cam_url, buoy_id, now):\n    img = requests.get(cam_url) # get the image\n    if img.status_code == 200:",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "all_buoy_urls",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "all_buoy_urls = create_buoy_links(ids)\nstitch_switch = False # make false if you don't want to stitch the images.\n# open the blacklist file\nfrom ratelimit import limits, sleep_and_retry\n# @limits(calls=1, period=4) # limit the number of calls to the function to 1 every 4 seconds.\n@sleep_and_retry\ndef pull_data(cam_url, buoy_id, now):\n    img = requests.get(cam_url) # get the image\n    if img.status_code == 200:\n        return img",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "stitch_switch",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "stitch_switch = False # make false if you don't want to stitch the images.\n# open the blacklist file\nfrom ratelimit import limits, sleep_and_retry\n# @limits(calls=1, period=4) # limit the number of calls to the function to 1 every 4 seconds.\n@sleep_and_retry\ndef pull_data(cam_url, buoy_id, now):\n    img = requests.get(cam_url) # get the image\n    if img.status_code == 200:\n        return img\n    else:",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "image",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "image = cv2.imread('images/buoys/46072/2022_11_5_19_27.jpg')\nimage_path = 'images/buoys/46072/2022_11_5_19_27.jpg'\n#* Test 2.\n# result = finding_red_version_two(image) # find the red in the image\n# print(result)\n#* Test 3. hsv and npwhere\noutput_img = finding_red_version_three(image_path) # find the red in the image\nprint(output_img)\n#print(output_hsv)\n#Notes to self: remove functions for tests up to this point.",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "image_path",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "image_path = 'images/buoys/46072/2022_11_5_19_27.jpg'\n#* Test 2.\n# result = finding_red_version_two(image) # find the red in the image\n# print(result)\n#* Test 3. hsv and npwhere\noutput_img = finding_red_version_three(image_path) # find the red in the image\nprint(output_img)\n#print(output_hsv)\n#Notes to self: remove functions for tests up to this point.\n#* Test 4. Just red percent",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "output_img",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "output_img = finding_red_version_three(image_path) # find the red in the image\nprint(output_img)\n#print(output_hsv)\n#Notes to self: remove functions for tests up to this point.\n#* Test 4. Just red percent\n#& Successful!\npercent_red = detect_red_v4(image_path)\nprint(percent_red)\n# test with the function to see if it detects red.\ndetect_red_v4(image_path)# returns True if it detects red, False if it doesn't.",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "percent_red",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "percent_red = detect_red_v4(image_path)\nprint(percent_red)\n# test with the function to see if it detects red.\ndetect_red_v4(image_path)# returns True if it detects red, False if it doesn't.\ndo_loop = True\nif do_loop:",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "do_loop",
        "kind": 5,
        "importPath": "old_files.looper",
        "description": "old_files.looper",
        "peekOfCode": "do_loop = True\nif do_loop:\n    pass\nelse:\n    exit() # exit the program if do_loop is False.\nwhile True:\n    try:\n        # turn on at 4 am CST and turn off at 11 pm CST\n        if datetime.datetime.now().hour < 3 or datetime.datetime.now().hour > 24: # if it is before 3 am or after 12 am\n            # wait to turn on until 4 am CST",
        "detail": "old_files.looper",
        "documentation": {}
    },
    {
        "label": "preprocess_image",
        "kind": 2,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "def preprocess_image(image_path):\n  \"\"\" Loads image from path and preprocesses to make it model ready\n      Args:\n        image_path: Path to the image file\n  \"\"\"\n  hr_image = tf.image.decode_image(tf.io.read_file(image_path))\n  # If PNG, remove the alpha channel. The model only supports\n  # images with 3 color channels.\n  if hr_image.shape[-1] == 4:\n    hr_image = hr_image[...,:-1]",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "save_image",
        "kind": 2,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "def save_image(image, filename):\n  \"\"\"\n    Saves unscaled Tensor Images.\n    Args:\n      image: 3D image tensor. [height, width, channels]\n      filename: Name of the file to save.\n  \"\"\"\n  if not isinstance(image, Image.Image):\n    image = tf.clip_by_value(image, 0, 255)\n    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "plot_image",
        "kind": 2,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "def plot_image(image, title=\"\"):\n  \"\"\"\n    Plots images from image tensors.\n    Args:\n      image: 3D image tensor. [height, width, channels].\n      title: Title to display in the plot.\n  \"\"\"\n  image = np.asarray(image)\n  image = tf.clip_by_value(image, 0, 255)\n  image = Image.fromarray(tf.cast(image, tf.uint8).numpy())",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "downscale_image",
        "kind": 2,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "def downscale_image(image):\n  \"\"\"\n      Scales down images using bicubic downsampling.\n      Args:\n          image: 3D or 4D tensor of preprocessed image\n  \"\"\"\n  image_size = []\n  if len(image.shape) == 3:\n    image_size = [image.shape[1], image.shape[0]]\n  else:",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"]",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\"\n# %%\n# !wget \"https://user-images.githubusercontent.com/12981474/40157448-eff91f06-5953-11e8-9a37-f6b5693fa03f.png\" -O original.png\n# %%\n# Declaring Constants\nIMAGE_PATH = \"images/keepers/2022_11_5_18_3_panel_3 copy.png\"\nSAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n# %% [markdown]\n# **Defining Helper Functions**\n# %%",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "IMAGE_PATH",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "IMAGE_PATH = \"images/keepers/2022_11_5_18_3_panel_3 copy.png\"\nSAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n# %% [markdown]\n# **Defining Helper Functions**\n# %%\ndef preprocess_image(image_path):\n  \"\"\" Loads image from path and preprocesses to make it model ready\n      Args:\n        image_path: Path to the image file\n  \"\"\"",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "SAVED_MODEL_PATH",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n# %% [markdown]\n# **Defining Helper Functions**\n# %%\ndef preprocess_image(image_path):\n  \"\"\" Loads image from path and preprocesses to make it model ready\n      Args:\n        image_path: Path to the image file\n  \"\"\"\n  hr_image = tf.image.decode_image(tf.io.read_file(image_path))",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "hr_image",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "hr_image = preprocess_image(IMAGE_PATH)\n# %%\n# Plotting Original Resolution image\nplot_image(tf.squeeze(hr_image), title=\"Original Image\")\nsave_image(tf.squeeze(hr_image), filename=\"Original Image\")\n# %%\nmodel = hub.load(SAVED_MODEL_PATH)\n# %%\nstart = time.time()\nfake_image = model(hr_image)",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "model = hub.load(SAVED_MODEL_PATH)\n# %%\nstart = time.time()\nfake_image = model(hr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\n# Plotting Super Resolution Image\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\nsave_image(tf.squeeze(fake_image), filename=\"Super Resolution\")",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "start",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "start = time.time()\nfake_image = model(hr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\n# Plotting Super Resolution Image\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\nsave_image(tf.squeeze(fake_image), filename=\"Super Resolution\")\n# %% [markdown]\n# ### Evaluating Performance of the Model",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "fake_image",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "fake_image = model(hr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\n# Plotting Super Resolution Image\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\nsave_image(tf.squeeze(fake_image), filename=\"Super Resolution\")\n# %% [markdown]\n# ### Evaluating Performance of the Model\n# %%",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "fake_image",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "fake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\n# Plotting Super Resolution Image\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\nsave_image(tf.squeeze(fake_image), filename=\"Super Resolution\")\n# %% [markdown]\n# ### Evaluating Performance of the Model\n# %%\n# !wget \"https://lh4.googleusercontent.com/-Anmw5df4gj0/AAAAAAAAAAI/AAAAAAAAAAc/6HxU8XFLnQE/photo.jpg64\" -O test.jpg",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "IMAGE_PATH",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "IMAGE_PATH = \"test.jpg\"\n# %%\n# Defining helper functions\ndef downscale_image(image):\n  \"\"\"\n      Scales down images using bicubic downsampling.\n      Args:\n          image: 3D or 4D tensor of preprocessed image\n  \"\"\"\n  image_size = []",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "hr_image",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "hr_image = preprocess_image(IMAGE_PATH)\n# %%\nlr_image = downscale_image(tf.squeeze(hr_image))\n# %%\n# Plotting Low Resolution Image\nplot_image(tf.squeeze(lr_image), title=\"Low Resolution\")\n# %%\nmodel = hub.load(SAVED_MODEL_PATH)\n# %%\nstart = time.time()",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "lr_image",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "lr_image = downscale_image(tf.squeeze(hr_image))\n# %%\n# Plotting Low Resolution Image\nplot_image(tf.squeeze(lr_image), title=\"Low Resolution\")\n# %%\nmodel = hub.load(SAVED_MODEL_PATH)\n# %%\nstart = time.time()\nfake_image = model(lr_image)\nfake_image = tf.squeeze(fake_image)",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "model = hub.load(SAVED_MODEL_PATH)\n# %%\nstart = time.time()\nfake_image = model(lr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n# Calculating PSNR wrt Original Image\npsnr = tf.image.psnr(",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "start",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "start = time.time()\nfake_image = model(lr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n# Calculating PSNR wrt Original Image\npsnr = tf.image.psnr(\n    tf.clip_by_value(fake_image, 0, 255),\n    tf.clip_by_value(hr_image, 0, 255), max_val=255)",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "fake_image",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "fake_image = model(lr_image)\nfake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n# Calculating PSNR wrt Original Image\npsnr = tf.image.psnr(\n    tf.clip_by_value(fake_image, 0, 255),\n    tf.clip_by_value(hr_image, 0, 255), max_val=255)\nprint(\"PSNR Achieved: %f\" % psnr)",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "fake_image",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "fake_image = tf.squeeze(fake_image)\nprint(\"Time Taken: %f\" % (time.time() - start))\n# %%\nplot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n# Calculating PSNR wrt Original Image\npsnr = tf.image.psnr(\n    tf.clip_by_value(fake_image, 0, 255),\n    tf.clip_by_value(hr_image, 0, 255), max_val=255)\nprint(\"PSNR Achieved: %f\" % psnr)\n# %% [markdown]",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "psnr",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "psnr = tf.image.psnr(\n    tf.clip_by_value(fake_image, 0, 255),\n    tf.clip_by_value(hr_image, 0, 255), max_val=255)\nprint(\"PSNR Achieved: %f\" % psnr)\n# %% [markdown]\n# **Comparing Outputs size by side.**\n# %%\nplt.rcParams['figure.figsize'] = [15, 10]\nfig, axes = plt.subplots(1, 3)\nfig.tight_layout()",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "plt.rcParams['figure.figsize']",
        "kind": 5,
        "importPath": "old_files.one",
        "description": "old_files.one",
        "peekOfCode": "plt.rcParams['figure.figsize'] = [15, 10]\nfig, axes = plt.subplots(1, 3)\nfig.tight_layout()\nplt.subplot(131)\nplot_image(tf.squeeze(hr_image), title=\"Original\")\nplt.subplot(132)\nfig.tight_layout()\nplot_image(tf.squeeze(lr_image), \"x4 Bicubic\")\nplt.subplot(133)\nfig.tight_layout()",
        "detail": "old_files.one",
        "documentation": {}
    },
    {
        "label": "BasePafy",
        "kind": 6,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "class BasePafy(object):\n    \"\"\" Class to represent a YouTube video. \"\"\"\n    def __init__(self, video_url, basic=True, gdata=False,\n                 size=False, callback=None, ydl_opts=None):\n        \"\"\" Set initial values. \"\"\"\n        self.version = __version__\n        self.videoid = extract_video_id(video_url)\n        self.watchv_url = g.urls['watchv'] % self.videoid\n        self.callback = callback\n        self._have_basic = False",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "BaseStream",
        "kind": 6,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "class BaseStream(object):\n    \"\"\" YouTube video stream class. \"\"\"\n    def __init__(self, parent):\n        \"\"\" Set initial values. \"\"\"\n        self._itag = None\n        self._mediatype = None\n        self._threed = None\n        self._rawbitrate = None\n        self._resolution = None\n        self._quality = None",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "extract_video_id",
        "kind": 2,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "def extract_video_id(url):\n    \"\"\" Extract the video id from a url, return video id as str. \"\"\"\n    idregx = re.compile(r'[\\w-]{11}$')\n    url = str(url).strip()\n    if idregx.match(url):\n        return url # ID of video\n    if '://' not in url:\n        url = '//' + url\n    parsedurl = urlparse(url)\n    if parsedurl.netloc in ('youtube.com', 'www.youtube.com', 'm.youtube.com', 'gaming.youtube.com'):",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "remux",
        "kind": 2,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "def remux(infile, outfile, quiet=False, muxer=\"ffmpeg\"):\n    \"\"\" Remux audio. \"\"\"\n    muxer = muxer if isinstance(muxer, str) else \"ffmpeg\"\n    for tool in set([muxer, \"ffmpeg\", \"avconv\"]):\n        cmd = [tool, \"-y\", \"-i\", infile, \"-acodec\", \"copy\", \"-vn\", outfile]\n        try:\n            with open(os.devnull, \"w\") as devnull:\n                subprocess.call(cmd, stdout=devnull, stderr=subprocess.STDOUT)\n        except OSError:\n            dbg(\"Failed to remux audio using %s\", tool)",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "get_size_done",
        "kind": 2,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "def get_size_done(bytesdone, progress):\n    _progress_dict = {'KB': 1024.0, 'MB': 1048576.0, 'GB': 1073741824.0}\n    return round(bytesdone/_progress_dict.get(progress, 1.0), 2)\ndef get_status_string(progress):\n    status_string = ('  {:,} ' + progress + ' [{:.2%}] received. Rate: [{:4.0f} '\n                     'KB/s].  ETA: [{:.0f} secs]')\n    if early_py_version:\n        status_string = ('  {0:} ' + progress + ' [{1:.2%}] received. Rate:'\n                         ' [{2:4.0f} KB/s].  ETA: [{3:.0f} secs]')\n    return status_string",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "get_status_string",
        "kind": 2,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "def get_status_string(progress):\n    status_string = ('  {:,} ' + progress + ' [{:.2%}] received. Rate: [{:4.0f} '\n                     'KB/s].  ETA: [{:.0f} secs]')\n    if early_py_version:\n        status_string = ('  {0:} ' + progress + ' [{1:.2%}] received. Rate:'\n                         ' [{2:4.0f} KB/s].  ETA: [{3:.0f} secs]')\n    return status_string",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "early_py_version",
        "kind": 5,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "early_py_version = sys.version_info[:2] < (2, 7)\nfrom . import __version__, g\nfrom .pafy import call_gdata\nfrom .playlist import get_playlist2\nfrom .util import xenc\ndbg = logging.debug\ndef extract_video_id(url):\n    \"\"\" Extract the video id from a url, return video id as str. \"\"\"\n    idregx = re.compile(r'[\\w-]{11}$')\n    url = str(url).strip()",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "dbg",
        "kind": 5,
        "importPath": "old_files.reformat",
        "description": "old_files.reformat",
        "peekOfCode": "dbg = logging.debug\ndef extract_video_id(url):\n    \"\"\" Extract the video id from a url, return video id as str. \"\"\"\n    idregx = re.compile(r'[\\w-]{11}$')\n    url = str(url).strip()\n    if idregx.match(url):\n        return url # ID of video\n    if '://' not in url:\n        url = '//' + url\n    parsedurl = urlparse(url)",
        "detail": "old_files.reformat",
        "documentation": {}
    },
    {
        "label": "model_filepath",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "model_filepath = 'models/converted_keras/keras_model.h5'\nimport tensorflow as tf\ntry:\n    model = tf.keras.models.load_model(model_filepath)\nexcept:\n    print('Model not found')\ntf.keras.models.load_model(\n    model_filepath, custom_objects=None, compile=True, options=None\n)\nprint('Model loaded')",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "image_path",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "image_path = 'images/panels/41001/2022_11_5_19_27.jpg_panel_1.jpg'\nimg = cv2.imread(image_path) # Reading the image\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Converting the image to RGB\nimg = cv2.resize(img, (224, 224)) # Resizing the image\nimg = img / 255 # Normalizing the image\nimg = np.array(img).reshape(-1, 224, 224, 3) # Reshaping the image\nprint('image loaded')\n# Predicting the class\nprediction = model.predict(img)\nprint(prediction)",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "img = cv2.imread(image_path) # Reading the image\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Converting the image to RGB\nimg = cv2.resize(img, (224, 224)) # Resizing the image\nimg = img / 255 # Normalizing the image\nimg = np.array(img).reshape(-1, 224, 224, 3) # Reshaping the image\nprint('image loaded')\n# Predicting the class\nprediction = model.predict(img)\nprint(prediction)",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Converting the image to RGB\nimg = cv2.resize(img, (224, 224)) # Resizing the image\nimg = img / 255 # Normalizing the image\nimg = np.array(img).reshape(-1, 224, 224, 3) # Reshaping the image\nprint('image loaded')\n# Predicting the class\nprediction = model.predict(img)\nprint(prediction)",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "img = cv2.resize(img, (224, 224)) # Resizing the image\nimg = img / 255 # Normalizing the image\nimg = np.array(img).reshape(-1, 224, 224, 3) # Reshaping the image\nprint('image loaded')\n# Predicting the class\nprediction = model.predict(img)\nprint(prediction)",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "img = img / 255 # Normalizing the image\nimg = np.array(img).reshape(-1, 224, 224, 3) # Reshaping the image\nprint('image loaded')\n# Predicting the class\nprediction = model.predict(img)\nprint(prediction)",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "img = np.array(img).reshape(-1, 224, 224, 3) # Reshaping the image\nprint('image loaded')\n# Predicting the class\nprediction = model.predict(img)\nprint(prediction)",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "prediction",
        "kind": 5,
        "importPath": "old_files.using_keras_modeling",
        "description": "old_files.using_keras_modeling",
        "peekOfCode": "prediction = model.predict(img)\nprint(prediction)",
        "detail": "old_files.using_keras_modeling",
        "documentation": {}
    },
    {
        "label": "BuoyImage",
        "kind": 6,
        "importPath": "rough_drafts.phase_one_draft",
        "description": "rough_drafts.phase_one_draft",
        "peekOfCode": "class BuoyImage:\n    def __init__(self, image_path):\n        self.image_path = image_path\n        self.image = cv2.imread(image_path)\n        self.average_color = self.get_average_color()\n    def get_average_color(self):\n        image = Image.fromarray(self.image)\n        img_width, img_height = image.size\n        average_color = image.getpixel((img_width // 2, img_height // 2))\n        return average_color",
        "detail": "rough_drafts.phase_one_draft",
        "documentation": {}
    },
    {
        "label": "PanoramicImage",
        "kind": 6,
        "importPath": "rough_drafts.phase_one_draft",
        "description": "rough_drafts.phase_one_draft",
        "peekOfCode": "class PanoramicImage:\n    def __init__(self, image_paths):\n        self.image_paths = image_paths\n        self.panorama = self.make_panorama()\n    def artist_eval(self):\n        img = Image.fromarray(self.panorama)\n        width, height = img.size\n        panels = [img.getpixel((int(width * i / 12), int(height / 2))) for i in [1, 3, 6, 9, 10, 11]]\n        mses = [np.mean((np.array(panels[i]) - np.array(panels[i + 1])) ** 2) for i in range(len(panels) - 1)]\n        mse = np.mean(mses)",
        "detail": "rough_drafts.phase_one_draft",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "rough_drafts.phase_one_draft",
        "description": "rough_drafts.phase_one_draft",
        "peekOfCode": "def main():\n    image_directory = \"path/to/image/directory\"\n    image_paths = [os.path.join(image_directory, image) for image in os.listdir(image_directory) if image.endswith(('.jpg', '.jpeg', '.png'))]\n    # Create BuoyImage instances\n    buoy_images = [BuoyImage(image_path) for image_path in image_paths]\n    # Create a PanoramicImage instance\n    panoramic_image = PanoramicImage(image_paths)\n    # Check if the panoramic_image is a consistent panorama\n    is_panorama = panoramic_image.artist_eval()\n    if is_panorama:",
        "detail": "rough_drafts.phase_one_draft",
        "documentation": {}
    },
    {
        "label": "BuoyImage",
        "kind": 6,
        "importPath": "rough_drafts.phase_one_draft2",
        "description": "rough_drafts.phase_one_draft2",
        "peekOfCode": "class BuoyImage:\n    def __init__(self, image_url, num_panels=6, target_height=500):\n        self.image_url = image_url\n        self.image = self.download_image(image_url)\n        self.panels = self.split_image_into_panels()\n        self.unusual_panels = self.check_unusual_panels()\n        self.image_url = image_url\n        self.num_panels = num_panels\n        self.target_height = target_height\n        self.image = self.download_image(image_url)",
        "detail": "rough_drafts.phase_one_draft2",
        "documentation": {}
    },
    {
        "label": "PanoramicImage",
        "kind": 6,
        "importPath": "rough_drafts.phase_one_draft2",
        "description": "rough_drafts.phase_one_draft2",
        "peekOfCode": "class PanoramicImage:\n    def __init__(self, images):\n        self.images = images\n        self.aligned_images = [self.align_horizon_line(img) for img in images]\n        self.stitched_image = self.stitch_aligned_images()\n    def detect_horizon_line(self, img):\n        # Convert the image to grayscale and apply a Canny edge detector\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n        # Use HoughLinesP to detect lines in the image",
        "detail": "rough_drafts.phase_one_draft2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "rough_drafts.phase_one_draft2",
        "description": "rough_drafts.phase_one_draft2",
        "peekOfCode": "def main():\n    buoy_urls = [\"buoy_url_1\", \"buoy_url_2\", \"buoy_url_3\"]\n    base_output_path = \"path/to/output/directory\"\n    for buoy_url in buoy_urls:\n        # Download the image and create a BuoyImage instance\n        buoy_image = BuoyImage(buoy_url)\n        if any(buoy_image.unusual_panels):\n            # Save the panels in a folder named after the buoy > date > time\n            current_datetime = datetime.now()\n            date_str = current_datetime.strftime(\"%Y-%m-%d\")",
        "detail": "rough_drafts.phase_one_draft2",
        "documentation": {}
    },
    {
        "label": "BuoyImage",
        "kind": 6,
        "importPath": "rough_drafts.phase_one_draft3",
        "description": "rough_drafts.phase_one_draft3",
        "peekOfCode": "class BuoyImage:\n    def __init__(self, image_url, num_panels=6, target_height=500, mse_threshold=2000):\n        self.image_url = image_url\n        self.num_panels = num_panels\n        self.target_height = target_height\n        self.mse_threshold = mse_threshold\n        self.image = self.download_image(image_url)\n        self.resized_image = self.resize_image_to_standard_height()\n        self.panels = self.split_image_into_panels()\n        self.unusual_panels = self.check_unusual_panels()",
        "detail": "rough_drafts.phase_one_draft3",
        "documentation": {}
    },
    {
        "label": "PanoramicImage",
        "kind": 6,
        "importPath": "rough_drafts.phase_one_draft3",
        "description": "rough_drafts.phase_one_draft3",
        "peekOfCode": "class PanoramicImage:\n    def __init__(self, images):\n        self.images = images\n        self.aligned_images = [self.align_horizon_line(img) for img in images]\n        self.stitched_image = self.stitch_aligned_images()\n    def detect_horizon_line(self, img):\n        \"\"\"\n        The detect_horizon_line function takes an image as input and returns the angle of the horizon line.\n        The function uses OpenCV to detect edges in a grayscale version of the image, then uses HoughLinesP to find lines in those edges.\n        It then finds the longest line and calculates its angle using arctan2.",
        "detail": "rough_drafts.phase_one_draft3",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "rough_drafts.phase_one_draft3",
        "description": "rough_drafts.phase_one_draft3",
        "peekOfCode": "def main():\n    buoy_urls = [\"buoy_url_1\", \"buoy_url_2\", \"buoy_url_3\"]\n    base_output_path = \"path/to/output/directory\"\n    for buoy_url in buoy_urls:\n        buoy_image = BuoyImage(buoy_url)\n        if any(buoy_image.unusual_panels):\n            current_datetime = datetime.now()\n            date_str = current_datetime.strftime(\"%Y-%m-%d\")\n            time_str = current_datetime.strftime(\"%H-%M-%S\")\n            buoy_name = buoy_url.split(\"/\")[-2]",
        "detail": "rough_drafts.phase_one_draft3",
        "documentation": {}
    },
    {
        "label": "make_panorama",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def make_panorama(self, images):\n    \"\"\"\n    make_panorama takes a list of images and makes a panorama out of them\n    :param images: _description_\n    :type images: _type_\n    :return: _description_\n    :rtype: _type_\n    \"\"\"\n    # Remove .DS_Store from the list of images\n    images = [image for image in images if image != '.DS_Store']",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "artist_eval",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def artist_eval(image_path):\n    \"\"\"\n    Using the mean squared error of the six panels' color similarity, we can determine if the image is a consistent panorama or not. If the mse is less than 100, we will consider the image a panorama. Otherwise, we will consider the image not a panorama.\n    _extended_summary_\n    :param image_path: _description_\n    :type image_path: _type_\n    :return: _description_\n    :rtype: _type_\n    \"\"\"\n    img = Image.open(image_path)",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "display_last_image",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def display_last_image(buoys_to_update):\n    # get the last buoy in the list of buoys that need to be updated\n    buoy_id = buoys_to_update[-1]\n    # get the list of images in the folder\n    # sort the images by date\n    # make folder_path variable from relative path\n    # choose the last buoy in the list of buoy folders\n    last_buoy=buoys_to_update[-1]\n    folder_path = 'images/buoys/{}'.format(last_buoy)\n    images = os.listdir(folder_path)",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "preprocess_image",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def preprocess_image(image_path):\n  \"\"\" Loads image from path and preprocesses to make it model ready\n      Args:\n        image_path: Path to the image file\n  \"\"\"\n  hr_image = tf.image.decode_image(tf.io.read_file(image_path))\n  # If PNG, remove the alpha channel. The model only supports\n  # images with 3 color channels.\n  if hr_image.shape[-1] == 4:\n    hr_image = hr_image[...,:-1]",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "save_image",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def save_image(image, filename):\n  \"\"\"\n    Saves unscaled Tensor Images.\n    Args:\n      image: 3D image tensor. [height, width, channels]\n      filename: Name of the file to save.\n  \"\"\"\n  if not isinstance(image, Image.Image):\n    image = tf.clip_by_value(image, 0, 255)\n    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "plot_image",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def plot_image(image, title=\"\"):\n  \"\"\"\n    Plots images from image tensors.\n    Args:\n      image: 3D image tensor. [height, width, channels].\n      title: Title to display in the plot.\n  \"\"\"\n  image = np.asarray(image)\n  image = tf.clip_by_value(image, 0, 255)\n  image = Image.fromarray(tf.cast(image, tf.uint8).numpy())",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "downscale_image",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def downscale_image(image):\n  \"\"\"\n      Scales down images using bicubic downsampling.\n      Args:\n          image: 3D or 4D tensor of preprocessed image\n  \"\"\"\n  image_size = []\n  if len(image.shape) == 3:\n    image_size = [image.shape[1], image.shape[0]]\n  else:",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "unusual_plotting_tf_squeeze",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def unusual_plotting_tf_squeeze():\n    start = time.time()\n    fake_image = model(lr_image)\n    fake_image = tf.squeeze(fake_image)\n    print(\"Time Taken: %f\" % (time.time() - start))\n    plot_image(tf.squeeze(fake_image), title=\"Super Resolution\")\n    # Calculating PSNR wrt Original Image\n    psnr = tf.image.psnr(\n        tf.clip_by_value(fake_image, 0, 255),\n        tf.clip_by_value(hr_image, 0, 255), max_val=255)",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "is_recent",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def is_recent(file, minutes):\n    # get the time the image was taken\n    image_time = os.path.getmtime(file)\n    # get the current time\n    current_time = time.time()\n    # get the difference between the two times\n    time_difference = current_time - image_time\n    # if the time difference is less than minutes, return true\n    if time_difference < minutes*60:\n        return True",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "crop_the_bottom_off",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def crop_the_bottom_off(images):\n    # for each of the images crop the bottom off (20 pixels)\n    for image in images:\n        try:\n            # get the image size\n            img_width, img_height = get_image_size(image)\n            # crop the bottom off\n            cropped_image = image.crop((0, 0, img_width, img_height-20))\n            # save the image\n            cropped_image.save(image)",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "check_colors_of_six_panels",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def check_colors_of_six_panels(image):\n    # there are six panels in the image (side by side) and we want to check the colors of each panel\n    # get the image size\n    # the input image should be an image object\n    img_width, img_height = get_image_size(image)\n    # get the width of each panel\n    panel_width = img_width/6\n    # get the height of each panel (remove botttom 20 pixels)\n    panel_height = img_height-20\n    # get the colors of each panel",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "get_panel_segments",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def get_panel_segments(image):\n    \"\"\"\n    get_panel_segments takes an image and returns the segments of the image that are the panels\n    :param image: the image to be segmented\n    :param image: the image to be segmented\n    :type image: image object (from PIL) or numpy array (from OpenCV)\n    :return: the segments of the image that are the panels\n    :rtype: list of image objects\n    \"\"\"\n    # get the image size",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "get_average_color",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def get_average_color(image):\n    \"\"\"\n    get_average_color takes an image and returns the average color of the image\n    :param image: the image to be segmented\n    :type image: image object (from PIL) or numpy array (from OpenCV)\n    :return: the average color of the image\n    :rtype: tuple of integers\n    \"\"\"\n    # get the image size\n    img_width, img_height = image.shape[0], image.shape[1]",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "generate_one_full_day",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def generate_one_full_day(buoy_id, day_number, month_number, year_number):\n    # concatenate one image for each hour of the day and save it as a new image called 'full_day.png'\n    # get the images from the buoy_id folder and sort them\n    images = os.listdir(buoy_id)\n    images.sort()\n    # the names of the images are in the format: '2019-01-01_00.png'\n    # images/buoys/41004/2022_11_5_15_44.jpg\n    # where the day is the 3rd element in the list\n    # and the hour is the 4th element in the list\n    # so we can use a list comprehension to get the images for each hour of the day if we sort the images first.",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "finding_red_version_two",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def finding_red_version_two(image):\n    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    image_height = image.shape[0]\n    image_width = image.shape[1]\n    # https://stackoverflow.com/questions/30331944/finding-red-color-in-image-using-python-opencv\n    image_result = np.zeros((image_height,image_width,3),np.uint8)\n    for i in range(image_height):  #those are set elsewhere\n        for j in range(image_width): #those are set elsewhere\n            if img_hsv[i][j][1]>=50 \\\n                and img_hsv[i][j][2]>=50 \\",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "finding_red_version_three",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def finding_red_version_three(image_path):\n    \"\"\"\n    finding_red_version_three takes an image and returns the red pixels in the image\n    :param image_path: the path to the image to be segmented\n    :param image_path: the path to the image to be segmented\n    :type image_path: string\n    :return: the red pixels in the image\n    :rtype: image object\n    \"\"\"\n    img=cv2.imread(image_path)",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "detect_red_v4",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def detect_red_v4(image):\n    # Red color\n    if type(image) == str:\n        image = cv2.imread(image) # read the image\n    low_red = np.array([161, 155, 84])\n    high_red = np.array([179, 255, 255])\n    red_mask = cv2.inRange(image, low_red, high_red)\n    percent_pixels_red = np.sum(red_mask) / (image.shape[0] * image.shape[1])\n    return percent_pixels_red\ndef detect_red(img):",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "detect_red",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def detect_red(img):\n    \"\"\"\n    detect_red _summary_\n    _extended_summary_\n    :param image: _description_\n    :type image:\n    :return: _description_\n    :rtype: _type_\n    \"\"\"\n    try:",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "deal_with_white_images_and_populate_tapestry",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def deal_with_white_images_and_populate_tapestry():\n    sunsets_found = 0 # keep track of how many sunsets we find\n    files =glob.glob('images/buoys/*/*')\n    # without glob\n    #files = []\n    #for file in os.listdir('images/buoys/'):\n    #   files.append('images/buoys/' + file)\n    #print(files)\n    height, width, channels = cv2.imread(files[0]).shape\n    # blank_image = np.zeros((height*10, width, channels), np.uint8)",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "stitched_panoramas",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def stitched_panoramas(panel1, panel2, panel3, panel4, panel5, panel6):\n    # get the image size\n    img_width, img_height = panel1.shape[1], panel1.shape[0]\n    # get the ratio of the width to height\n    r = float(img_width)/float(img_height)\n    # get the aspect ratio of the image\n    ar = round(r, 2)\n    # calculate the rotation angle\n    rot = math.degrees(math.atan2(-panel1.get_top(), -panel1.get_left()))\n    # get the rotation matrix for this angle",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "get_image_size",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def get_image_size(image):\n    \"\"\"\n    get_image_size returns the width and height of an image\n    _extended_summary_\n    :param image: the image to get the size of\n    :type image: cv2 image\n    :return: the width and height of the image\n    :rtype: tuple\n    \"\"\"\n    # get the image width and height",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "buoy_links",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def buoy_links():\n    global ids\n    links = [\"https://www.ndbc.noaa.gov/buoycam.php?station=42001\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46059\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41044\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46071\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46072\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46066\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41046\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46088\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44066\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46089\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41043\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42012\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42039\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46012\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46011\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42060\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41009\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46028\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44011\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41008\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46015\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42059\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44013\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44007\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51003\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46027\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46026\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51000\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42040\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44020\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46025\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41010\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41004\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51001\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44025\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41001\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51004\",\"https://www.ndbc.noaa.gov/buoycam.php?station=44027\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42020\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46078\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46087\",\"https://www.ndbc.noaa.gov/buoycam.php?station=51101\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46086\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45002\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46053\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46047\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46084\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46085\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45003\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45007\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46042\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45012\",\"https://www.ndbc.noaa.gov/buoycam.php?station=42019\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46069\",\"https://www.ndbc.noaa.gov/buoycam.php?station=46054\",\"https://www.ndbc.noaa.gov/buoycam.php?station=41049\",\"https://www.ndbc.noaa.gov/buoycam.php?station=45005\"]\n    #note: undo this to go with the established buoy list\n    # links_2 = create_buoy_links(ids)\n    # # append the links_2 to links if they are not already in links\n    # for link in links_2:\n    #     if link not in links:\n    #         links.append(link)\n    return links",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "create_buoy_links",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def create_buoy_links(ids):\n    # for each id in ids, create a link\n    links = []\n    for id in ids:\n        link = \"https://www.ndbc.noaa.gov/buoycam.php?station=\" + id\n        links.append(link)\n    return links\n# Notes:\n# Buoy 42002 Has good sunsets\ndef check_buoy_image_ifwhite(image):",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "check_buoy_image_ifwhite",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def check_buoy_image_ifwhite(image):\n    \"\"\"\n    check_buoy_image_ifwhite checks if the image is white\n    This function checks if the image is white. If the image is white, then the image is not valid and should be deleted.\n    :param image: the image to check\n    :type image: result of requests library get request for image url\n    :return: True if the image is white, False if the image is not white\n    :rtype: bool\n    \"\"\"\n    # some buoys do not have a camera or the camera is not working. In these cases the image is white with only the text \"No Image Available\"",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "ocean_stitching",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def ocean_stitching(imagePaths, pano_path):\n    images = []\n    # loop over the image paths, load each one, and add them to our\n    # images to stitch list\n    # open each image with cv2 and append to images list\n    for imagePath in imagePaths:\n        try:\n            # add the full path to the image\n            # '/Volumes/Backups of Grahams IMAC/PythonProjects/PySeas_Master_Folder/PySeas/images/panels/44020/2022_11_6_10_54/panel_1.jpg'\n            # read the image",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "refine_view",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def refine_view(stitched_image):\n    stitched = cv2.copyMakeBorder(stitched, 10, 10, 10, 10,\n\t\t\tcv2.BORDER_CONSTANT, (0, 0, 0))\n    # convert the stitched image to grayscale and threshold it\n    # such that all pixels greater than zero are set to 255\n    # (foreground) while all others remain 0 (background)\n    gray = cv2.cvtColor(stitched, cv2.COLOR_BGR2GRAY)\n    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n    # find all external contours in the threshold image then find\n    # the *largest* contour which will be the contour/outline of",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "create_pano_image",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def create_pano_image(image_list, pano_path):\n    # create a pano image from the images in image_list\n    # image_list is a list of image paths\n    # pano_path is the path to save the pano image\n    # create the pano image\n    ocean_stitching(image_list, pano_path)\n    # refine the pano image\n    #refine_view(pano_path)\ndef chunk_images(buoy_id,foldername):\n    \"\"\"",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "chunk_images",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def chunk_images(buoy_id,foldername):\n    \"\"\"\n    chunk_images takes a folder of images and splits them into sets of 6 images\n    _extended_summary_\n    :param buoy_id: The id of the buoy\n    :type buoy_id: int\n    :param foldername: The name of the folder containing the images\n    :type foldername: str\n    # \"\"\"\n    # #buoy_id = str(foldername)",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "pull_data",
        "kind": 2,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "def pull_data(cam_url, buoy_id, now):\n    img = requests.get(cam_url) # get the image\n    if img.status_code == 200:\n        return img\n    else:\n        print(\"status code\", img.status_code, \"for buoy\", buoy_id)\n    return img\n# ### Testing the code\n# # detect red in an image\n# # load the image",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "IMAGE_PATH",
        "kind": 5,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "IMAGE_PATH = \"images/keepers/2022_11_5_18_3_panel_3 copy.png\"\nSAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n# model = hub.load(SAVED_MODEL_PATH)\ndef make_panorama(self, images):\n    \"\"\"\n    make_panorama takes a list of images and makes a panorama out of them\n    :param images: _description_\n    :type images: _type_\n    :return: _description_\n    :rtype: _type_",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "SAVED_MODEL_PATH",
        "kind": 5,
        "importPath": "scripts.helper_functions",
        "description": "scripts.helper_functions",
        "peekOfCode": "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n# model = hub.load(SAVED_MODEL_PATH)\ndef make_panorama(self, images):\n    \"\"\"\n    make_panorama takes a list of images and makes a panorama out of them\n    :param images: _description_\n    :type images: _type_\n    :return: _description_\n    :rtype: _type_\n    \"\"\"",
        "detail": "scripts.helper_functions",
        "documentation": {}
    },
    {
        "label": "BuoyImage",
        "kind": 6,
        "importPath": "scripts.import os",
        "description": "scripts.import os",
        "peekOfCode": "class BuoyImage:\n    def __init__(self, image_url, num_panels=6, target_height=500, mse_threshold=2000):\n        self.image_url = image_url\n        self.num_panels = num_panels\n        self.target_height = target_height\n        self.mse_threshold = mse_threshold\n        self.image = self.download_image(image_url)\n        self.resized_image = self.resize_image_to_standard_height()\n        self.panels = self.split_image_into_panels()\n        self.unusual_panels = self.check_unusual_panels()",
        "detail": "scripts.import os",
        "documentation": {}
    },
    {
        "label": "PanoramicImage",
        "kind": 6,
        "importPath": "scripts.import os",
        "description": "scripts.import os",
        "peekOfCode": "class PanoramicImage:\n    def __init__(self, images):\n        self.images = images\n        self.aligned_images = [self.align_horizon_line(img) for img in images]\n        self.stitched_image = self.stitch_aligned_images()\n    def detect_horizon_line(self, img):\n        \"\"\"\n        The detect_horizon_line function takes an image as input and returns the angle of the horizon line.\n        The function uses OpenCV to detect edges in a grayscale version of the image, then uses HoughLinesP to find lines in those edges.\n        It then finds the longest line and calculates its angle using arctan2.",
        "detail": "scripts.import os",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.import os",
        "description": "scripts.import os",
        "peekOfCode": "def main():\n    buoy_urls = [\"buoy_url_1\", \"buoy_url_2\", \"buoy_url_3\"]\n    base_output_path = \"path/to/output/directory\"\n    for buoy_url in buoy_urls:\n        buoy_image = BuoyImage(buoy_url)\n        if any(buoy_image.unusual_panels):\n            current_datetime = datetime.now()\n            date_str = current_datetime.strftime(\"%Y-%m-%d\")\n            time_str = current_datetime.strftime(\"%H-%M-%S\")\n            buoy_name = buoy_url.split(\"/\")[-2]",
        "detail": "scripts.import os",
        "documentation": {}
    },
    {
        "label": "classify_image",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    img_array = keras_image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "get_image_size",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def get_image_size(img):\n    return img.size\ndef mse_between_arrays(arr1, arr2):\n    try:\n        return np.mean((arr1 - arr2) ** 2)\n    except:\n        return 0\ndef crop_the_bottom_off(image, filename):\n    try:\n        img_width, img_height = image.size",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "mse_between_arrays",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def mse_between_arrays(arr1, arr2):\n    try:\n        return np.mean((arr1 - arr2) ** 2)\n    except:\n        return 0\ndef crop_the_bottom_off(image, filename):\n    try:\n        img_width, img_height = image.size\n        cropped_image = image.crop((0, 0, img_width, img_height - 20))\n        # Use the original format when saving the cropped image",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "crop_the_bottom_off",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def crop_the_bottom_off(image, filename):\n    try:\n        img_width, img_height = image.size\n        cropped_image = image.crop((0, 0, img_width, img_height - 20))\n        # Use the original format when saving the cropped image\n        file_format = image.format\n        cropped_image.save(f\"cropped_{filename}\", format=file_format)\n        return cropped_image\n    except Exception as e:\n        print(\"Error cropping the bottom off of the image: \" + str(e))",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "download_image",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def download_image(image_url):\n    response = requests.get(image_url)\n    if response.status_code != 200:\n        print(f\"API response: {response.status_code}\")\n        return None\n    img = Image.open(BytesIO(response.content)).convert('L')  # Convert image to grayscale\n    min_value, max_value = img.getextrema()\n    if max_value < 200:\n        # Rest of the code\n        print(f\"\\nImage too white: {image_url}\")",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "resize_image_to_standard_height",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def resize_image_to_standard_height(image, target_height):\n    if image is None:\n        return None\n    width, height = image.size\n    new_height = target_height\n    new_width = int((new_height / height) * width)\n    return image.resize((new_width, new_height), Image.ANTIALIAS)\ndef split_image_into_panels(resized_image, num_panels):\n    if resized_image is None:\n        return None",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "split_image_into_panels",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def split_image_into_panels(resized_image, num_panels):\n    if resized_image is None:\n        return None\n    width, height = resized_image.size\n    panel_width = width // num_panels\n    panels = []\n    for i in range(num_panels):\n        left = i * panel_width\n        right = left + panel_width\n        panel = resized_image.crop((left, 0, right, height))",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "detect_horizon_line",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def detect_horizon_line(img):\n    img = np.array(img)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    # Use a Gaussian blur to reduce noise before edge detection\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n    edges = cv2.Canny(blurred, 50, 150, apertureSize=3)\n    # Increase the threshold for HoughLinesP to reduce false positives\n    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 150, minLineLength=100, maxLineGap=20)\n    if lines is None:\n        return 0",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "align_horizon_line",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def align_horizon_line(img):\n    img = np.array(img)\n    original = img.copy()\n    tilt_angle = detect_horizon_line(img)\n    height, width = img.shape[:2]\n    center = (width // 2, height // 2)\n    rotation_matrix = cv2.getRotationMatrix2D(center, tilt_angle, 1)\n    aligned_img = cv2.warpAffine(img, rotation_matrix, (width, height), flags=cv2.INTER_LINEAR,\n                                 borderMode=cv2.BORDER_REPLICATE)\n    fixed = aligned_img.copy()",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def mse(image_a, image_b):\n    try:\n        return np.mean((image_a - image_b) ** 2)\n    except:\n        return 0\ndef check_unusual_panels(panels, mse_threshold=1):\n    \"\"\"\n    The check_unusual_panels function takes in a list of panels and returns the indices of the unusual panels.\n    :param panels: Pass the list of panels to be checked\n    :param mse_threshold: Determine the threshold for which a panel is considered unusual",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "check_unusual_panels",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def check_unusual_panels(panels, mse_threshold=1):\n    \"\"\"\n    The check_unusual_panels function takes in a list of panels and returns the indices of the unusual panels.\n    :param panels: Pass the list of panels to be checked\n    :param mse_threshold: Determine the threshold for which a panel is considered unusual\n    :return: A list of panel indices that are unusual, a list of panel indices that have rich colors, and a boolean indicating whether the image is too white\n    :doc-author: Trelent\n    \"\"\"\n    unusual_panels = []\n    rich_color_panels = []",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "detect_horizon_line",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def detect_horizon_line(img):\n    if isinstance(img, PIL.Image.Image):\n        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n    if len(img.shape) == 2 or img.shape[2] == 1:\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    # The rest of the function\n    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=100, maxLineGap=10)\n    try:",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "align_horizon_line",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def align_horizon_line(img):\n    img = np.array(img)\n    original = img.copy()\n    tilt_angle = detect_horizon_line(img)\n    height, width = img.shape[:2]\n    center = (width // 2, height // 2)\n    rotation_matrix = cv2.getRotationMatrix2D(center, tilt_angle, 1)\n    aligned_img = cv2.warpAffine(img, rotation_matrix, (width, height), flags=cv2.INTER_LINEAR,\n                                 borderMode=cv2.BORDER_REPLICATE)\n    fixed = aligned_img.copy()",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "stitch_aligned_images",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def stitch_aligned_images(aligned_images):\n    stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()\n    if len(aligned_images) < 2:\n        print(\"Not enough images to stitch\")\n        return None\n    orb = cv2.ORB_create(nfeatures=1000)\n    for i, img in enumerate(aligned_images):\n        keypoints, _ = orb.detectAndCompute(img, None)\n        print(f\"Image {i + 1} has {len(keypoints)} features\")\n    (status, stitched_image) = stitcher.stitch(aligned_images)",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "load_skipped_buoys",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def load_skipped_buoys(filename):\n    with open(filename, 'r') as f:\n        skipped_buoys = [line.strip() for line in f.readlines()]\n    return skipped_buoys\ndef main():\n    buoy_list_df = pd.read_csv(\"scripts/working_buoys.csv\")\n    skip_buoy_list = pd.read_csv(\"scripts/failing_buoys.csv\")[\"station_id\"].tolist()\n    # make unique list of buoys to process\n    # remove dupes from skip_buoy_list\n    skip_buoy_list = list(set(skip_buoy_list))",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "def main():\n    buoy_list_df = pd.read_csv(\"scripts/working_buoys.csv\")\n    skip_buoy_list = pd.read_csv(\"scripts/failing_buoys.csv\")[\"station_id\"].tolist()\n    # make unique list of buoys to process\n    # remove dupes from skip_buoy_list\n    skip_buoy_list = list(set(skip_buoy_list))\n    buoy_list = buoy_list_df[\"station_id\"].tolist()\n    # remove any skipped buoys from the list\n    buoy_list = [buoy for buoy in buoy_list if buoy not in skip_buoy_list]\n    print(f'There are {len(buoy_list)} buoys to process, we have identified {len(skip_buoy_list)} buoys to skip')",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "collecting_all",
        "kind": 5,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "collecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image as keras_image\nimport PIL\n# MODEL_PATH = 'models/buoy_model/keras_model.h5'\nMODEL_PATH = 'models/gen3_keras/keras_model.h5'\nIMAGE_SIZE = (224, 224)",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "buoy_list",
        "kind": 5,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "buoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image as keras_image\nimport PIL\n# MODEL_PATH = 'models/buoy_model/keras_model.h5'\nMODEL_PATH = 'models/gen3_keras/keras_model.h5'\nIMAGE_SIZE = (224, 224)\n# CLASS_NAMES = ['Direct Sun', 'Stormy Weather', 'Interesting', 'Object Detected', 'Sunset', 'Clouds', 'Night']",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "MODEL_PATH = 'models/gen3_keras/keras_model.h5'\nIMAGE_SIZE = (224, 224)\n# CLASS_NAMES = ['Direct Sun', 'Stormy Weather', 'Interesting', 'Object Detected', 'Sunset', 'Clouds', 'Night']\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\n# 0 Sunset\n# 1 Storms\n# 2 Normal\n# 3 Object In View\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "IMAGE_SIZE",
        "kind": 5,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "IMAGE_SIZE = (224, 224)\n# CLASS_NAMES = ['Direct Sun', 'Stormy Weather', 'Interesting', 'Object Detected', 'Sunset', 'Clouds', 'Night']\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\n# 0 Sunset\n# 1 Storms\n# 2 Normal\n# 3 Object In View\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "scripts.phase_one",
        "description": "scripts.phase_one",
        "peekOfCode": "CLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\n# 0 Sunset\n# 1 Storms\n# 2 Normal\n# 3 Object In View\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)",
        "detail": "scripts.phase_one",
        "documentation": {}
    },
    {
        "label": "Buoy",
        "kind": 6,
        "importPath": "scripts.pyseas",
        "description": "scripts.pyseas",
        "peekOfCode": "class Buoy:\n    \"\"\"Parent class representing a buoy.\"\"\"\n    def __init__(self, buoy_id=\"none\", temperature=\"none\"):\n        \"\"\"Initialize the Buoy class with optional buoy_id and temperature attributes.\"\"\"\n        self.buoy_id = buoy_id\n        self.temperature = temperature\n    def check_buoy(self, buoy_id):\n        \"\"\"Check the buoy with the given buoy_id.\"\"\"\n        self.check_data = 'defaults' # put defaults into the code here\nclass Chosen_Buoy(Buoy):",
        "detail": "scripts.pyseas",
        "documentation": {}
    },
    {
        "label": "Chosen_Buoy",
        "kind": 6,
        "importPath": "scripts.pyseas",
        "description": "scripts.pyseas",
        "peekOfCode": "class Chosen_Buoy(Buoy):\n    \"\"\"Child class of Buoy representing a chosen buoy.\"\"\"\n    def __init__(self, buoy_type=\"none\"):\n        \"\"\"Initialize the Chosen_Buoy class with buoy_lat, buoy_lng, buoy_depth, buoy_temp, and buoy_atmpressure attributes.\"\"\"\n        super().__init__(\"Chosen_Buoy\")\n        self.buoy_lat = 10.0\n        self.buoy_lng = 10.0\n        self.buoy_depth = 10.0\n        self.buoy_temp = 10.0\n        self.buoy_atmpressure = 10.0",
        "detail": "scripts.pyseas",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.pyseas",
        "description": "scripts.pyseas",
        "peekOfCode": "def main():\n    # Get buoy data.\n    product = 'air_temperature'\n    station_id = str(8454000)\n    start_year = str(2021)\n    start_month = '11'\n    start_day = str('11')\n    end_year = str('2021')\n    end_month = str('11')\n    end_day = str(start_day)",
        "detail": "scripts.pyseas",
        "documentation": {}
    },
    {
        "label": "classify_image",
        "kind": 2,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "def classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    img_array = keras_image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "def main():\n    buoy_list_df = pd.read_csv(\"scripts/working_buoys.csv\")\n    skip_buoy_list = pd.read_csv(\"scripts/failing_buoys.csv\")[\"station_id\"].tolist()\n    buoy_urls = buoy_list_df[\"station_id\"].tolist()\n    base_output_path = \"scripts/output\"\n    model = load_model(MODEL_PATH)\n    for buoy_url in tqdm(buoy_urls, desc=\"Processing buoys\"):\n        print(f'Processing {buoy_url}', end='', flush=True)\n        buoy_output_df, processed_images, processed_panels, processed_aligned, processed_stitched, processed_classifications, processed_mse, processed_horizon = process_buoy(buoy_url, model, base_output_path)\n        if buoy_url in skip_buoy_list:",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "MODEL_PATH = 'models/gen3_keras/keras_model.h5'\nIMAGE_SIZE = (224, 224)\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "IMAGE_SIZE",
        "kind": 5,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "IMAGE_SIZE = (224, 224)\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "CLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "output_dir",
        "kind": 5,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "output_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "collecting_all",
        "kind": 5,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "collecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "buoy_list",
        "kind": 5,
        "importPath": "scripts.refact2",
        "description": "scripts.refact2",
        "peekOfCode": "buoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    img_array = keras_image.img_to_array(img)",
        "detail": "scripts.refact2",
        "documentation": {}
    },
    {
        "label": "classify_image",
        "kind": 2,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "def classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    img_array = keras_image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "get_image_size",
        "kind": 2,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "def get_image_size(img):\n    return img.size\ndef mse_between_arrays(arr1, arr2):\n    try:\n        return np.mean((arr1 - arr2) ** 2)\n    except:\n        return 0\ndef crop_the_bottom_off(image, filename):\n    try:\n        img = cv2.imread(image)",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "mse_between_arrays",
        "kind": 2,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "def mse_between_arrays(arr1, arr2):\n    try:\n        return np.mean((arr1 - arr2) ** 2)\n    except:\n        return 0\ndef crop_the_bottom_off(image, filename):\n    try:\n        img = cv2.imread(image)\n        height, width, channels = img.shape\n        crop_img = img[0:height-100, 0:width]",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "crop_the_bottom_off",
        "kind": 2,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "def crop_the_bottom_off(image, filename):\n    try:\n        img = cv2.imread(image)\n        height, width, channels = img.shape\n        crop_img = img[0:height-100, 0:width]\n        cv2.imwrite(filename, crop_img)\n        return filename\n    except:\n        return image\ndef main():",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "def main():\n    # Load the model\n    model = load_model(MODEL_PATH)\n    # Download the images\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    # Process the images\n    for index, row in tqdm(buoy_list.iterrows(), total=buoy_list.shape[0]):\n        # Download the image\n        image_path = download_image(row['image_url'], output_dir)",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "MODEL_PATH = 'models/gen3_keras/keras_model.h5'\nIMAGE_SIZE = (224, 224)\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"images\"\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "IMAGE_SIZE",
        "kind": 5,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "IMAGE_SIZE = (224, 224)\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"images\"\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "CLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"images\"\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "output_dir",
        "kind": 5,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "output_dir = \"images\"\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "buoy_list",
        "kind": 5,
        "importPath": "scripts.refact3",
        "description": "scripts.refact3",
        "peekOfCode": "buoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    img_array = keras_image.img_to_array(img)",
        "detail": "scripts.refact3",
        "documentation": {}
    },
    {
        "label": "classify_image",
        "kind": 2,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "def classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    img_array = keras_image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = img_array / 255.0",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "get_image_size",
        "kind": 2,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "def get_image_size(img):\n    return img.size\ndef mse_between_arrays(arr1, arr2):\n    try:\n        return np.mean((arr1 - arr2) ** 2)\n    except:\n        return 0\ndef crop_the_bottom_off(image, filename):\n    try:\n        img_width, img_height = image.size",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "mse_between_arrays",
        "kind": 2,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "def mse_between_arrays(arr1, arr2):\n    try:\n        return np.mean((arr1 - arr2) ** 2)\n    except:\n        return 0\ndef crop_the_bottom_off(image, filename):\n    try:\n        img_width, img_height = image.size\n        cropped_image = image.crop((0, 0, img_width, img_height - 20))\n        # Use the original format when saving the cropped image",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "crop_the_bottom_off",
        "kind": 2,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "def crop_the_bottom_off(image, filename):\n    try:\n        img_width, img_height = image.size\n        cropped_image = image.crop((0, 0, img_width, img_height - 20))\n        # Use the original format when saving the cropped image\n        file_format = image.format\n        cropped_image.save(f\"cropped_{filename}\", format=file_format)\n        return cropped_image\n    except Exception as e:\n        print(\"Error cropping the bottom off of the image: \" + str(e))",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "process_buoy",
        "kind": 2,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "def process_buoy(buoy_url, model, base_output_path):\n    buoy_id = buoy_url.split(\"/\")[-1]\n    buoy_id = buoy_id.split(\".\")[0]\n    buoy_output_path = os.path.join(base_output_path, buoy_id)\n    if not os.path.exists(buoy_output_path):\n        os.mkdir(buoy_output_path)\n    buoy_images_path = os.path.join(buoy_output_path, \"images\")\n    if not os.path.exists(buoy_images_path):\n        os.mkdir(buoy_images_path)\n    buoy_panels_path = os.path.join(buoy_output_path, \"panels\")",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "def main():\n    buoy_list_df = pd.read_csv(\"scripts/working_buoys.csv\")\n    skip_buoy_list = pd.read_csv(\"scripts/failing_buoys.csv\")[\"station_id\"].tolist()\n    buoy_urls = buoy_list_df[\"station_id\"].tolist()\n    base_output_path = \"scripts/output\"\n    # The rest of the main function body remains the same\n    model = load_model(MODEL_PATH)\n    for buoy_url in tqdm(buoy_urls, desc=\"Processing buoys\"):\n        print(f'Processing {buoy_url}', end='', flush=True)\n        buoy_output_df, processed_images, processed_panels, processed_aligned, processed_stitched, processed_classifications, processed_mse, processed_horizon = process_buoy(buoy_url, model, base_output_path)",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "MODEL_PATH = 'models/gen3_keras/keras_model.h5'\nIMAGE_SIZE = (224, 224)\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "IMAGE_SIZE",
        "kind": 5,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "IMAGE_SIZE = (224, 224)\nCLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "CLASS_NAMES = ['Sunset', 'Storms', 'Normal', 'Object In View']\noutput_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "output_dir",
        "kind": 5,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "output_dir = \"scripts/output\"\ncollecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "collecting_all",
        "kind": 5,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "collecting_all = True\nbuoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "buoy_list",
        "kind": 5,
        "importPath": "scripts.refactoring",
        "description": "scripts.refactoring",
        "peekOfCode": "buoy_list = pd.read_csv(\"scripts/working_buoys.csv\")\n# Classification Functions\ndef classify_image(image, model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n    if not isinstance(image, PIL.Image.Image):\n        img = keras_image.load_img(image, target_size=image_size)\n    else:\n        img = image.resize(image_size)\n    if img.mode != 'RGB':\n        img = img.convert('RGB')\n    img_array = keras_image.img_to_array(img)",
        "detail": "scripts.refactoring",
        "documentation": {}
    },
    {
        "label": "split_into_panels",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def split_into_panels(image, num_panels=6):\n    width, height = image.size\n    panel_width = width // num_panels\n    panels = [image.crop((i * panel_width, 0, (i + 1) * panel_width, height)) for i in range(num_panels)]\n    return panels\ndef crop_bottoms(panels, num_pixels=30):\n    cropped_panels = [panel.crop((0, 0, panel.width, panel.height - num_pixels)) for panel in panels]\n    return cropped_panels\ndef detect_horizon_tilt(panel):\n    horizon_tilt = detect_horizon_line(panel)",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "crop_bottoms",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def crop_bottoms(panels, num_pixels=30):\n    cropped_panels = [panel.crop((0, 0, panel.width, panel.height - num_pixels)) for panel in panels]\n    return cropped_panels\ndef detect_horizon_tilt(panel):\n    horizon_tilt = detect_horizon_line(panel)\n    return horizon_tilt\ndef avg_color_above_horizon(panel, horizon_tilt):\n    panel_array = np.array(panel.rotate(horizon_tilt))\n    height = panel_array.shape[0] // 2\n    sky_array = panel_array[:height]",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "detect_horizon_tilt",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def detect_horizon_tilt(panel):\n    horizon_tilt = detect_horizon_line(panel)\n    return horizon_tilt\ndef avg_color_above_horizon(panel, horizon_tilt):\n    panel_array = np.array(panel.rotate(horizon_tilt))\n    height = panel_array.shape[0] // 2\n    sky_array = panel_array[:height]\n    avg_sky_color = np.mean(sky_array, axis=(0, 1))\n    return avg_sky_color\ndef avg_color_below_horizon(panel, horizon_tilt):",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "avg_color_above_horizon",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def avg_color_above_horizon(panel, horizon_tilt):\n    panel_array = np.array(panel.rotate(horizon_tilt))\n    height = panel_array.shape[0] // 2\n    sky_array = panel_array[:height]\n    avg_sky_color = np.mean(sky_array, axis=(0, 1))\n    return avg_sky_color\ndef avg_color_below_horizon(panel, horizon_tilt):\n    panel_array = np.array(panel.rotate(horizon_tilt))\n    height = panel_array.shape[0] // 2\n    ocean_array = panel_array[height:]",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "avg_color_below_horizon",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def avg_color_below_horizon(panel, horizon_tilt):\n    panel_array = np.array(panel.rotate(horizon_tilt))\n    height = panel_array.shape[0] // 2\n    ocean_array = panel_array[height:]\n    avg_ocean_color = np.mean(ocean_array, axis=(0, 1))\n    return avg_ocean_color\nimport numpy as np\nimport cv2\nfrom PIL import Image\ndef detect_horizon_line(img, resize_dim=None,",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "detect_horizon_line",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def detect_horizon_line(img, resize_dim=None,\n                        blur_kernel_size=5,\n                        canny_low_ratio=0.33,\n                        canny_high_ratio=1.33,\n                        angle_tolerance=10):\n    \"\"\"\n    The detect_horizon_line function takes an image and returns the angle of the horizon line.\n    :param img: Pass in the image to be processed\n    :param resize_dim: Increase the resolution of the image, type(tuple) (width, height)\n    :param blur_kernel_size: Define the size of the kernel used in gaussian blur",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "make_horizon_straight",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def make_horizon_straight(img):\n    # using the horizon tilt, rotate the image to make the horizon straight and return the rotated image\n    horizon_tilt = detect_horizon_line(img,\n                                       resize_dim=(3000, 1500),\n                                        blur_kernel_size=5,\n                                        canny_low_ratio=0.33,\n                                        canny_high_ratio=1.33,\n                                        angle_tolerance=10)\n    print(f'Rotating panel {horizon_tilt} degrees')\n    return img.rotate(horizon_tilt) #",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "stitch_panels",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def stitch_panels(panels):\n    # Get the total width and height of the stitched panorama\n    total_width = sum([panel.width for panel in panels])\n    height = panels[0].height\n    # Create a new image with the total width and the same height as the panels\n    panorama = Image.new(\"RGB\", (total_width, height))\n    # Paste each panel into the new image\n    current_x = 0\n    for panel in panels:\n        panorama.paste(panel, (current_x, 0))",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "add_horizon_line",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def add_horizon_line(img, horizon_tilt):\n    # add a red line where the horizon is detected, at the angle of the horizon tilt\n    img = img.copy()\n    draw = ImageDraw.Draw(img)\n    width, height = img.size\n    horizon_line = height / 2\n    horizon_line = horizon_line + (horizon_tilt / 180) * height / 2\n    draw.line((0, horizon_line, width, horizon_line), fill=(255, 0, 0), width=5)\n    return img\ndef main():",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "clickuptask_alpha1",
        "description": "clickuptask_alpha1",
        "peekOfCode": "def main():\n    # Load and process the image\n    panoramic_image = Image.open(\"W44A_2023_05_07_1710.jpg\")\n    panels = split_into_panels(panoramic_image)\n    cropped_panels = crop_bottoms(panels)\n    # use the make_horizon_straight function to make the horizon straight\n    cropped_panels = [make_horizon_straight(panel) for panel in cropped_panels]\n    horizon_tilts = [detect_horizon_tilt(panel) for panel in cropped_panels]\n    avg_sky_colors = [avg_color_above_horizon(panel, tilt) for panel, tilt in zip(cropped_panels, horizon_tilts)]\n    avg_ocean_colors = [avg_color_below_horizon(panel, tilt) for panel, tilt in",
        "detail": "clickuptask_alpha1",
        "documentation": {}
    },
    {
        "label": "ImageClassifier",
        "kind": 6,
        "importPath": "image_classifier",
        "description": "image_classifier",
        "peekOfCode": "class ImageClassifier:\n    def __init__(self):\n        pass\n    def classify_image(self, image, model, white_model=temp_model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n        if not isinstance(image, PIL.Image.Image):\n            img = keras_image.load_img(image, target_size=image_size)\n        else:\n            img = image.resize(image_size)\n        if img.mode != 'RGB':\n            img = img.convert('RGB')",
        "detail": "image_classifier",
        "documentation": {}
    },
    {
        "label": "IMAGE_SIZE",
        "kind": 5,
        "importPath": "image_classifier",
        "description": "image_classifier",
        "peekOfCode": "IMAGE_SIZE = (224, 224)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"normal\",\n    \"moon\"\n]",
        "detail": "image_classifier",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "image_classifier",
        "description": "image_classifier",
        "peekOfCode": "CLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"normal\",\n    \"moon\"\n]\ntemp_model = load_model('models/blank_or_not_model/keras_model.h5')",
        "detail": "image_classifier",
        "documentation": {}
    },
    {
        "label": "temp_model",
        "kind": 5,
        "importPath": "image_classifier",
        "description": "image_classifier",
        "peekOfCode": "temp_model = load_model('models/blank_or_not_model/keras_model.h5')\nclass ImageClassifier:\n    def __init__(self):\n        pass\n    def classify_image(self, image, model, white_model=temp_model, image_size=IMAGE_SIZE, class_names=CLASS_NAMES):\n        if not isinstance(image, PIL.Image.Image):\n            img = keras_image.load_img(image, target_size=image_size)\n        else:\n            img = image.resize(image_size)\n        if img.mode != 'RGB':",
        "detail": "image_classifier",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def process_image(image):\n    \"\"\"\n    The process_image function takes an image and returns a list of 6 images, representing the 6 horizonally segmented panels of the original image.\n    The function crops the original image into six equal parts, then removes 30 pixels from the bottom to remove\n    the date/time stamp.\n    :param image: Pass in the image that will be processed\n    :return: A list of 6 cropped images\n    :doc-author: Trelent\n    \"\"\"\n    # Get the size of the image",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "analyze_buoys",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def analyze_buoys(model, blank_or_not_model=white_model):\n    \"\"\"\n    The analyze_buoys function takes a model and an optional blank_or_not_model as arguments.\n    It then iterates through the buoy urls, downloading each image and processing it into panels.\n    The function classifies each panel using the ImageClassifier class, which uses the provided model to classify images.\n    If any of those panels are classified as &quot;White&quot;, that buoy is skipped (removed from buoy_urls) and added to skip_buoy list.\n    :param model: Specify which model to use for the classification\n    :param blank_or_not_model: Determine if the image is blank or not\n    :return: A list of the buoys that were skipped due to white panels\n    :doc-author: Trelent",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "refine_list",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def refine_list(buoy_urls, skip_buoy_list):\n    # using the prefixes of the files in the /raw folder, build a list of non-malfunctioing buoys\n    # get the list of files in the /raw folder\n    files = os.listdir('raw')\n    # get the list of buoys from the files\n    buoys = [file.split('_')[0] for file in files]\n    # remove duplicates\n    buoys = list(dict.fromkeys(buoys))\n    return buoys\nfirst_buoys = pd.read_csv(\"scripts/manual_buoys.csv\")[\"station_id\"].tolist()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "MODEL_PATH = 'models/converted_keras/keras_model.h5'\nBLANK_OR_NOT_MODEL_PATH = 'models/blank_or_not_model/keras_model.h5'\n#! Flags\nwhite_mode = False # set to True to use the blank_or_not_model to determine if the image is blank or not\nonly_save_originals = True # set to True to only save the original images and skip saving the panels individually.\nsave_confidence_plots = False # set to True to save the confidence plots\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nmodel = load_model(MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "BLANK_OR_NOT_MODEL_PATH",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "BLANK_OR_NOT_MODEL_PATH = 'models/blank_or_not_model/keras_model.h5'\n#! Flags\nwhite_mode = False # set to True to use the blank_or_not_model to determine if the image is blank or not\nonly_save_originals = True # set to True to only save the original images and skip saving the panels individually.\nsave_confidence_plots = False # set to True to save the confidence plots\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nmodel = load_model(MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "white_mode",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "white_mode = False # set to True to use the blank_or_not_model to determine if the image is blank or not\nonly_save_originals = True # set to True to only save the original images and skip saving the panels individually.\nsave_confidence_plots = False # set to True to save the confidence plots\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nmodel = load_model(MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "only_save_originals",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "only_save_originals = True # set to True to only save the original images and skip saving the panels individually.\nsave_confidence_plots = False # set to True to save the confidence plots\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nmodel = load_model(MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "save_confidence_plots",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "save_confidence_plots = False # set to True to save the confidence plots\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nmodel = load_model(MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"strange sky\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "white_model",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "white_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nmodel = load_model(MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"strange sky\",\n    \"object\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "model = load_model(MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"strange sky\",\n    \"object\",\n    \"normal\",",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "CLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"strange sky\",\n    \"object\",\n    \"normal\",\n    \"moon\"",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "first_buoys",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "first_buoys = pd.read_csv(\"scripts/manual_buoys.csv\")[\"station_id\"].tolist()\n# refined_buoys = if len(refine_list(buoy_urls, skip_buoy_list)) > 0: refine_list(buoy_urls, skip_buoy_list) else: first_buoys\nskip_buoy_list = []\n# Define buoy URLs from the working_buoys.csv file in the scripts folder\nfirst_buoys = pd.read_csv(\"scripts/manual_buoys.csv\")[\"station_id\"].tolist()\nbuoy_urls = pd.read_csv(\"scripts/working_buoys.csv\")[\"station_id\"].tolist()\nbuoy_urls = first_buoys + buoy_urls\n# get unique values\nbuoy_urls = list(dict.fromkeys(buoy_urls))\nif len(refine_list(buoy_urls, skip_buoy_list)) > 0:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "skip_buoy_list",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "skip_buoy_list = []\n# Define buoy URLs from the working_buoys.csv file in the scripts folder\nfirst_buoys = pd.read_csv(\"scripts/manual_buoys.csv\")[\"station_id\"].tolist()\nbuoy_urls = pd.read_csv(\"scripts/working_buoys.csv\")[\"station_id\"].tolist()\nbuoy_urls = first_buoys + buoy_urls\n# get unique values\nbuoy_urls = list(dict.fromkeys(buoy_urls))\nif len(refine_list(buoy_urls, skip_buoy_list)) > 0:\n    refined_buoys = refine_list(buoy_urls, skip_buoy_list)\nelse:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "first_buoys",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "first_buoys = pd.read_csv(\"scripts/manual_buoys.csv\")[\"station_id\"].tolist()\nbuoy_urls = pd.read_csv(\"scripts/working_buoys.csv\")[\"station_id\"].tolist()\nbuoy_urls = first_buoys + buoy_urls\n# get unique values\nbuoy_urls = list(dict.fromkeys(buoy_urls))\nif len(refine_list(buoy_urls, skip_buoy_list)) > 0:\n    refined_buoys = refine_list(buoy_urls, skip_buoy_list)\nelse:\n    refined_buoys = first_buoys\n# Main loop",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "buoy_urls",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "buoy_urls = pd.read_csv(\"scripts/working_buoys.csv\")[\"station_id\"].tolist()\nbuoy_urls = first_buoys + buoy_urls\n# get unique values\nbuoy_urls = list(dict.fromkeys(buoy_urls))\nif len(refine_list(buoy_urls, skip_buoy_list)) > 0:\n    refined_buoys = refine_list(buoy_urls, skip_buoy_list)\nelse:\n    refined_buoys = first_buoys\n# Main loop\nloop_count = 0",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "buoy_urls",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "buoy_urls = first_buoys + buoy_urls\n# get unique values\nbuoy_urls = list(dict.fromkeys(buoy_urls))\nif len(refine_list(buoy_urls, skip_buoy_list)) > 0:\n    refined_buoys = refine_list(buoy_urls, skip_buoy_list)\nelse:\n    refined_buoys = first_buoys\n# Main loop\nloop_count = 0\nsame = 0",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "buoy_urls",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "buoy_urls = list(dict.fromkeys(buoy_urls))\nif len(refine_list(buoy_urls, skip_buoy_list)) > 0:\n    refined_buoys = refine_list(buoy_urls, skip_buoy_list)\nelse:\n    refined_buoys = first_buoys\n# Main loop\nloop_count = 0\nsame = 0\nwhile True:\n    #! IF - we have looped at least 5 times and the length of unique buoys has not changed (i.e. refined_buoys length has not changed) then stop reading the file and use the refined_buoys list with no dupes for the list of buoys to scrape",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "loop_count",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "loop_count = 0\nsame = 0\nwhile True:\n    #! IF - we have looped at least 5 times and the length of unique buoys has not changed (i.e. refined_buoys length has not changed) then stop reading the file and use the refined_buoys list with no dupes for the list of buoys to scrape\n    last_length_refined = len(refined_buoys)\n    loop_count += 1\n    if loop_count > 5 and len(refined_buoys) == last_length_refined:\n        first_buoys = refined_buoys # this is the list of buoys that will be used to scrape now make them urls\n        buoy_urls = [f'https://www.ndbc.noaa.gov/buoycam.php?station={station}' for station in first_buoys]\n        print(Fore.GREEN + f'Using refined_buoys list with {len(refined_buoys)} buoys')",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "same",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "same = 0\nwhile True:\n    #! IF - we have looped at least 5 times and the length of unique buoys has not changed (i.e. refined_buoys length has not changed) then stop reading the file and use the refined_buoys list with no dupes for the list of buoys to scrape\n    last_length_refined = len(refined_buoys)\n    loop_count += 1\n    if loop_count > 5 and len(refined_buoys) == last_length_refined:\n        first_buoys = refined_buoys # this is the list of buoys that will be used to scrape now make them urls\n        buoy_urls = [f'https://www.ndbc.noaa.gov/buoycam.php?station={station}' for station in first_buoys]\n        print(Fore.GREEN + f'Using refined_buoys list with {len(refined_buoys)} buoys')\n        print(Fore.GREEN + f'Loop count: {loop_count}', Style.RESET_ALL)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "refine_list",
        "kind": 2,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "def refine_list(buoy_urls, skip_buoy_list):\n    \"\"\"\n    The refine_list function takes a list of buoys and removes any buoys that are not functioning.\n    It does this by checking the /raw folder for files with the buoy number as a prefix. If there is no file, then it is assumed that the buoy is not working.\n    :param buoy_urls: Pass the list of buoys to the function\n    :param skip_buoy_list: Pass a list of buoys that are known to be malfunctioning\n    :return: A list of buoys that are not in the skip_buoy_list\n    :doc-author: Trelent\n    \"\"\"\n    # using the prefixes of the files in the /raw folder, build a list of non-malfunctioing buoys",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "process_image",
        "kind": 2,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "def process_image(image):\n    \"\"\"\n    The process_image function takes an image and returns a list of 6 images, representing the 6 horizonally segmented panels of the original image.\n    The function crops the original image into six equal parts, then removes 30 pixels from the bottom to remove\n    the date/time stamp.\n    :param image: Pass in the image that will be processed\n    :return: A list of 6 cropped images\n    :doc-author: Trelent\n    \"\"\"\n    width, height = image.size",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "classify_panel",
        "kind": 2,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "def classify_panel(panel, model, white_model):\n    \"\"\"\n    The classify_panel function takes in a panel image and classifies it as one of the following:\n        - 'white' if the average color is greater than 200 (i.e. white)\n        - 'night' if the average color is less than 10 (i.e. black)\n        - otherwise, it uses ImageClassifier to classify_image\n    :param panel: Pass in the image of a panel\n    :param model: Classify the panel as a day or night image\n    :param white_model: Classify panels as white\n    :return: The class of the panel",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "analyze_buoys",
        "kind": 2,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "def analyze_buoys(model, white_model):\n    \"\"\"\n    The analyze_buoys function takes in a model and white_model, which are the models that will be used to classify\n    the images. The function then iterates through each buoy url in the buoy_urls list, downloads the image from that url,\n    and saves it as an Image object. It then processes this image into panels using process_image(), and classifies each panel\n    using ImageClassifier().classify_image() with either model or white_model depending on whether or not it is a night time\n    panel (determined by checking if its average color is less than 10). If there are 6 panels and their average\n    :param model: Classify the image\n    :param white_model: Classify the image as white or not\n    :return: A list of images that are classified as stormy",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "run_analysis_loop",
        "kind": 2,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "def run_analysis_loop():\n    \"\"\"\n    The run_analysis_loop function is the main function that runs the analysis.\n    It first reads in a list of buoys from a csv file, and then loops through each buoy,\n    downloading an image from it's url and running it through our model to get predictions.\n    The results are saved as a csv file for later use.\n    :return: A list of buoy urls\n    :doc-author: Trelent\n    \"\"\"\n    first_buoys = pd.read_csv(\"scripts/manual_buoys.csv\")[\"station_id\"].tolist()",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "def main():\n    \"\"\"\n    The main function is the entry point for this script.\n    It will run a loop that downloads images from NOAA buoy cameras,\n    classifies them using the model specified in load_model(), and then saves them to disk.\n    :return: The output of the analysis loop\n    :doc-author: Trelent\n    \"\"\"\n    first_buoys = pd.read_csv(\"scripts/manual_buoys.csv\")[\"station_id\"].tolist()\n    # refined_buoys = if len(refine_list(buoy_urls, skip_buoy_list)) > 0: refine_list(buoy_urls, skip_buoy_list) else: first_buoys",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "MODEL_PATH",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "MODEL_PATH = 'models/converted_keras/keras_model.h5'\nBLANK_OR_NOT_MODEL_PATH = 'models/blank_or_not_model/keras_model.h5'\nwhite_mode = False\nonly_save_originals = True\nsave_confidence_plots = False\nfrom colorama import Fore, Back, Style\nmodel = load_model(MODEL_PATH)\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "BLANK_OR_NOT_MODEL_PATH",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "BLANK_OR_NOT_MODEL_PATH = 'models/blank_or_not_model/keras_model.h5'\nwhite_mode = False\nonly_save_originals = True\nsave_confidence_plots = False\nfrom colorama import Fore, Back, Style\nmodel = load_model(MODEL_PATH)\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "white_mode",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "white_mode = False\nonly_save_originals = True\nsave_confidence_plots = False\nfrom colorama import Fore, Back, Style\nmodel = load_model(MODEL_PATH)\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "only_save_originals",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "only_save_originals = True\nsave_confidence_plots = False\nfrom colorama import Fore, Back, Style\nmodel = load_model(MODEL_PATH)\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "save_confidence_plots",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "save_confidence_plots = False\nfrom colorama import Fore, Back, Style\nmodel = load_model(MODEL_PATH)\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "model = load_model(MODEL_PATH)\nwhite_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"strange sky\",\n    \"object\",",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "white_model",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "white_model = load_model(BLANK_OR_NOT_MODEL_PATH)\nCLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"strange sky\",\n    \"object\",\n    \"normal\",",
        "detail": "main2",
        "documentation": {}
    },
    {
        "label": "CLASS_NAMES",
        "kind": 5,
        "importPath": "main2",
        "description": "main2",
        "peekOfCode": "CLASS_NAMES = [\n    \"sunset\",\n    \"night\",\n    \"white\",\n    \"storm\",\n    \"clouds\",\n    \"strange sky\",\n    \"object\",\n    \"normal\",\n    \"moon\"",
        "detail": "main2",
        "documentation": {}
    }
]