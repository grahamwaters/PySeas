{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: determine which cameras (on buoys) from NOAA have webcams that are functional and can be used for the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import shutil\n",
    "from difPy import dif\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "# Set up logging file\n",
    "logging.basicConfig(filename='cam_finder.log', level=logging.INFO)\n",
    "\n",
    "import time\n",
    "import random\n",
    "import imutils\n",
    "# import pillow\n",
    "from PIL import Image\n",
    "\n",
    "# the list of buoys to check for cameras are in the file data/buoy_ids.csv\n",
    "with open('data/buoys.csv', 'r') as f:\n",
    "    buoy_ids = f.read().splitlines()\n",
    "\n",
    "# How can we know if a buoy has a camera?\n",
    "# We can check the text of the page for the buoy on the NOAA website for the word \"Camera\"\n",
    "# If the word \"Camera\" is in the text, then we know there is a camera\n",
    "\n",
    "# We can use the requests library to get the text of the page\n",
    "# We can use the BeautifulSoup library to parse the text of the page\n",
    "# We can use the re library to search for the word \"Camera\" in the text of the page\n",
    "\n",
    "# We will store the buoy ids that have cameras in the list cam_buoys\n",
    "cam_buoys = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"21414\",\"21415\",\"21416\",\"21417\",\"21418\",\"21419\",\"32301\",\"32302\",\"32411\",\"32412\",\"32413\",\"41001\",\"41002\",\"41003\",\"41004\",\"41007\",\"41008\",\"41009\",\"41010\",\"41011\",\"41012\",\"41016\",\"41017\",\"41018\",\"41021\",\"41022\",\"41023\",\"41036\",\"41040\",\"41041\",\"41043\",\"41044\",\"41046\",\"41049\",\"41420\",\"41421\",\"41424\",\"41425\",\"42001\",\"42002\",\"42003\",\"42004\",\"42007\",\"42008\",\"42009\",\"42010\",\"42011\",\"42012\",\"42017\",\"42018\",\"42019\",\"42020\",\"42025\",\"42035\",\"42038\",\"42039\",\"42040\",\"42041\",\"42042\",\"42053\",\"42056\",\"42057\",\"42058\",\"42059\",\"42060\",\"42065\",\"42408\",\"42409\",\"42429\",\"42501\",\"42503\",\"42534\",\"44001\",\"44003\",\"44004\",\"44005\",\"44006\",\"44007\",\"44010\",\"44011\",\"44012\",\"44013\",\"44014\",\"44015\",\"44019\",\"44020\",\"44023\",\"44025\",\"44026\",\"44027\",\"44066\",\"44070\",\"44071\",\"44401\",\"44402\",\"44403\",\"45002\",\"45003\",\"45004\",\"45005\",\"45006\",\"45007\",\"45010\",\"45011\",\"45012\",\"46001\",\"46002\",\"46003\",\"46007\",\"46008\",\"46009\",\"46010\",\"46011\",\"46012\",\"46015\",\"46016\",\"46017\",\"46018\",\"46019\",\"46020\",\"46023\",\"46024\",\"46025\",\"46026\",\"46027\",\"46028\",\"46031\",\"46032\",\"46033\",\"46034\",\"46035\",\"46037\",\"46040\",\"46041\",\"46042\",\"46043\",\"46045\",\"46047\",\"46051\",\"46053\",\"46054\",\"46059\",\"46060\",\"46061\",\"46066\",\"46069\",\"46070\",\"46071\",\"46072\",\"46073\",\"46077\",\"46078\",\"46079\",\"46080\",\"46081\",\"46082\",\"46085\",\"46086\",\"46087\",\"46088\",\"46089\",\"46090\",\"46107\",\"46115\",\"46270\",\"46290\",\"46401\",\"46402\",\"46405\",\"46406\",\"46407\",\"46408\",\"46409\",\"46410\",\"46413\",\"46414\",\"46415\",\"46416\",\"46419\",\"46490\",\"46779\",\"46780\",\"46781\",\"46782\",\"46785\",\"51000\",\"51001\",\"51002\",\"51003\",\"51004\",\"51005\",\"51028\",\"51100\",\"51101\",\"51406\",\"51407\",\"51425\",\"52009\",\"52401\",\"52402\",\"52403\",\"52404\",\"52405\",\"91204\",\"91222\",\"91251\",\"91328\",\"91338\",\"91343\",\"91356\",\"91365\",\"91374\",\"91377\",\"91411\",\"91442\",\"46265\",\"41670\",\"41852\",\"41904\",\"41933\",\"48916\",\"48917\",\"52838\",\"52839\",\"52840\",\"52841\",\"52842\",\"52843\",\"52862\",\"55012\",\"55013\",\"55015\",\"55016\",\"55023\",\"55042\",\"58952\",\"31052\",\"31053\",\"41052\",\"41053\",\"41056\",\"41058\",\"41115\",\"41121\",\"41030\",\"44042\",\"44043\",\"44057\",\"44058\",\"44059\",\"44061\",\"44064\",\"44068\",\"45016\",\"45017\",\"45018\",\"45019\",\"45177\",\"45202\",\"45203\",\"45204\",\"45205\",\"45206\",\"45207\",\"46116\",\"46117\",\"46127\",\"42014\",\"42021\",\"42022\",\"42023\",\"42024\",\"42026\",\"32404\",\"41029\",\"41033\",\"41037\",\"41038\",\"41064\",\"41065\",\"41110\",\"41119\",\"41159\",\"32488\",\"41193\",\"44138\",\"44139\",\"44140\",\"44141\",\"44142\",\"44150\",\"44176\",\"44235\",\"44251\",\"44255\",\"44258\",\"44488\",\"45132\",\"45135\",\"45136\",\"45137\",\"45138\",\"45139\",\"45142\",\"45143\",\"45144\",\"45145\",\"45147\",\"45148\",\"45151\",\"45152\",\"45154\",\"45155\",\"45158\",\"45159\",\"46036\",\"46131\",\"46132\",\"46084\",\"46134\",\"46138\",\"46139\",\"46147\",\"46181\",\"46183\",\"46184\",\"46185\",\"46204\",\"46207\",\"46208\",\"46303\",\"46304\",\"48021\",\"45162\",\"45163\",\"45195\",\"23219\",\"23227\",\"32067\",\"32068\",\"42087\",\"42088\",\"42089\",\"42090\",\"46109\",\"46110\",\"46111\",\"46112\",\"21346\",\"21347\",\"21348\",\"21595\",\"21597\",\"21598\",\"21637\",\"21640\",\"22102\",\"22103\",\"22104\",\"22105\",\"22106\",\"22107\",\"45029\",\"45164\",\"45165\",\"45168\",\"45169\",\"45176\",\"46091\",\"46092\",\"62091\",\"62092\",\"62093\",\"62094\",\"41097\",\"41098\",\"41100\",\"41101\",\"41300\",\"61001\",\"45025\",\"45175\",\"44039\",\"44040\",\"44060\",\"23220\",\"23223\",\"23225\",\"46261\",\"46263\",\"48901\",\"48908\",\"48909\",\"48912\",\"44024\",\"44029\",\"44030\",\"44031\",\"44032\",\"44033\",\"44036\",\"44037\",\"45172\",\"45173\",\"46118\",\"46119\",\"46531\",\"46534\",\"46538\",\"46565\",\"44075\",\"44076\",\"44077\",\"44078\",\"46097\",\"46098\",\"51046\",\"51201\",\"51202\",\"51203\",\"51204\",\"51205\",\"51208\",\"51209\",\"51210\",\"51211\",\"51212\",\"51213\",\"52202\",\"52211\",\"13002\",\"13008\",\"13009\",\"13010\",\"15001\",\"15002\",\"31001\",\"31002\",\"31003\",\"31004\",\"31005\",\"31006\",\"62121\",\"62124\",\"62125\",\"62126\",\"62127\",\"62130\",\"62144\",\"62145\",\"62146\",\"62147\",\"62148\",\"62149\",\"62165\",\"62166\",\"63105\",\"63110\",\"63112\",\"63113\",\"14041\",\"14043\",\"14047\",\"23001\",\"23003\",\"23004\",\"23008\",\"23009\",\"23010\",\"23011\",\"23012\",\"23013\",\"23016\",\"23017\",\"53005\",\"53006\",\"53009\",\"53040\",\"56053\",\"01506\",\"01507\",\"01518\",\"01537\",\"48904\",\"48907\",\"01521\",\"01522\",\"01523\",\"01524\",\"01526\",\"01531\",\"01535\",\"01536\",\"01538\",\"01909\",\"01910\",\"31201\",\"41112\",\"41113\",\"41114\",\"41116\",\"41118\",\"41120\",\"42084\",\"42091\",\"42094\",\"42099\",\"44088\",\"44094\",\"44099\",\"44100\",\"44172\",\"46114\",\"46211\",\"46212\",\"46215\",\"46216\",\"46217\",\"46218\",\"46219\",\"46220\",\"46223\",\"46224\",\"46225\",\"46226\",\"46227\",\"46228\",\"46231\",\"46232\",\"46234\",\"46235\",\"46236\",\"46237\",\"46240\",\"46241\",\"46242\",\"46243\",\"46244\",\"46245\",\"46249\",\"46250\",\"46251\",\"46253\",\"46254\",\"46256\",\"46262\",\"46267\",\"46268\",\"46269\",\"46273\",\"46274\",\"51200\",\"48212\",\"48213\",\"48214\",\"48677\",\"48678\",\"48679\",\"48680\",\"48911\",\"42044\",\"42045\",\"42046\",\"42047\",\"42048\",\"42049\",\"42078\",\"42079\",\"42093\",\"42095\",\"42097\",\"44056\",\"45180\",\"46259\",\"46266\",\"62028\",\"62029\",\"62030\",\"62050\",\"62081\",\"62103\",\"62108\",\"62163\",\"62170\",\"62298\",\"62301\",\"62303\",\"62442\",\"64045\",\"44098\",\"46121\",\"46122\",\"46123\",\"46124\",\"28902\",\"28903\",\"28904\",\"28906\",\"28907\",\"28908\",\"58900\",\"58902\",\"58903\",\"58904\",\"58905\",\"58906\",\"58909\",\"68900\",\"78900\",\"45014\",\"45184\",\"44053\",\"01517\",\"32012\",\"41060\",\"41061\",\"21D20\",\"32D12\",\"32D13\",\"41A46\",\"41S43\",\"41S46\",\"46B35\",\"ALSN6\",\"AMAA2\",\"AUGA2\",\"BLIA2\",\"BURL1\",\"BUSL1\",\"CDRF1\",\"CHLV2\",\"CLKN7\",\"CSBF1\",\"DBLN6\",\"DESW1\",\"DRFA2\",\"DRYF1\",\"DSLN7\",\"DUCN7\",\"EB01\",\"EB10\",\"EB33\",\"EB35\",\"EB36\",\"EB43\",\"EB52\",\"EB53\",\"EB70\",\"EB90\",\"EB91\",\"EB92\",\"FARP2\",\"FBIS1\",\"FPSN7\",\"FWYF1\",\"GBCL1\",\"GDIL1\",\"GLLN6\",\"IOSN3\",\"LONF1\",\"LPOI1\",\"MDRM1\",\"MISM1\",\"MLRF1\",\"MPCL1\",\"PILA2\",\"PILM4\",\"PLSF1\",\"POTA2\",\"PTAC1\",\"PTAT2\",\"SANF1\",\"SAUF1\",\"SBIO1\",\"SGNW3\",\"SGOF1\",\"SISW1\",\"SPGF1\",\"SRST2\",\"STDM4\",\"SUPN6\",\"SVLS1\",\"THIN6\",\"VENF1\",\"HBXC1\",\"MYXC1\",\"TDPC1\",\"FSTI2\",\"DMNO3\",\"GPTW1\",\"HMNO3\",\"PRTO3\",\"SEFO3\",\"SETO3\",\"SRAW1\",\"SRFW1\",\"TANO3\",\"ANMF1\",\"ARPF1\",\"BGCF1\",\"CAMF1\",\"CLBF1\",\"EGKF1\",\"NFBF1\",\"PTRF1\",\"SHPF1\",\"MBIN7\",\"MBNN7\",\"OCPN7\",\"BSCA1\",\"CRTA1\",\"DPHA1\",\"KATA1\",\"MBLA1\",\"MHPA1\",\"SACV4\",\"BBSF1\",\"BDVF1\",\"BKYF1\",\"BNKF1\",\"BOBF1\",\"BSKF1\",\"CNBF1\",\"CWAF1\",\"DKKF1\",\"GBIF1\",\"GBTF1\",\"GKYF1\",\"JBYF1\",\"JKYF1\",\"LBRF1\",\"LBSF1\",\"LMDF1\",\"LMRF1\",\"LSNF1\",\"MDKF1\",\"MNBF1\",\"MUKF1\",\"NRRF1\",\"PKYF1\",\"TCVF1\",\"THRF1\",\"TPEF1\",\"TRRF1\",\"WIWF1\",\"WPLF1\",\"APNM4\",\"CHII2\",\"MCYI3\",\"SRLM4\",\"SVNM4\",\"TBIM4\",\"THLO1\",\"LCIY2\",\"LLBP7\",\"FWIC3\",\"MISC3\",\"MISN6\",\"NCSC3\",\"NOSC3\",\"OFPN6\",\"ILDL1\",\"MRSL1\",\"SIPM6\",\"SLPL1\",\"LUML1\",\"TAML1\",\"AKXA2\",\"APMA2\",\"BEXA2\",\"CDXA2\",\"CPXA2\",\"DHXA2\",\"DPXA2\",\"ERXA2\",\"GBXA2\",\"GEXA2\",\"GIXA2\",\"GPXA2\",\"HMSA2\",\"ICYA2\",\"JLXA2\",\"JMLA2\",\"JNGA2\",\"KEXA2\",\"KNXA2\",\"KOZA2\",\"LIXA2\",\"MIXA2\",\"MRNA2\",\"MRYA2\",\"NKLA2\",\"NKXA2\",\"NLXA2\",\"NMXA2\",\"NSXA2\",\"PAUA2\",\"PEXA2\",\"PGXA2\",\"PPXA2\",\"PTLA2\",\"RIXA2\",\"SCXA2\",\"SIXA2\",\"SKXA2\",\"SLXA2\",\"SPXA2\",\"SRXA2\",\"STXA2\",\"SXXA2\",\"TKEA2\",\"TPXA2\",\"UQXA2\",\"VDXA2\",\"WCXA2\",\"MSG10\",\"MSG12\",\"ACQS1\",\"ACXS1\",\"ANMN6\",\"ANRN6\",\"APQF1\",\"APXA2\",\"BILW3\",\"BRIM2\",\"BSLM2\",\"BVQW1\",\"CHNO3\",\"CHQO3\",\"CWQT2\",\"DBQS1\",\"DEQD1\",\"DRSD1\",\"EAZC1\",\"EHSC1\",\"EVMC1\",\"FFFC1\",\"GBHM6\",\"GBQN3\",\"GBRM6\",\"GDQM6\",\"GGGC1\",\"GTQF1\",\"GTXF1\",\"HBMN6\",\"HMRA2\",\"HUQN6\",\"JCTN4\",\"JOBP4\",\"JOQP4\",\"JOXP4\",\"KCHA2\",\"LTQM2\",\"MIST2\",\"MQMT2\",\"MWQT2\",\"NAQR1\",\"NAXR1\",\"NIQS1\",\"NOXN7\",\"NPQN6\",\"NPXN6\",\"OWDO1\",\"OWQO1\",\"OWSO1\",\"PBLW1\",\"PKBW3\",\"RKQF1\",\"RKXF1\",\"RYEC1\",\"SAQG1\",\"SCQC1\",\"SCQN6\",\"SEQA2\",\"SFXC1\",\"SKQN6\",\"SLOO3\",\"TCSV2\",\"TIQC1\",\"TIXC1\",\"TKPN6\",\"WAQM3\",\"WAXM3\",\"WELM1\",\"WEQM1\",\"WEXM1\",\"WKQA1\",\"WKXA1\",\"WYBS1\",\"NLMA3\",\"SBBN2\",\"SLMN2\",\"BAXC1\",\"BDRN4\",\"BDSP1\",\"BGNN6\",\"BKBF1\",\"BLIF1\",\"BRND1\",\"CHCM2\",\"CHYV2\",\"COVM2\",\"CPMW1\",\"CPNW1\",\"CRYV2\",\"DELD1\",\"DMSF1\",\"DOMV2\",\"DPXC1\",\"EBEF1\",\"FMOA1\",\"FRVM3\",\"FRXM3\",\"FSKM2\",\"FSNM2\",\"GCTF1\",\"LNDC1\",\"LQAT2\",\"LTJF1\",\"MBPA1\",\"MCGA1\",\"MHBT2\",\"MRCP1\",\"MTBF1\",\"MZXC1\",\"NBLP1\",\"NFDF1\",\"NWHC3\",\"OMHC1\",\"OPTF1\",\"PDVR1\",\"PEGF1\",\"PFDC1\",\"PFXC1\",\"PPTM2\",\"PPXC1\",\"PRJC1\",\"PRUR1\",\"PSBC1\",\"PSXC1\",\"PTOA1\",\"PVDR1\",\"PXAC1\",\"PXOC1\",\"PXSC1\",\"QPTR1\",\"RPLV2\",\"RTYC1\",\"SEIM1\",\"SJSN4\",\"SKCF1\",\"SWPM4\",\"TCNW1\",\"TLVT2\",\"TPAF1\",\"TSHF1\",\"TXVT2\",\"UPBC1\",\"WDSV2\",\"ACYN4\",\"ADKA2\",\"AGCM4\",\"ALIA2\",\"ALXN6\",\"AMRL1\",\"APAM2\",\"APCF1\",\"APRP7\",\"ASTO3\",\"ATGM1\",\"ATKA2\",\"BEPB6\",\"BFTN7\",\"BHBM3\",\"BISM2\",\"BKTL1\",\"BLTM2\",\"BYGL1\",\"BZBM3\",\"CAMM2\",\"CAPL1\",\"CARL1\",\"CASM1\",\"CECC1\",\"CFWM1\",\"CHAO3\",\"CHAV3\",\"CHBV2\",\"CHSV3\",\"CHYW1\",\"CLBP4\",\"CMAN4\",\"CMTI2\",\"CNDO1\",\"CRVA2\",\"DILA1\",\"DKCM6\",\"DTLM4\",\"DUKN7\",\"DULM5\",\"EBSW1\",\"ERTF1\",\"ESPP4\",\"FAIO1\",\"FCGT2\",\"FMRF1\",\"FOXR1\",\"FPTT2\",\"FRCB6\",\"FRDF1\",\"FRDW1\",\"FREL1\",\"FRPS1\",\"FTPC1\",\"GBWW3\",\"GCVF1\",\"GDMM5\",\"GISL1\",\"GNJT2\",\"GTOT2\",\"GWPM6\",\"HBYC1\",\"HCGN7\",\"HLNM4\",\"HMDO3\",\"ICAC1\",\"IIWC1\",\"ILOH1\",\"ITKA2\",\"JMPN7\",\"JNEA2\",\"KECA2\",\"KGCA2\",\"KLIH1\",\"KPTN6\",\"KPTV2\",\"KWHH1\",\"KYWF1\",\"LABL1\",\"LAMV3\",\"LAPW1\",\"LCLL1\",\"LDTM4\",\"LOPW1\",\"LPNM4\",\"LTBV3\",\"LTRM4\",\"LWSD1\",\"LWTV2\",\"MBRM4\",\"MCGM4\",\"MCYF1\",\"MEYC1\",\"MGIP4\",\"MGZP4\",\"MOKH1\",\"MQTT2\",\"MRHO1\",\"MROS1\",\"MTKN6\",\"MTYC1\",\"NEAW1\",\"NIAN6\",\"NJLC1\",\"NKTA2\",\"NLNC3\",\"NMTA2\",\"NTBC1\",\"NTKM3\",\"NUET2\",\"NWCL1\",\"NWPR1\",\"NWWH1\",\"OCIM2\",\"OHBC1\",\"OLSA2\",\"OOUH1\",\"ORIN7\",\"OSGN6\",\"PCBF1\",\"PCLF1\",\"PCOC1\",\"PGBP7\",\"PHBP1\",\"PLXA2\",\"PNLM6\",\"PORO3\",\"PRDA2\",\"PRYC1\",\"PSBM1\",\"PSLC1\",\"PTAW1\",\"PTIM4\",\"PTIT2\",\"PTWW1\",\"RARM6\",\"RCKM4\",\"RCYF1\",\"RDDA2\",\"RDYD1\",\"SAPF1\",\"SBEO3\",\"SBLF1\",\"SDBC1\",\"SDHN4\",\"SHBL1\",\"SJNP4\",\"SKTA2\",\"SLIM2\",\"SNDP5\",\"SWLA2\",\"SWPV2\",\"TESL1\",\"THRO1\",\"TLBO3\",\"TRDF1\",\"TXPT2\",\"ULAM6\",\"ULRA2\",\"UNLA2\",\"VAKF1\",\"VDZA2\",\"WAHV2\",\"WAKP8\",\"WASD2\",\"WAVM6\",\"WLON7\",\"WPTW1\",\"WYCM6\",\"YATA2\",\"BLTA2\",\"CDEA2\",\"EROA2\",\"LCNA2\",\"PBPA2\",\"PRTA2\",\"SDIA2\",\"AGMW3\",\"BHRI3\",\"BIGM4\",\"BSBM4\",\"CBRW3\",\"CLSM4\",\"FPTM4\",\"GBLW3\",\"GRMM4\",\"GSLM4\",\"GTLM4\",\"GTRM4\",\"KP53\",\"KP58\",\"KP59\",\"LSCM4\",\"MEEM4\",\"NABM4\",\"PCLM4\",\"PNGW3\",\"PRIM4\",\"PSCM4\",\"PWAW3\",\"SBLM4\",\"SPTM4\",\"SXHW3\",\"SYWW3\",\"TAWM4\",\"WFPM4\",\"BARN6\",\"CBLO1\",\"CHDS1\",\"CMPO1\",\"GELO1\",\"HHLO1\",\"LORO1\",\"NREP1\",\"OLCN6\",\"RPRN6\",\"WATS1\",\"AUDP4\",\"FRDP4\",\"PLSP4\",\"VQSP4\",\"CGCL1\",\"SKMG1\",\"SPAG1\",\"AVAN4\",\"BRBN4\",\"OCGN4\",\"AWRT2\",\"BABT2\",\"BZST2\",\"CLLT2\",\"CPNT2\",\"EMAT2\",\"GRRT2\",\"HIST2\",\"IRDT2\",\"LUIT2\",\"LYBT2\",\"MGPT2\",\"NWST2\",\"PACT2\",\"PCGT2\",\"PCNT2\",\"PMNT2\",\"PORT2\",\"RSJT2\",\"RTAT2\",\"RTOT2\",\"SDRT2\",\"SGNT2\",\"TAQT2\",\"BTHD1\",\"FRFN7\",\"JPRN7\",\"18CI3\",\"20CM4\",\"GDIV2\",\"32ST0\",\"41NT0\"]\n",
    "buoy_ids = ids\n",
    "\n",
    "buoy_ids_with_cameras = [] # blank list to store buoy ids with cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1219/1219 [00:00<00:00, 300827.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through the buoy ids\n",
    "for buoy_id in tqdm(buoy_ids):\n",
    "    # if the page text needs to be retrieved then do so, else pull from the text files\n",
    "    if not os.path.exists('data/buoy_pages/{}.txt'.format(buoy_id)):\n",
    "        # get the page text\n",
    "        time.sleep(1)\n",
    "        page = requests.get('https://www.ndbc.noaa.gov/station_page.php?station={}'.format(buoy_id))\n",
    "        # write the page text to a file\n",
    "        with open('data/buoy_pages/{}.txt'.format(buoy_id), 'w+') as f:\n",
    "            f.write(page.text)\n",
    "        if 'Buoy Camera' in page.text:\n",
    "            # save the buoy id to the list of buoy ids with cameras\n",
    "            buoy_ids_with_cameras.append(buoy_id)\n",
    "            with open('data/buoy_ids_with_cameras.txt', 'a+') as f:\n",
    "                f.write(buoy_id + ',')\n",
    "    else:\n",
    "        # read the page text from a file\n",
    "        # with open('data/buoy_pages/{}.txt'.format(buoy_id), 'r') as f:\n",
    "        #     page = f.read()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the page text\n",
    "cam_buoys = [] # blank list to store buoy ids with cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1219/1219 [01:03<00:00, 19.31it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# open each buoy page text file in data/buoy_pages and parse the page text\n",
    "for buoy_page in tqdm(os.listdir('data/buoy_pages')):\n",
    "    with open('data/buoy_pages/{}'.format(buoy_page), 'r') as f:\n",
    "        page = f.read() # read the page text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    # search for the word \"Camera\" in the page text\n",
    "    if re.search('Camera', soup.text):\n",
    "        # if the word \"Camera\" is in the page text, then the buoy has a camera.\n",
    "        # save the name of the file (without the .txt extension) to the list of buoy ids with cameras (cam_buoys) array.\n",
    "        cam_buoys.append(buoy_page.replace('.txt', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61 buoys with functional cameras.\n",
      "These have been saved in the cam_buoys array.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Found {len(cam_buoys)} buoys with functional cameras.')\n",
    "# save them to the file data/buoys.csv\n",
    "with open('data/buoys.csv', 'w+') as f:\n",
    "    f.write(\"'buoy_id',\\n\") # could add lat and lng later\n",
    "    for buoy_id in cam_buoys:\n",
    "        f.write('{},\\n'.format(buoy_id))\n",
    "print('These have been saved in the cam_buoys array.')\n",
    "\n",
    "#46078 is functional and very interesting as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 752507.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These have been saved in the cam_urls array.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# building the urls for the cameras\n",
    "cam_urls = [] # blank list to store the camera urls\n",
    "for buoy_id in tqdm(cam_buoys):\n",
    "    cam_url = 'https://www.ndbc.noaa.gov/buoycam.php?station={}'.format(buoy_id)\n",
    "    cam_urls.append(cam_url) # add the camera url to the list of camera urls\n",
    "\n",
    "# save the camera urls to the file data/camera_urls.csv\n",
    "with open('data/camera_urls.csv', 'w+') as f:\n",
    "    f.write(\"'cam_url',\\n\")\n",
    "    for cam_url in cam_urls:\n",
    "        f.write('{},\\n'.format(cam_url))\n",
    "\n",
    "print('These have been saved in the cam_urls array.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def panel_sorter():\n",
    "    # Go into each panel directory and sort the images into folders by the date in their filename (if they haven't already been sorted)\n",
    "    # example unsorted directory: 'images/panels/46078/2022_11_5_15_44_panel_1.png'\n",
    "    # example sorted directory: images/panels/51000/2022_11_5_15_44/panel_1.png\n",
    "\n",
    "    for buoy_id in os.listdir('images/panels'):\n",
    "        if buoy_id != '.DS_Store' and '.' not in buoy_id:\n",
    "            for image in os.listdir('images/panels/{}'.format(buoy_id)):\n",
    "                if image != '.DS_Store' and '.' not in image:\n",
    "                    try:\n",
    "                        # find the 2022_11_5_15_44 (#_#_#_#_#) part of the filename and make a new folder with that name.\n",
    "                        # move the image that contain the matching pattern in their filename into the new folder\n",
    "                        # if the folder already exists, then move the image into the existing folder\n",
    "                        # if the folder doesn't exist, then create the folder and move the image into the new folder\n",
    "                        # if the image has already been moved into a folder, then skip it\n",
    "                        # if the image is the .DS_Store file, then skip it\n",
    "                        # if the image is None, then skip it\n",
    "                    \n",
    "                        pattern = re.compile(r'\\d{4}_\\d{1,2}_\\d{1,2}_\\d{1,2}_\\d{1,2}') # create a pattern to match the date in the filename\n",
    "                        match = pattern.search(image) # search the filename for the date\n",
    "                        if match:\n",
    "                            date = match.group() # get the date from the match\n",
    "                            if not os.path.exists('images/panels/{}/{}'.format(buoy_id, date)): # if the folder doesn't exist, then create it\n",
    "                                os.makedirs('images/panels/{}/{}'.format(buoy_id, date)) # create the folder\n",
    "                            shutil.move('images/panels/{}/{}'.format(buoy_id, image), 'images/panels/{}/{}/{}'.format(buoy_id, date, image)) # move the image into the new folder\n",
    "                        else:\n",
    "                            pass\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "# Image Processing Functions\n",
    "# we have the images in the images/buoys directory already downloaded.\n",
    "\n",
    "def divide_into_panels(buoy_id, image_file):\n",
    "    # divide the image into six panels, as dictated in the image processing pipeline for NOAA Buoy Cameras Comments above.\n",
    "\n",
    "    # read the image\n",
    "    img = cv2.imread(image_file)\n",
    "    # get the name of the image file\n",
    "    image_name = image_file.split('/')[-1]\n",
    "\n",
    "    # get the dimensions of the image\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    # Before dividing into panels, crop the image to remove 30 pixels from the bottom of the image.\n",
    "    # This is to remove the \"Buoy Camera\" text from the image.\n",
    "    # img = img[0:height-30, 0:width]\n",
    "\n",
    "    # divide the image into six panels named: image_name_panel_#.jpg\n",
    "    image_name = image_name.replace('.jpg', '') # remove the .jpg extension for now\n",
    "    panel_1 = img[0:height-30, 0:int(width/6)]\n",
    "    cv2.imwrite('images/panels/{}/{}_panel_1.png'.format(buoy_id, image_name), panel_1)\n",
    "    panel_2 = img[0:height-30, int(width/6):int(width/3)]\n",
    "    cv2.imwrite('images/panels/{}/{}_panel_2.png'.format(buoy_id, image_name), panel_2)\n",
    "    panel_3 = img[0:height-30, int(width/3):int(width/2)]\n",
    "    cv2.imwrite('images/panels/{}/{}_panel_3.png'.format(buoy_id, image_name), panel_3)\n",
    "    panel_4 = img[0:height-30, int(width/2):int(width*2/3)]\n",
    "    cv2.imwrite('images/panels/{}/{}_panel_4.png'.format(buoy_id, image_name), panel_4)\n",
    "    panel_5 = img[0:height-30, int(width*2/3):int(width*5/6)]\n",
    "    cv2.imwrite('images/panels/{}/{}_panel_5.png'.format(buoy_id, image_name), panel_5)\n",
    "    panel_6 = img[0:height-30, int(width*5/6):width]\n",
    "    cv2.imwrite('images/panels/{}/{}_panel_6.png'.format(buoy_id, image_name), panel_6)\n",
    "    return panel_1, panel_2, panel_3, panel_4, panel_5, panel_6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "def is_it_daytime(image_path):\n",
    "    # This function will take an image path and return True if it is daytime and False if it is nighttime.\n",
    "    # The image path should be a string.\n",
    "    # The image path should be the path to the image that was used to create the panels.\n",
    "    # The image path should be in the format 'images/buoys/46025/2019_12_12_12_12.jpg'\n",
    "    \n",
    "    # get the image\n",
    "    img = Image.open(image_path)\n",
    "    # get the image size\n",
    "    width, height = img.size\n",
    "    # get the pixel values for the center of the image\n",
    "    pixel_values = img.getpixel((int(width/2), int(height/2)))\n",
    "    # get the pixel values for the top left corner of the image\n",
    "    upper_left = img.getpixel((0, 0))\n",
    "    # get the pixel values for the top right corner of the image\n",
    "    upper_right = img.getpixel((width-1, 0))\n",
    "    \n",
    "    # get the pixel values for the centers of the six panels in the image\n",
    "    panel_1 = img.getpixel((int(width/12), int(height/2)))\n",
    "    panel_2 = img.getpixel((int(width/4), int(height/2)))\n",
    "    panel_3 = img.getpixel((int(width/2), int(height/2)))\n",
    "    panel_4 = img.getpixel((int(width*3/4), int(height/2)))\n",
    "    panel_5 = img.getpixel((int(width*5/6), int(height/2)))\n",
    "    panel_6 = img.getpixel((int(width*11/12), int(height/2)))\n",
    "\n",
    "    # put those pixel values into a list\n",
    "    pixels_array = [pixel_values, upper_left, upper_right, panel_1, panel_2, panel_3, panel_4, panel_5, panel_6]\n",
    "    brights = []\n",
    "    \n",
    "    # get the red, green, and blue values\n",
    "    red, green, blue = pixel_values\n",
    "\n",
    "    # for the panels\n",
    "    for measurement in pixel_values[3:]:\n",
    "        # calculate the brightness\n",
    "        brightness = math.sqrt(0.241*(red**2) + 0.691*(green**2) + 0.068*(blue**2)) # this is the formula for brightness\n",
    "        # add the brightness to the list\n",
    "        brights.append(brightness) # add the brightness to the list of brightnesses\n",
    "    # get the median brightness\n",
    "    median_brightness = np.median(brights)\n",
    "\n",
    "    # if the red value is greater than 200, then it is unusual and we want to return True\n",
    "    \n",
    "    # print('median brightness: {}'.format(median_brightness))\n",
    "    # print('red: {}'.format(red))\n",
    "    # print('green: {}'.format(green))\n",
    "    # print('blue: {}'.format(blue))\n",
    "    \n",
    "    if red > 200 and median_brightness > 25:\n",
    "        return True\n",
    "    # if over 95% of the colors in the image are pure white it is a blank image and we will return False\n",
    "    if median_brightness > 350:\n",
    "        return False\n",
    "    # if the brightness is greater than 100, it is daytime\n",
    "    if median_brightness > 50:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of the buoys with cameras we can isolate these, create the urls, and download the latest images to the images folder. We will use the requests library to download the images and the os library to create the folder structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these photos are a series of six panels spread horizontally to create a panorama of the area around the buoy. The first step is to isolate the panels and then crop them to the size of the camera. We will use Python and CV2 to do this.\n",
    "\n",
    "# Image Processing Pipeline for NOAA Buoy Cameras\n",
    "1. Get the latest image in the buoy's folder\n",
    "2. Isolate the six panels and save them as individual images with the pattern \"original_name + panel_number\".png (e.g. 41001_2019-07-01_00:00:00_panel_1.png)\n",
    "3. The height of the cropped image should be 270 pixels (measured from the top of the image)\n",
    "4. The widths of each cropped panel should be 480 pixels (measured from the left of the image). The first panel should start at 0 pixels and the last panel should end at 2880 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoy_update_rates_dict = {} # blank dictionary to store the update rates for each buoy (i.e. how often the buoy takes a picture (measured in seconds))\n",
    "# fill the dictionary with blank update rate arrays for each buoy.\n",
    "# these arrays will be averaged to get the average update rate for each buoy in real time.\n",
    "\n",
    "for buoy_id in cam_buoys:\n",
    "    buoy_update_rates_dict[buoy_id] = 1 # set the initial update rate to 600 seconds (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_has_changed(image_one,image_two):\n",
    "    # looks for changes between two images and returns True if there are changes and False if there are not.\n",
    "    # this function is used to determine what rate the images are being updated for each buoy.\n",
    "    # if the images are not changing, then the buoy is not updating the images.\n",
    "    # if the images are changing, then the buoy is updating the images.\n",
    "    try:\n",
    "        image_one = cv2.imread(image_one)\n",
    "        image_two = cv2.imread(image_two)\n",
    "        difference = cv2.subtract(image_one, image_two)\n",
    "        result = not np.any(difference)\n",
    "        return result\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    # difference = cv2.subtract(image_one, image_two)\n",
    "    # b, g, r = cv2.split(difference)\n",
    "    # if cv2.countNonZero(b) == 0 and cv2.countNonZero(g) == 0 and cv2.countNonZero(r) == 0:\n",
    "    #     return False # images are the same\n",
    "    # else:\n",
    "    #     return True # there are changes between the two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Artist:\n",
    "    def __init__(self):\n",
    "        self.folder = 'images'\n",
    "    def make_panorama(self, images):\n",
    "        # this function will take a list of images and make a panorama out of them\n",
    "        # resize image\n",
    "        scale_percent = 70 # percent of original size\n",
    "        images = [cv2.resize(images[i], (int(images[i].shape[1]*scale_percent/100), int(images[i].shape[0]*scale_percent/100)), interpolation= cv2.INTER_AREA) for i in range(len(images))]\n",
    "        # create a list of the images\n",
    "        # print('Making a panorama...')\n",
    "        # images = [cv2.imread(image) for image in images]\n",
    "        # # resize the images\n",
    "        # print('images: {}'.format(images))\n",
    "        # print(f'Resizing images...')\n",
    "        # images = [cv2.resize(images[i], (int(images[i].shape[1]*scale_percent/100), int(images[i].shape[0]*scale_percent/100)), interpolation= cv2.INTER_AREA) for i in range(len(images))]\n",
    "        # take a list of images and stitch them together with cv2\n",
    "        stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create() # stitcher object\n",
    "        # make stitcher with higher resolution\n",
    "        stitcher.setPanoConfidenceThresh(0.1)\n",
    "        stitcher.setRegistrationResol(0.6)\n",
    "        stitcher.setSeamEstimationResol(0.1)\n",
    "        stitcher.setCompositingResol(0.6)\n",
    "        stitcher.setWaveCorrection(True)\n",
    "        stitcher.setWaveCorrectKind(cv2.WAVE_CORRECT_HORIZ)\n",
    "        stitcher.setFeaturesFinder(cv2.ORB_create())\n",
    "        stitcher.setFeaturesMatcher(cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING))\n",
    "        stitcher.setBundleAdjuster(cv2.detail_BundleAdjusterRay())\n",
    "        stitcher.setExposureCompensator(cv2.detail.ExposureCompensator_createDefault(cv2.detail.ExposureCompensator_GAIN_BLOCKS))\n",
    "        stitcher.setBlender(cv2.detail.Blender_createDefault(cv2.detail.Blender_NO))\n",
    "        stitcher.setSeamFinder(cv2.detail.SeamFinder_createDefault(cv2.detail.SeamFinder_VORONOI_SEAM))\n",
    "        stitcher.setWarper(cv2.PyRotationWarper(cv2.ROTATION_WARP_PERSPECTIVE))\n",
    "        stitcher.setInterpolationFlags(cv2.INTER_LINEAR_EXACT)\n",
    "    \n",
    "    \n",
    "        (status, stitched) = stitcher.stitch(images) # stitch the images together with cv2\n",
    "        \n",
    "        \n",
    "        # print('stitched: {}'.format(stitched))\n",
    "    \n",
    "        \n",
    "        if status == 0:\n",
    "            # resize the stitched image to be a panorama size\n",
    "            stitched = cv2.resize(stitched, (int(stitched.shape[1]*scale_percent/100), int(stitched.shape[0]*scale_percent/100)), interpolation= cv2.INTER_AREA)\n",
    "            return stitched\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "\n",
    "def artist_eval(image_path):\n",
    "    # get the image\n",
    "    img = Image.open(image_path)\n",
    "    # get the image size\n",
    "    width, height = img.size\n",
    "    # get the pixel values for the center of the image\n",
    "    pixel_values = img.getpixel((int(width/2), int(height/2)))\n",
    "    # get the pixel values for the top left corner of the image\n",
    "    upper_left = img.getpixel((0, 0))\n",
    "    # get the pixel values for the top right corner of the image\n",
    "    upper_right = img.getpixel((width-1, 0))\n",
    "    \n",
    "    # get the pixel values for the centers of the six panels in the image\n",
    "    panel_1 = img.getpixel((int(width/12), int(height/2)))\n",
    "    panel_2 = img.getpixel((int(width/4), int(height/2)))\n",
    "    panel_3 = img.getpixel((int(width/2), int(height/2)))\n",
    "    panel_4 = img.getpixel((int(width*3/4), int(height/2)))\n",
    "    panel_5 = img.getpixel((int(width*5/6), int(height/2)))\n",
    "    panel_6 = img.getpixel((int(width*11/12), int(height/2)))\n",
    "\n",
    "    # a panorama is best when the panels are similar in color\n",
    "    # let's see how close the panels are to each other\n",
    "    # we'll use the mean squared error\n",
    "    mse_1 = np.mean((np.array(panel_1) - np.array(panel_2)) ** 2)\n",
    "    mse_2 = np.mean((np.array(panel_2) - np.array(panel_3)) ** 2)\n",
    "    mse_3 = np.mean((np.array(panel_3) - np.array(panel_4)) ** 2)\n",
    "    mse_4 = np.mean((np.array(panel_4) - np.array(panel_5)) ** 2)\n",
    "    mse_5 = np.mean((np.array(panel_5) - np.array(panel_6)) ** 2)\n",
    "\n",
    "    # the mean squared error is a good measure of how similar the panels are\n",
    "    # the lower the mse, the more similar the panels are\n",
    "    # let's take the average of the mse's\n",
    "    mse = (mse_1 + mse_2 + mse_3 + mse_4 + mse_5) / 5\n",
    "\n",
    "    # we will make a panorama if the mse is less than 100\n",
    "    # this is a pretty arbitrary number, but it seems to work well\n",
    "    if mse < 100:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_updates(buoy_update_rates_dict):\n",
    "    # Check the buoy_update_rates_dict to see if any of the buoys satistfy the update rate requirements:\n",
    "    # Requirements: the current time minus the last time we downloaded an image for this buoy must be greater than the update rate for this buoy. If it is, then we will add the buoy id to the list of buoys that need to be updated and return it to the main function.\n",
    "    # If the buoy_update_rates_dict is empty, then we will return an empty list.\n",
    "    # If the buoy_update_rates_dict is not empty, then we will check the update rates for each buoy and return a list of the buoy ids that need to be updated.\n",
    "\n",
    "    if len(buoy_update_rates_dict) == 0:\n",
    "        return []\n",
    "    else:\n",
    "        buoys_to_update = []\n",
    "        for buoy_id in buoy_update_rates_dict:\n",
    "            #print(buoy_update_rates_dict[buoy_id])\n",
    "            if (datetime.datetime.now() - buoy_update_rates_dict[buoy_id][1]).seconds > buoy_update_rates_dict[buoy_id][0]:\n",
    "                # the current time minus the last time we downloaded an image for this buoy must be greater than the update rate for this buoy.\n",
    "                buoys_to_update.append(buoy_id)\n",
    "                # reset the last time we downloaded an image for this buoy to the current time.\n",
    "                buoy_update_rates_dict[buoy_id][1] = datetime.datetime.now()\n",
    "            \n",
    "        return buoys_to_update, buoy_update_rates_dict # return a list of the buoy ids that need to be updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([], {'46025': [600, datetime.datetime(2022, 11, 6, 14, 47, 35, 856029)]})\n",
      "([], {'46025': [600, datetime.datetime(2022, 11, 6, 14, 47, 35, 856029)]})\n"
     ]
    }
   ],
   "source": [
    "# test check_for_updates function\n",
    "buoy_update_rates_dict = {'46025': [600, datetime.datetime.now()]}\n",
    "print(check_for_updates(buoy_update_rates_dict)) # should return an empty list\n",
    "# wait 10 seconds\n",
    "time.sleep(10)\n",
    "print(check_for_updates(buoy_update_rates_dict)) # should return ['46025']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1099 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0771 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0948 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0925 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1064 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1058 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.093 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0957 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0845 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0859 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.101 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0869 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.083 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0923 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0587 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0938 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1106 seconds.\n",
      "DifPy preparing files: [30/30] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.229 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0839 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0872 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1109 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0928 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0731 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0918 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0977 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0904 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1097 seconds.\n",
      "DifPy preparing files: [27/27] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.2029 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1027 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [10/10] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0991 seconds.\n",
      "DifPy preparing files: [11/11] [100%]\n",
      "DifPy comparing images: [10/10] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1036 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0903 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1123 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1139 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0931 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0941 seconds.\n",
      "DifPy preparing files: [3/3] [100%]\n",
      "DifPy comparing images: [2/2] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0162 seconds.\n",
      "DifPy preparing files: [9/9] [100%]\n",
      "DifPy comparing images: [8/8] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.055 seconds.\n",
      "DifPy preparing files: [11/11] [100%]\n",
      "DifPy comparing images: [10/10] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0774 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0889 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1005 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0964 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0804 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0916 seconds.\n",
      "DifPy preparing files: [11/11] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0817 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0914 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0858 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0939 seconds.\n",
      "DifPy preparing files: [9/9] [100%]\n",
      "DifPy comparing images: [9/9] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0622 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0921 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0864 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0901 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0872 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0863 seconds.\n",
      "DifPy preparing files: [11/11] [100%]\n",
      "DifPy comparing images: [10/10] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0681 seconds.\n",
      "DifPy preparing files: [17/17] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1329 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1145 seconds.\n",
      "DifPy preparing files: [11/11] [100%]\n",
      "DifPy comparing images: [10/10] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0848 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0817 seconds.\n",
      "DifPy preparing files: [16/16] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1081 seconds.\n",
      "DifPy preparing files: [11/11] [100%]\n",
      "DifPy comparing images: [10/10] [100%]\n",
      "Found 2 images with one or more duplicate/similar images in 0.0657 seconds.\n",
      "\n",
      "Deleted file: images/buoys/42039/2022_11_6_10_54.jpg\n",
      "Deleted file: images/buoys/42039/2022_11_6_13_41.jpg\n",
      "***\n",
      "Deleted 2 images.\n"
     ]
    }
   ],
   "source": [
    "# import shutil\n",
    "# from difPy import dif\n",
    "\n",
    "# go through each buoy and check if there are duplicated images in the images/buoys folder\n",
    "for folder in os.listdir('images/buoys'):\n",
    "    if folder == '.DS_Store':\n",
    "        continue\n",
    "    # get the list of images in the folder\n",
    "    # sort the images by date\n",
    "    # make folder_path variable from relative path\n",
    "    folder_path = 'images/buoys/{}'.format(folder)\n",
    "    search = dif(folder_path, similarity='normal', show_output=False, show_progress=True, silent_del=True, delete=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest news from the RSS feed at https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt, and return the pandas dataframe of the data.\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "def get_latest_data():\n",
    "    url = \"https://www.ndbc.noaa.gov/data/latest_obs/latest_obs.txt\"\n",
    "    s=requests.get(url).content\n",
    "\n",
    "    # the table contains two rows that have header data. combine them into one row.\n",
    "\n",
    "    df = pd.read_csv(io.StringIO(s.decode('utf-8')), sep='\\s+')\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # df = df.dropna(axis=1, how='all')\n",
    "    # df = df.dropna(axis=0, how='all')\n",
    "    # df = df.dropna(axis=0, how='any')\n",
    "    # df = df.reset_index(drop=True)\n",
    "    # df = df.drop(df.index[0])\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Artist Class Explained\n",
    "\n",
    "The goal of the artist is to identify which buoy photo sets are the most beautiful or interesting.\n",
    "The artist will be able to select a photo set and then rate it on a scale of 1-5.\n",
    "\n",
    "the photo sets are located in the images/panels directory and are named by the buoy id\n",
    "over time the artist will learn which times of day are the most beautiful and interesting for each buoy and will be able to teach the system to automatically raise the rate of photo capture during those times. For example, the most beautiful photos could be those that are taken at sunrise and sunset. The artist could also teach the system to take more photos when the weather is clear and less photos when the weather is cloudy. Unless cloudy weather is the most beautiful weather. That is up for debate.\n",
    "\n",
    "As the system collects data about the buoy's photos it will begin to add weights to each buoy which will inform a random.random.choice function with weighted probabilities. This will allow the system to take photos of the most beautiful buoys more often.\n",
    "\n",
    "\n",
    "\n",
    "The artist will use an ESRGAN on the photo sets that they think are most beautiful and enhance their quality. If they go well together then the artist will be able to create a video of the photo set or a panorama of the photo set.\n",
    "\n",
    "- Step One - Evaluation of the photo sets\n",
    "- Step Two - ESRGAN on the photo sets\n",
    "- Step Three - Video creation\n",
    "- Step Four - Panorama creation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the images\n",
    "# until the current time is 10 pm Central Standard Time (CST) Keep downloading images from the cameras every 10 minutes\n",
    "iteration_counter = 0\n",
    "vincent = Artist() # create an instance of the Artist class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the download loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:27<00:00,  2.19it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 20545.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.1173 seconds.\n",
      "\n",
      "Deleted file: images/buoys/46086/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.089 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0932 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.101 seconds.\n",
      "DifPy preparing files: [16/16] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1165 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1171 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1142 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.1172 seconds.\n",
      "\n",
      "Deleted file: images/buoys/46026/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0977 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0938 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1214 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1021 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0982 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0994 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.0676 seconds.\n",
      "\n",
      "Deleted file: images/buoys/41008/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1096 seconds.\n",
      "DifPy preparing files: [16/16] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.13 seconds.\n",
      "DifPy preparing files: [31/31] [100%]\n",
      "DifPy comparing images: [15/15] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.2482 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1015 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0948 seconds.\n",
      "DifPy preparing files: [16/16] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1205 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0979 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0807 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0984 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1095 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0967 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.124 seconds.\n",
      "DifPy preparing files: [28/28] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.212 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1036 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0808 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.09 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.0898 seconds.\n",
      "\n",
      "Deleted file: images/buoys/41004/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [16/16] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1186 seconds.\n",
      "DifPy preparing files: [16/16] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1176 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0964 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.0995 seconds.\n",
      "\n",
      "Deleted file: images/buoys/42012/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [4/4] [100%]\n",
      "DifPy comparing images: [3/3] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.0196 seconds.\n",
      "\n",
      "Deleted file: images/buoys/46085/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [10/10] [100%]\n",
      "DifPy comparing images: [9/9] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0626 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0811 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1005 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.104 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1085 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0906 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1027 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0903 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0973 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0917 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1012 seconds.\n",
      "DifPy preparing files: [10/10] [100%]\n",
      "DifPy comparing images: [10/10] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0747 seconds.\n",
      "DifPy preparing files: [14/14] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1029 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.0945 seconds.\n",
      "\n",
      "Deleted file: images/buoys/44027/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0985 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.0941 seconds.\n",
      "\n",
      "Deleted file: images/buoys/44011/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0928 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0719 seconds.\n",
      "DifPy preparing files: [18/18] [100%]\n",
      "DifPy comparing images: [15/15] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1293 seconds.\n",
      "DifPy preparing files: [15/15] [100%]\n",
      "DifPy comparing images: [14/14] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.1087 seconds.\n",
      "DifPy preparing files: [12/12] [100%]\n",
      "DifPy comparing images: [11/11] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0778 seconds.\n",
      "DifPy preparing files: [13/13] [100%]\n",
      "DifPy comparing images: [12/12] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0863 seconds.\n",
      "DifPy preparing files: [17/17] [100%]\n",
      "DifPy comparing images: [13/13] [100%]\n",
      "Found 1 image with one or more duplicate/similar images in 0.1117 seconds.\n",
      "\n",
      "Deleted file: images/buoys/42001/2022_11_6_14_49.jpg\n",
      "***\n",
      "Deleted 1 images.\n",
      "DifPy preparing files: [10/10] [100%]\n",
      "DifPy comparing images: [9/9] [100%]\n",
      "Found 0 images with one or more duplicate/similar images in 0.0573 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 72356.49it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 104.48it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 103.84it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 142.02it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 158.22it/s]\n",
      "100%|██████████| 73/73 [00:03<00:00, 21.40it/s] \n",
      "100%|██████████| 72/72 [00:00<00:00, 186.51it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 76.34it/s] \n",
      "100%|██████████| 72/72 [00:02<00:00, 25.38it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 122.26it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 141.21it/s]\n",
      "100%|██████████| 72/72 [00:02<00:00, 30.75it/s] \n",
      "100%|██████████| 72/72 [00:01<00:00, 46.20it/s] \n",
      "100%|██████████| 72/72 [00:00<00:00, 90.34it/s] \n",
      "100%|██████████| 48/48 [00:00<00:00, 115.25it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 177.31it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 90.33it/s] \n",
      "100%|██████████| 72/72 [00:00<00:00, 92.13it/s] \n",
      "100%|██████████| 84/84 [00:00<00:00, 138.17it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 57.71it/s] \n",
      "100%|██████████| 48/48 [00:00<00:00, 63.95it/s] \n",
      "100%|██████████| 60/60 [00:00<00:00, 124.69it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 128.90it/s]\n",
      "100%|██████████| 48/48 [00:01<00:00, 46.49it/s] \n",
      "100%|██████████| 49/49 [00:00<00:00, 100.18it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 100.38it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 63.09it/s] \n",
      "100%|██████████| 72/72 [00:01<00:00, 41.77it/s] \n",
      "100%|██████████| 84/84 [00:00<00:00, 142.73it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 92.64it/s] \n",
      "100%|██████████| 36/36 [00:00<00:00, 57.02it/s] \n",
      "100%|██████████| 36/36 [00:00<00:00, 45.68it/s] \n",
      "100%|██████████| 48/48 [00:00<00:00, 87.79it/s] \n",
      "100%|██████████| 60/60 [00:00<00:00, 83.84it/s] \n",
      "100%|██████████| 72/72 [00:00<00:00, 118.12it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 61.87it/s] \n",
      "100%|██████████| 60/60 [00:02<00:00, 27.53it/s] \n",
      "100%|██████████| 24/24 [00:01<00:00, 15.67it/s]\n",
      "100%|██████████| 72/72 [00:01<00:00, 39.74it/s] \n",
      "100%|██████████| 72/72 [00:00<00:00, 171.61it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 171.99it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 140.16it/s]\n",
      "100%|██████████| 84/84 [00:00<00:00, 122.85it/s]\n",
      "100%|██████████| 48/48 [00:01<00:00, 39.03it/s] \n",
      "100%|██████████| 60/60 [00:02<00:00, 27.23it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 76.42it/s] \n",
      "100%|██████████| 72/72 [00:00<00:00, 83.31it/s] \n",
      "100%|██████████| 72/72 [00:00<00:00, 117.35it/s]\n",
      "100%|██████████| 60/60 [00:01<00:00, 53.92it/s] \n",
      "100%|██████████| 36/36 [00:00<00:00, 100.46it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 106.27it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 51.27it/s] \n",
      "100%|██████████| 48/48 [00:00<00:00, 105.34it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 51.85it/s] \n",
      "100%|██████████| 84/84 [00:00<00:00, 88.25it/s] \n",
      "100%|██████████| 36/36 [00:00<00:00, 70.79it/s] \n",
      "100%|██████████| 84/84 [00:00<00:00, 124.63it/s]\n",
      "100%|██████████| 72/72 [00:00<00:00, 118.94it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 40.23it/s]\n",
      "100%|██████████| 48/48 [00:00<00:00, 93.57it/s] \n",
      "100%|██████████| 60/60 [00:00<00:00, 86.61it/s] \n",
      "100%|██████████| 60/60 [00:02<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with this run\n",
      "Waiting for the remainder of the minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 33/510 [00:33<07:58,  1.00s/it]"
     ]
    }
   ],
   "source": [
    "print('Starting the download loop')\n",
    "last_time_fetched = time.time() # get the current time\n",
    "first_run = True # set a flag to indicate that this is the first run of the loop (for the first run, we will download rss feeds for all the buoys)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # turn on at 4 am CST and turn off at 11 pm CST\n",
    "        if datetime.datetime.now().hour < 4 or datetime.datetime.now().hour > 22: # if it is before 4 am or after 11 pm\n",
    "            # wait to turn on until 4 am CST\n",
    "            # keep the computer awake\n",
    "            print('The computer is sleeping')\n",
    "            time.sleep(240) # sleep for 4 minutes\n",
    "            continue\n",
    "        # # if the time is between 4 am and 11 am pacific time, then your wait_period is 100 seconds\n",
    "        # if datetime.datetime.now().hour >= 4 and datetime.datetime.now().hour < 11:\n",
    "        #     wait_period = 100\n",
    "        # # if the time is between 11 am and 11 pm pacific time, then your wait_period is 600 seconds\n",
    "        # if datetime.datetime.now().hour >= 11 and datetime.datetime.now().hour < 13:\n",
    "        #     wait_period = 600 # 10 minutes\n",
    "        # wait for 15 minutes\n",
    "        wait_period = 600 # 10 minutes\n",
    "        start_time = datetime.datetime.now() # use this to calculate the next time to download images (every ten minutes)\n",
    "        # print('I can still see things! Downloading images...')\n",
    "        for cam_url in tqdm(cam_urls): \n",
    "            # get the buoy id from the camera url\n",
    "            buoy_id = re.search('station=(.*)', cam_url).group(1)\n",
    "            # get the current time\n",
    "            now = datetime.datetime.now()\n",
    "            # create a directory for the buoy id if it doesn't already exist\n",
    "            if not os.path.exists('images/buoys/{}'.format(buoy_id)):\n",
    "                os.makedirs('images/buoys/{}'.format(buoy_id))\n",
    "            # get the image\n",
    "            if 'images/buoys/{}/{}_{}_{}_{}_{}.jpg'.format(buoy_id, now.year, now.month, now.day, now.hour, now.minute) not in os.listdir('images/buoys/{}'.format(buoy_id)): # if the image has not already been downloaded\n",
    "                time.sleep(0.25) # wait 0.25 seconds to avoid getting blocked by the server\n",
    "                img = requests.get(cam_url) # get the image\n",
    "                # save the image\n",
    "                with open('images/buoys/{}/{}_{}_{}_{}_{}.jpg'.format(buoy_id, now.year, now.month, now.day, now.hour, now.minute), 'wb+') as f:\n",
    "                    f.write(img.content) # write the image to the file\n",
    "                # check if the image is daytime or nighttime\n",
    "                #if not is_it_daytime('images/buoys/{}/{}_{}_{}_{}_{}.jpg'.format(buoy_id, now.year, now.month, now.day, now.hour, now.minute)): # if it is nighttime\n",
    "                    # then we will delete the image\n",
    "                    #*print(f'Deleting image for buoy {buoy_id} because it is nighttime.')\n",
    "                    #*os.remove('images/buoys/{}/{}_{}_{}_{}_{}.jpg'.format(buoy_id, now.year, now.month, now.day, now.hour, now.minute))\n",
    "                #    pass\n",
    "            else:\n",
    "                pass # if the image already exists, don't download it again\n",
    "\n",
    "\n",
    "        # Save the panels to the images/panels directory\n",
    "        list_of_buoys = os.listdir('images/buoys') # get the list of buoy ids by their directory names\n",
    "        for buoy_id in tqdm(list_of_buoys):\n",
    "            # get the list of images for the buoy\n",
    "            if buoy_id != '.DS_Store':\n",
    "                images = os.listdir('images/buoys/{}'.format(buoy_id))\n",
    "                # if the image has not already been used to create panels, create the panels and save them to the images/panels directory\n",
    "                for image in images:\n",
    "                    # if the image is not None\n",
    "                    if image == '.DS_Store' or image != 'None':\n",
    "                        continue\n",
    "                    # If the panels directory for the buoy doesn't exist, create it.\n",
    "                    if not os.path.exists('images/panels/{}'.format(buoy_id)):\n",
    "                        os.makedirs('images/panels/{}'.format(buoy_id))\n",
    "                    if 'images/buoys/{}/{}'.format(buoy_id, image) in os.listdir('images/panels/{}'.format(buoy_id)):\n",
    "                        print('This image has already been used to create panels.')\n",
    "                        continue\n",
    "                    if image == '.DS_Store' and buoy_id != '.DS_Store':\n",
    "                        continue # skip the .DS_Store file\n",
    "                    #print('Processing image: {}'.format(image))\n",
    "\n",
    "                    # get the panels\n",
    "                    panel_1, panel_2, panel_3, panel_4, panel_5, panel_6 = divide_into_panels(buoy_id, 'images/buoys/{}/{}'.format(buoy_id, image))\n",
    "                    print('Saving panels...')\n",
    "                    # save the panels to the images/panels directory\n",
    "\n",
    "        \n",
    "        # Stage 4: save buoy_update_rates_dict to a csv file\n",
    "        buoy_update_rates_dict_df = pd.DataFrame.from_dict(buoy_update_rates_dict, orient='index')\n",
    "        buoy_update_rates_dict_df.to_csv('data/buoy_update_rates_dict.csv')\n",
    "\n",
    "        # Stage 5: Remove any duplicate images in the images/buoys directory with DifPy\n",
    "\n",
    "    \n",
    "\n",
    "        # Remove duplicate images (preferably before paneling but for now after)\n",
    "        for folder in os.listdir('images/buoys'):\n",
    "            if folder == '.DS_Store':\n",
    "                continue\n",
    "            # get the list of images in the folder\n",
    "            # sort the images by date\n",
    "            # make folder_path variable from relative path\n",
    "            folder_path = 'images/buoys/{}'.format(folder)\n",
    "            search = dif(folder_path, similarity='high', show_output=False, show_progress=True, silent_del=True, delete=True)\n",
    "\n",
    "        # final step: make sure that all the previous buoy images have been panelled and saved to the images/panels directory\n",
    "        for folder in tqdm(os.listdir('images/buoys')):\n",
    "            if folder == '.DS_Store':\n",
    "                continue\n",
    "            if not os.path.exists('images/panels/{}'.format(folder)):\n",
    "                print('The images in the images/buoys/{} directory have not been panelled yet.'.format(folder))\n",
    "                # panelling the images\n",
    "                os.mkdir('images/panels/{}'.format(folder))\n",
    "                images = os.listdir('images/buoys/{}'.format(folder))\n",
    "                for image in images:\n",
    "                    try:\n",
    "                        if image == '.DS_Store':\n",
    "                            continue\n",
    "                        # get the panels\n",
    "                        panel_1, panel_2, panel_3, panel_4, panel_5, panel_6 = divide_into_panels(folder, 'images/buoys/{}/{}'.format(folder, image))\n",
    "                        # save the panels to the images/panels directory\n",
    "                        cv2.imwrite('images/panels/{}/{}_panel_1.jpg'.format(folder, image), panel_1)\n",
    "                        cv2.imwrite('images/panels/{}/{}_panel_2.jpg'.format(folder, image), panel_2)\n",
    "                        cv2.imwrite('images/panels/{}/{}_panel_3.jpg'.format(folder, image), panel_3)\n",
    "                        cv2.imwrite('images/panels/{}/{}_panel_4.jpg'.format(folder, image), panel_4)\n",
    "                        cv2.imwrite('images/panels/{}/{}_panel_5.jpg'.format(folder, image), panel_5)\n",
    "                        cv2.imwrite('images/panels/{}/{}_panel_6.jpg'.format(folder, image), panel_6)\n",
    "                        logging.info('Saved panels for image: {}'.format(image))\n",
    "                    except:\n",
    "                        logging.ERROR('Error while saving panels for image: {}'.format(image))\n",
    "                        # print('Could not create panels for image: {}'.format(image))\n",
    "                        continue\n",
    "\n",
    "        # for each folder in the images/panels folder, stitch the images together and save them to the images/panoramas folder with the same name as the folder + panorama.png\n",
    "        \n",
    "        #note: the for loop below does not account for the fact that there are multiple captures with 6 frames per capture. This means that the images will be stitched together incorrectly. This is a problem that needs to be fixed. Find a way to select only the sets of 6 images that go together to stitch together.\n",
    "\n",
    "        for folder in os.listdir('images/panels'):\n",
    "            if folder == '.DS_Store':\n",
    "                continue\n",
    "            images = []\n",
    "            for image in tqdm(os.listdir(f'images/panels/{folder}')):\n",
    "                if image == '.DS_Store':\n",
    "                    continue\n",
    "                if artist_eval(f'images/panels/{folder}/{image}'): # if the artist decides to make a panorama (True)\n",
    "                    images.append(cv2.imread(f'images/panels/{folder}/{image}'))\n",
    "                    try:\n",
    "                        panorama = vincent.make_panorama(images)\n",
    "                        cv2.imwrite(f'images/panoramas/{folder}_panorama.png', panorama)\n",
    "                    except:\n",
    "                        ##print(f'Could not create panorama for {folder}')\n",
    "                        pass\n",
    "                else:\n",
    "                    #print(f'Could not create panorama for {folder}')\n",
    "                    pass\n",
    "\n",
    "\n",
    "        # Stage 6: Create the buoy dataframes\n",
    "            # if it has been ten minutes since the last time the data was fetched, fetch the data again\n",
    "        if time.time() - last_time_fetched > 600 or first_run:\n",
    "            latest_data = get_latest_data() # get the latest data from the RSS feed (updates every 10 minutes)\n",
    "            # save the master dataframe to a csv file\n",
    "            run_date = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            latest_data.to_csv(f'data/rss/rss_buoy_data_{run_date}.csv', index=False)\n",
    "            print('Done with this run')\n",
    "            time_last_fetched_rss = time.time() # get the time of the last fetch\n",
    "\n",
    "\n",
    "\n",
    "        # how much time has passed since the start of the loop?\n",
    "        time_elapsed = datetime.datetime.now() - start_time\n",
    "        # wait until the time elapsed is 15 minutes from the start of the loop\n",
    "        print(\"Waiting for the remainder of the minutes...\")\n",
    "        # wait_period = 100 # was 900 (15 minutes)\n",
    "        for i in tqdm(range(wait_period - time_elapsed.seconds)):\n",
    "            time.sleep(1)\n",
    "        iteration_counter += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Error occurred. Restarting loop...')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is designed to run continuously until we have a large enough dataset to train a model. We will use the time library to set the interval between downloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Recognition Pipeline for NOAA Buoy Camera Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41088 - takes every hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'images/panels/46066/2022_11_5_15_45/2022_11_5_15_45_panel_1.png'\n",
    "print(is_it_daytime(path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('pyseas_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d626167f0daf48f1329c2d475d765434ba28299f98c9f4c92c2fe00e06e2119b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
